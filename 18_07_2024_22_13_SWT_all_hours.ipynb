{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/18_07_2024_22_13_SWT_all_hours.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFDa5DVspn8"
      },
      "source": [
        "18/07/2024"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Modify this path accordingly\n",
        "file_path = '/content/QSI points.xlsx'\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Get the lineID from the user\n",
        "lineID = input(\"Please enter the lineID: \")\n",
        "\n",
        "# Check if the necessary column is present\n",
        "if 'Route_Dir_QSI_No' not in df.columns:\n",
        "    print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "else:\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Create regular expressions for filtering\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for lineID_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for lineID_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "\n",
        "    # Function to fetch and process route sequence data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    matched_results_df_A = matched_results_df_A[matched_results_df_A['Route_Dir_QSI_No'].str.match(pattern_A)]\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    matched_results_df_B = matched_results_df_B[matched_results_df_B['Route_Dir_QSI_No'].str.match(pattern_B)]\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # Display the combined DataFrame\n",
        "    print(\"\\n\\n\\033[1m\\033[4mCombined QSI stop points for directions A and B\\033[0m\\n\")\n",
        "    print(combined_df[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "0c55c4d8-ca0f-455a-a83e-f7441d8b29ef",
        "id": "7YH0gajXuMuI"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5c2d33ae6aed>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Get the lineID from the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mlineID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter the lineID: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Check if the necessary column is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Function to fetch data from the API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "            slots[hour].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# Function to calculate Scheduled Wait Time (SWT) for all hours\n",
        "def calculate_swt_for_all_hours(slots):\n",
        "    swt_per_hour = []\n",
        "    for hour in range(24):\n",
        "        total_buses = len(slots[hour])\n",
        "        scheduled_wait_time = 60 / (total_buses * 2) if total_buses > 0 else None  # Use None to indicate no buses\n",
        "        swt_per_hour.append((scheduled_wait_time, total_buses))\n",
        "    return swt_per_hour\n",
        "\n",
        "# Function to select the preferred schedule name based on the current day of the week\n",
        "def select_preferred_schedule(schedule_names_dict, day_of_week):\n",
        "    if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "    elif day_of_week.lower() == 'friday':\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "    elif day_of_week.lower() == 'saturday':\n",
        "        preferred_schedule_names = ['Saturday']\n",
        "    elif day_of_week.lower() == 'sunday':\n",
        "        preferred_schedule_names = ['Sunday']\n",
        "    else:\n",
        "        preferred_schedule_names = [day_of_week]\n",
        "\n",
        "    for preferred_name in preferred_schedule_names:\n",
        "        if preferred_name in schedule_names_dict:\n",
        "            return preferred_name\n",
        "    return None\n",
        "\n",
        "# Main logic to fetch and calculate SWT\n",
        "def main(combined_df, lineID):\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    swt_data = {\n",
        "        'Route_Dir_QSI_No': [],\n",
        "        'ID': [],\n",
        "    }\n",
        "    # Initialize keys for all 24 hours in the dictionary\n",
        "    for hour in range(24):\n",
        "        swt_data[f'SWT_{hour}'] = []\n",
        "        swt_data[f'Sch_{hour}'] = []\n",
        "\n",
        "    # Update current time and hour\n",
        "    current_time = datetime.now(bst)\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    # Store selected schedule name to ensure it's printed only once\n",
        "    selected_schedule_name = None\n",
        "    printed_schedule_name = False\n",
        "\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "        if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "            direction = 'outbound'\n",
        "        elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "            direction = 'inbound'\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "        data = fetch_data(url)\n",
        "\n",
        "        schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "        if not selected_schedule_name:\n",
        "            selected_schedule_name = select_preferred_schedule(schedule_names_dict, day_of_week)\n",
        "\n",
        "        if selected_schedule_name and not printed_schedule_name:\n",
        "            print(f\"\\n\\033[1m\\033[4mToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\\033[0m\")\n",
        "            printed_schedule_name = True\n",
        "\n",
        "        if selected_schedule_name:\n",
        "            timetable = schedule_names_dict[selected_schedule_name]\n",
        "            slots = categorize_into_slots(timetable)\n",
        "\n",
        "            # Calculate SWT for all hours\n",
        "            swt_per_hour = calculate_swt_for_all_hours(slots)\n",
        "\n",
        "            # Store SWT data for all hours\n",
        "            swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "            swt_data['ID'].append(stop_point_id)\n",
        "            for hour in range(24):\n",
        "                swt, total_buses = swt_per_hour[hour]\n",
        "                swt_data[f'SWT_{hour}'].append(swt)\n",
        "                swt_data[f'Sch_{hour}'].append(total_buses)\n",
        "\n",
        "    # Create DataFrame for SWT data\n",
        "    swt_df = pd.DataFrame(swt_data)\n",
        "    #print(swt_df)\n",
        "    # Print the SWT DataFrame\n",
        "    #print(\"\\n\\nSWT DataFrame:\")\n",
        "    #print(swt_df.to_string())\n",
        "\n",
        "# Assuming combined_df and lineID are defined and available\n",
        "# combined_df = ... (from previous code)\n",
        "# lineID = ... (from user input)\n",
        "main(combined_df, lineID)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkihpEM8upYC",
        "outputId": "000415a7-1ba9-4257-fb2a-97eb6c101203"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[4mToday is Thursday. The selected Schedule name is Mon-Fri Schooldays.\u001b[0m\n",
            "   Route_Dir_QSI_No          ID SWT_0  Sch_0 SWT_1  Sch_1 SWT_2  Sch_2 SWT_3  Sch_3  SWT_4  Sch_4  SWT_5  Sch_5  SWT_6  Sch_6  SWT_7  Sch_7  SWT_8  Sch_8  SWT_9  Sch_9  SWT_10  Sch_10  SWT_11  Sch_11  SWT_12  Sch_12  SWT_13  Sch_13  SWT_14  Sch_14  SWT_15  Sch_15  SWT_16  Sch_16  SWT_17  Sch_17  SWT_18  Sch_18  SWT_19  Sch_19  SWT_20  Sch_20  SWT_21  Sch_21  SWT_22  Sch_22  SWT_23  Sch_23\n",
            "0            179_A1  490001063C  None      0  None      0  None      0  None      0   30.0      1   10.0      3    7.5      4    6.0      5    6.0      5    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     6.0       5     6.0       5     6.0       5     6.0       5     7.5       4    10.0       3    10.0       3    10.0       3    10.0       3\n",
            "1            179_A2  490007021E  None      0  None      0  None      0  None      0   30.0      1   10.0      3   10.0      3    5.0      6    7.5      4    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5    10.0       3    10.0       3    10.0       3    10.0       3\n",
            "2            179_A3  490014847S  None      0  None      0  None      0  None      0    NaN      0   10.0      3    7.5      4    7.5      4    6.0      5    5.0      6     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     7.5       4     7.5       4    10.0       3    10.0       3    10.0       3\n",
            "3            179_A4  490015122C  None      0  None      0  None      0  None      0    NaN      0   10.0      3   10.0      3    6.0      5    7.5      4    5.0      6     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     6.0       5     6.0       5     6.0       5    10.0       3    10.0       3    10.0       3     7.5       4\n",
            "4            179_A5  490005002N  None      0  None      0  None      0  None      0    NaN      0   10.0      3   10.0      3    7.5      4    6.0      5    5.0      6     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     6.0       5    10.0       3    10.0       3    10.0       3    10.0       3\n",
            "5            179_A6  490015202N  None      0  None      0  None      0  None      0    NaN      0   10.0      3   15.0      2    7.5      4    6.0      5    6.0      5     5.0       6     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     7.5       4    10.0       3    10.0       3    10.0       3\n",
            "6            179_A7  490005699D  None      0  None      0  None      0  None      0    NaN      0   15.0      2   10.0      3   10.0      3    6.0      5    5.0      6     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     7.5       4     7.5       4    10.0       3    10.0       3\n",
            "7            179_B1  490007657W  None      0  None      0  None      0  None      0    NaN      0   10.0      3    7.5      4    5.0      6    6.0      5    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     6.0       5     7.5       4     6.0       5     6.0       5     6.0       5    10.0       3    10.0       3    10.0       3    10.0       3\n",
            "8            179_B2  490001157G  None      0  None      0  None      0  None      0    NaN      0   10.0      3    7.5      4    5.0      6    7.5      4    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5    10.0       3    10.0       3    10.0       3    10.0       3\n",
            "9            179_B3  490015202M  None      0  None      0  None      0  None      0    NaN      0   15.0      2    7.5      4    5.0      6    6.0      5    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5    10.0       3    10.0       3    10.0       3    10.0       3\n",
            "10           179_B4  490012285S  None      0  None      0  None      0  None      0    NaN      0   15.0      2   10.0      3    6.0      5    5.0      6    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     7.5       4    10.0       3    10.0       3    10.0       3\n",
            "11           179_B5  490000217E  None      0  None      0  None      0  None      0    NaN      0   15.0      2   10.0      3    6.0      5    5.0      6    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     7.5       4    10.0       3    10.0       3    10.0       3\n",
            "12           179_B6  490014847N  None      0  None      0  None      0  None      0    NaN      0   15.0      2   10.0      3    7.5      4    5.0      6    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     7.5       4    10.0       3    10.0       3     7.5       4\n",
            "13           179_B7  490007021W  None      0  None      0  None      0  None      0    NaN      0   30.0      1   10.0      3    7.5      4    5.0      6    6.0      5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     6.0       5     5.0       6     7.5       4    10.0       3    10.0       3    10.0       3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Function to fetch data from the API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "            slots[hour].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# Function to calculate Scheduled Wait Time (SWT) for all hours\n",
        "def calculate_swt_for_all_hours(slots):\n",
        "    swt_per_hour = []\n",
        "    for hour in range(24):\n",
        "        total_buses = len(slots[hour])\n",
        "        scheduled_wait_time = 60 / (total_buses * 2) if total_buses > 0 else None  # Use None to indicate no buses\n",
        "        swt_per_hour.append((scheduled_wait_time, total_buses))\n",
        "    return swt_per_hour\n",
        "\n",
        "# Function to select the preferred schedule name based on the current day of the week\n",
        "def select_preferred_schedule(schedule_names_dict, day_of_week):\n",
        "    if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "    elif day_of_week.lower() == 'friday':\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "    elif day_of_week.lower() == 'saturday':\n",
        "        preferred_schedule_names = ['Saturday']\n",
        "    elif day_of_week.lower() == 'sunday':\n",
        "        preferred_schedule_names = ['Sunday']\n",
        "    else:\n",
        "        preferred_schedule_names = [day_of_week]\n",
        "\n",
        "    for preferred_name in preferred_schedule_names:\n",
        "        if preferred_name in schedule_names_dict:\n",
        "            return preferred_name\n",
        "    return None\n",
        "\n",
        "# Main logic to fetch and calculate SWT\n",
        "def main(combined_df, lineID):\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    swt_data = {\n",
        "        'Route_Dir_QSI_No': [],\n",
        "        'ID': [],\n",
        "    }\n",
        "    # Initialize keys for all 24 hours in the dictionary\n",
        "    for hour in range(24):\n",
        "        swt_data[f'SWT_{hour}'] = []\n",
        "        swt_data[f'Sch_{hour}'] = []\n",
        "\n",
        "    # Update current time and hour\n",
        "    current_time = datetime.now(bst)\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    # Store selected schedule name to ensure it's printed only once\n",
        "    selected_schedule_name = None\n",
        "    printed_schedule_name = False\n",
        "\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "        if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "            direction = 'outbound'\n",
        "        elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "            direction = 'inbound'\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "        data = fetch_data(url)\n",
        "\n",
        "        schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "        if not selected_schedule_name:\n",
        "            selected_schedule_name = select_preferred_schedule(schedule_names_dict, day_of_week)\n",
        "\n",
        "        if selected_schedule_name and not printed_schedule_name:\n",
        "            print(f\"\\n\\033[1m\\033[4mToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\\033[0m\")\n",
        "            printed_schedule_name = True\n",
        "\n",
        "        if selected_schedule_name:\n",
        "            timetable = schedule_names_dict[selected_schedule_name]\n",
        "            slots = categorize_into_slots(timetable)\n",
        "\n",
        "            # Calculate SWT for all hours\n",
        "            swt_per_hour = calculate_swt_for_all_hours(slots)\n",
        "\n",
        "            # Store SWT data for all hours\n",
        "            swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "            swt_data['ID'].append(stop_point_id)\n",
        "            for hour in range(24):\n",
        "                swt, total_buses = swt_per_hour[hour]\n",
        "                swt_data[f'SWT_{hour}'].append(swt)\n",
        "                swt_data[f'Sch_{hour}'].append(total_buses)\n",
        "\n",
        "    # Create DataFrame for SWT data\n",
        "    swt_df = pd.DataFrame(swt_data)\n",
        "\n",
        "    # Calculate Route SWT for each hour for directions A and B\n",
        "    route_swt_data = {\n",
        "        'Hour': [],\n",
        "        'Route SWT A': [],\n",
        "        'Route SWT B': []\n",
        "    }\n",
        "\n",
        "    for hour in range(24):\n",
        "        # Calculate Route SWT for direction A\n",
        "        swt_a = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_A')]\n",
        "        weighted_sum_a = sum(swt_a[f'SWT_{hour}'] * swt_a[f'Sch_{hour}']) if not swt_a.empty else 0\n",
        "        total_buses_a = sum(swt_a[f'Sch_{hour}']) if not swt_a.empty else 0\n",
        "        route_swt_a = weighted_sum_a / total_buses_a if total_buses_a > 0 else None\n",
        "\n",
        "        # Calculate Route SWT for direction B\n",
        "        swt_b = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_B')]\n",
        "        weighted_sum_b = sum(swt_b[f'SWT_{hour}'] * swt_b[f'Sch_{hour}']) if not swt_b.empty else 0\n",
        "        total_buses_b = sum(swt_b[f'Sch_{hour}']) if not swt_b.empty else 0\n",
        "        route_swt_b = weighted_sum_b / total_buses_b if total_buses_b > 0 else None\n",
        "\n",
        "        route_swt_data['Hour'].append(hour)\n",
        "        route_swt_data['Route SWT A'].append(route_swt_a)\n",
        "        route_swt_data['Route SWT B'].append(route_swt_b)\n",
        "\n",
        "    route_swt_df = pd.DataFrame(route_swt_data)\n",
        "\n",
        "    # Print the Route SWT DataFrame\n",
        "    print(\"\\n\\nRoute SWT DataFrame:\")\n",
        "    print(route_swt_df.to_string())\n",
        "\n",
        "# Assuming combined_df and lineID are defined and available\n",
        "# combined_df = ... (from previous code)\n",
        "# lineID = ... (from user input)\n",
        "main(combined_df, lineID)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfJgVhEr0Pmy",
        "outputId": "1358614e-7914-469f-a869-930446c320be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[4mToday is Thursday. The selected Schedule name is Mon-Fri Schooldays.\u001b[0m\n",
            "\n",
            "\n",
            "Route SWT DataFrame:\n",
            "    Hour  Route SWT A  Route SWT B\n",
            "0      0          NaN          NaN\n",
            "1      1          NaN          NaN\n",
            "2      2          NaN          NaN\n",
            "3      3          NaN          NaN\n",
            "4      4          NaN          NaN\n",
            "5      5    10.500000    14.000000\n",
            "6      6     9.545455     8.750000\n",
            "7      7     6.774194     5.833333\n",
            "8      8     6.363636     5.526316\n",
            "9      9     5.384615     6.000000\n",
            "10    10     5.833333     6.000000\n",
            "11    11     6.000000     6.000000\n",
            "12    12     6.000000     6.000000\n",
            "13    13     6.000000     6.000000\n",
            "14    14     5.675676     5.675676\n",
            "15    15     6.000000     6.000000\n",
            "16    16     5.833333     6.176471\n",
            "17    17     6.000000     6.000000\n",
            "18    18     5.675676     6.000000\n",
            "19    19     6.000000     5.833333\n",
            "20    20     8.750000     8.400000\n",
            "21    21     9.545455    10.000000\n",
            "22    22    10.000000    10.000000\n",
            "23    23     9.545455     9.545455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Function to fetch data from the API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "            slots[hour].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# Function to calculate Scheduled Wait Time (SWT) for all hours\n",
        "def calculate_swt_for_all_hours(slots):\n",
        "    swt_per_hour = []\n",
        "    for hour in range(24):\n",
        "        total_buses = len(slots[hour])\n",
        "        scheduled_wait_time = 60 / (total_buses * 2) if total_buses > 0 else None  # Use None to indicate no buses\n",
        "        swt_per_hour.append((scheduled_wait_time, total_buses))\n",
        "    return swt_per_hour\n",
        "\n",
        "# Function to select the preferred schedule name based on the current day of the week\n",
        "def select_preferred_schedule(schedule_names_dict, day_of_week):\n",
        "    if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "    elif day_of_week.lower() == 'friday':\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "    elif day_of_week.lower() == 'saturday':\n",
        "        preferred_schedule_names = ['Saturday']\n",
        "    elif day_of_week.lower() == 'sunday':\n",
        "        preferred_schedule_names = ['Sunday']\n",
        "    else:\n",
        "        preferred_schedule_names = [day_of_week]\n",
        "\n",
        "    for preferred_name in preferred_schedule_names:\n",
        "        if preferred_name in schedule_names_dict:\n",
        "            return preferred_name\n",
        "    return None\n",
        "\n",
        "# Main logic to fetch and calculate SWT\n",
        "def main(combined_df, lineID):\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    swt_data = {\n",
        "        'Route_Dir_QSI_No': [],\n",
        "        'ID': [],\n",
        "    }\n",
        "    # Initialize keys for all 24 hours in the dictionary\n",
        "    for hour in range(24):\n",
        "        swt_data[f'SWT_{hour}'] = []\n",
        "        swt_data[f'Sch_{hour}'] = []\n",
        "\n",
        "    # Update current time and hour\n",
        "    current_time = datetime.now(bst)\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    # Store selected schedule name to ensure it's printed only once\n",
        "    selected_schedule_name = None\n",
        "    printed_schedule_name = False\n",
        "\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "        if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "            direction = 'outbound'\n",
        "        elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "            direction = 'inbound'\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "        data = fetch_data(url)\n",
        "\n",
        "        schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "        if not selected_schedule_name:\n",
        "            selected_schedule_name = select_preferred_schedule(schedule_names_dict, day_of_week)\n",
        "\n",
        "        if selected_schedule_name and not printed_schedule_name:\n",
        "            print(f\"\\n\\033[1m\\033[4mToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\\033[0m\")\n",
        "            printed_schedule_name = True\n",
        "\n",
        "        if selected_schedule_name:\n",
        "            timetable = schedule_names_dict[selected_schedule_name]\n",
        "            slots = categorize_into_slots(timetable)\n",
        "\n",
        "            # Calculate SWT for all hours\n",
        "            swt_per_hour = calculate_swt_for_all_hours(slots)\n",
        "\n",
        "            # Store SWT data for all hours\n",
        "            swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "            swt_data['ID'].append(stop_point_id)\n",
        "            for hour in range(24):\n",
        "                swt, total_buses = swt_per_hour[hour]\n",
        "                swt_data[f'SWT_{hour}'].append(swt)\n",
        "                swt_data[f'Sch_{hour}'].append(total_buses)\n",
        "\n",
        "    # Create DataFrame for SWT data\n",
        "    swt_df = pd.DataFrame(swt_data)\n",
        "\n",
        "    # Calculate Route SWT for each hour for directions A and B\n",
        "    route_swt_data = {\n",
        "        'Hour': [],\n",
        "        'Route SWT A': [],\n",
        "        'Route SWT B': []\n",
        "    }\n",
        "\n",
        "    for hour in range(24):\n",
        "        # Calculate Route SWT for direction A\n",
        "        swt_a = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_A')]\n",
        "        valid_swt_a = swt_a[pd.notna(swt_a[f'SWT_{hour}'])]  # Filter out NaN values\n",
        "        weighted_sum_a = sum(valid_swt_a[f'SWT_{hour}'] * valid_swt_a[f'Sch_{hour}']) if not valid_swt_a.empty else 0\n",
        "        total_buses_a = sum(valid_swt_a[f'Sch_{hour}']) if not valid_swt_a.empty else 0\n",
        "        route_swt_a = round(weighted_sum_a / total_buses_a, 2) if total_buses_a > 0 else None\n",
        "\n",
        "\n",
        "        # Calculate Route SWT for direction B\n",
        "        swt_b = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_B')]\n",
        "        valid_swt_b = swt_b[pd.notna(swt_b[f'SWT_{hour}'])]  # Filter out NaN values\n",
        "        weighted_sum_b = sum(valid_swt_b[f'SWT_{hour}'] * valid_swt_b[f'Sch_{hour}']) if not valid_swt_b.empty else 0\n",
        "        total_buses_b = sum(valid_swt_b[f'Sch_{hour}']) if not valid_swt_b.empty else 0\n",
        "        route_swt_b = round(weighted_sum_b / total_buses_b, 2) if total_buses_b > 0 else None\n",
        "\n",
        "        route_swt_data['Hour'].append(hour)\n",
        "        route_swt_data['Route SWT A'].append(route_swt_a)\n",
        "        route_swt_data['Route SWT B'].append(route_swt_b)\n",
        "\n",
        "    route_swt_df = pd.DataFrame(route_swt_data)\n",
        "\n",
        "    # Print the Route SWT DataFrame\n",
        "    print(\"\\n\\nRoute SWT DataFrame:\")\n",
        "    print(route_swt_df.to_string())\n",
        "\n",
        "# Assuming combined_df and lineID are defined and available\n",
        "# combined_df = ... (from previous code)\n",
        "# lineID = ... (from user input)\n",
        "main(combined_df, lineID)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KM-Xo9q1C8L",
        "outputId": "bb325a46-1a39-4a13-964a-a84c12520a85"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[4mToday is Thursday. The selected Schedule name is Mon-Fri Schooldays.\u001b[0m\n",
            "\n",
            "\n",
            "Route SWT DataFrame:\n",
            "    Hour  Route SWT A  Route SWT B\n",
            "0      0          NaN          NaN\n",
            "1      1          NaN          NaN\n",
            "2      2          NaN          NaN\n",
            "3      3          NaN          NaN\n",
            "4      4        30.00          NaN\n",
            "5      5        10.50        14.00\n",
            "6      6         9.55         8.75\n",
            "7      7         6.77         5.83\n",
            "8      8         6.36         5.53\n",
            "9      9         5.38         6.00\n",
            "10    10         5.83         6.00\n",
            "11    11         6.00         6.00\n",
            "12    12         6.00         6.00\n",
            "13    13         6.00         6.00\n",
            "14    14         5.68         5.68\n",
            "15    15         6.00         6.00\n",
            "16    16         5.83         6.18\n",
            "17    17         6.00         6.00\n",
            "18    18         5.68         6.00\n",
            "19    19         6.00         5.83\n",
            "20    20         8.75         8.40\n",
            "21    21         9.55        10.00\n",
            "22    22        10.00        10.00\n",
            "23    23         9.55         9.55\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZF4b3tBdZItNXvBASQvod",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}