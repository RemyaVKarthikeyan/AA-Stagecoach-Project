{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/18_07_2024_16_34_Timetable_and_SWT%2C_SWT_hr1%2C_SWT_hr2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFDa5DVspn8"
      },
      "source": [
        "18/07/2024"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Modify this path accordingly\n",
        "file_path = '/content/QSI points.xlsx'\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Get the lineID from the user\n",
        "lineID = input(\"Please enter the lineID: \")\n",
        "\n",
        "# Check if the necessary column is present\n",
        "if 'Route_Dir_QSI_No' not in df.columns:\n",
        "    print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "else:\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Create regular expressions for filtering\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for lineID_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for lineID_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "\n",
        "    # Function to fetch and process route sequence data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    matched_results_df_A = matched_results_df_A[matched_results_df_A['Route_Dir_QSI_No'].str.match(pattern_A)]\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    matched_results_df_B = matched_results_df_B[matched_results_df_B['Route_Dir_QSI_No'].str.match(pattern_B)]\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # Display the combined DataFrame\n",
        "    print(\"\\n\\n\\033[1m\\033[4mCombined QSI stop points for directions A and B\\033[0m\\n\")\n",
        "    print(combined_df[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1663648a-4098-4a5b-e0e3-c8e49baee809",
        "id": "7YH0gajXuMuI"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the lineID: 179\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction 179_A\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                            STOP_Name          ID\n",
            "0           179_A1                    Chingford Station  490001063C\n",
            "2           179_A2                          Friday Hill  490007021E\n",
            "3           179_A3      Woodford Green / Broadmead Road  490014847S\n",
            "4           179_A4               South Woodford Station  490015122C\n",
            "5           179_A5           Charlie Brown's Roundabout  490005002N\n",
            "7           179_A6  Gants Hill Station / Cranbrook Road  490015202N\n",
            "8           179_A7                       Ilford Station  490005699D\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction 179_B\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                            STOP_Name          ID\n",
            "0           179_B1                      Hainault Street  490007657W\n",
            "1           179_B2                       Ilford Station  490001157G\n",
            "2           179_B3  Gants Hill Station / Cranbrook Road  490015202M\n",
            "4           179_B4                        Southend Road  490012285S\n",
            "5           179_B5               South Woodford Station  490000217E\n",
            "7           179_B6      Woodford Green / Broadmead Road  490014847N\n",
            "8           179_B7             Kings Road / Friday Hill  490007021W\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mCombined QSI stop points for directions A and B\u001b[0m\n",
            "\n",
            "   Route_Dir_QSI_No                            STOP_Name          ID\n",
            "0            179_A1                    Chingford Station  490001063C\n",
            "1            179_A2                          Friday Hill  490007021E\n",
            "2            179_A3      Woodford Green / Broadmead Road  490014847S\n",
            "3            179_A4               South Woodford Station  490015122C\n",
            "4            179_A5           Charlie Brown's Roundabout  490005002N\n",
            "5            179_A6  Gants Hill Station / Cranbrook Road  490015202N\n",
            "6            179_A7                       Ilford Station  490005699D\n",
            "7            179_B1                      Hainault Street  490007657W\n",
            "8            179_B2                       Ilford Station  490001157G\n",
            "9            179_B3  Gants Hill Station / Cranbrook Road  490015202M\n",
            "10           179_B4                        Southend Road  490012285S\n",
            "11           179_B5               South Woodford Station  490000217E\n",
            "12           179_B6      Woodford Green / Broadmead Road  490014847N\n",
            "13           179_B7             Kings Road / Friday Hill  490007021W\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import time  # Import the time module for sleep functionality\n",
        "\n",
        "# Function to fetch data from the API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "            slots[hour].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# DataFrames to store SWT data\n",
        "swt_data = {\n",
        "    'Route_Dir_QSI_No': [],\n",
        "    'ID': [],\n",
        "    'SWT': [],\n",
        "    'No_Buses_Sch': [],\n",
        "    'SWT_hr1': [],\n",
        "    'No_Buses_Sch_hr1': [],\n",
        "    'SWT_hr2': [],\n",
        "    'No_Buses_Sch_hr2': []\n",
        "}\n",
        "\n",
        "# Fetch timetable for each stop point ID and calculate SWT\n",
        "bst = pytz.timezone('Europe/London')\n",
        "while True:\n",
        "    # Update current time and hour\n",
        "    current_time = datetime.now(bst)\n",
        "    current_hour = current_time.hour\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    # Store selected schedule name to ensure it's printed only once\n",
        "    selected_schedule_name = None\n",
        "    printed_schedule_name = False\n",
        "\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "        if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "            direction = 'outbound'\n",
        "        elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "            direction = 'inbound'\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "        data = fetch_data(url)\n",
        "\n",
        "        schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "        if not selected_schedule_name:\n",
        "            if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "                preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "            elif day_of_week.lower() == 'friday':\n",
        "                preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "            elif day_of_week.lower() == 'saturday':\n",
        "                preferred_schedule_names = ['Saturday']\n",
        "            elif day_of_week.lower() == 'sunday':\n",
        "                preferred_schedule_names = ['Sunday']\n",
        "            else:\n",
        "                preferred_schedule_names = [day_of_week]\n",
        "\n",
        "            for preferred_name in preferred_schedule_names:\n",
        "                if preferred_name in schedule_names_dict:\n",
        "                    selected_schedule_name = preferred_name\n",
        "                    break\n",
        "\n",
        "        if selected_schedule_name and not printed_schedule_name:\n",
        "            print(f\"\\n\\033[1m\\033[4mToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\\033[0m\")\n",
        "            printed_schedule_name = True\n",
        "\n",
        "        if selected_schedule_name:\n",
        "            timetable = schedule_names_dict[selected_schedule_name]\n",
        "            slots = categorize_into_slots(timetable)\n",
        "\n",
        "            # Calculate Scheduled Wait Time (SWT)\n",
        "            total_buses_this_hour = len(slots[current_hour])\n",
        "            scheduled_wait_time = 60 / (total_buses_this_hour * 2) if total_buses_this_hour > 0 else float('inf')\n",
        "            next_hour = (current_hour + 1) % 24  # Wrap around using modulo operator\n",
        "            total_buses_hr1 = len(slots[next_hour])\n",
        "            scheduled_wait_time_hr1 = 60 / (total_buses_hr1 * 2) if total_buses_hr1 > 0 else float('inf')\n",
        "            next_next_hour = (current_hour + 2) % 24  # Wrap around using modulo operator\n",
        "            total_buses_hr2 = len(slots[next_next_hour])\n",
        "            scheduled_wait_time_hr2 = 60 / (total_buses_hr2 * 2) if total_buses_hr2 > 0 else float('inf')\n",
        "\n",
        "            # Store SWT data\n",
        "            swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "            swt_data['ID'].append(stop_point_id)\n",
        "            swt_data['SWT'].append(scheduled_wait_time)\n",
        "            swt_data['No_Buses_Sch'].append(total_buses_this_hour)\n",
        "            swt_data['SWT_hr1'].append(scheduled_wait_time_hr1)\n",
        "            swt_data['No_Buses_Sch_hr1'].append(total_buses_hr1)\n",
        "            swt_data['SWT_hr2'].append(scheduled_wait_time_hr2)\n",
        "            swt_data['No_Buses_Sch_hr2'].append(total_buses_hr2)\n",
        "\n",
        "            #print (\"................................................................\\n\")\n",
        "            # Print Scheduled Wait Time rounded to two decimal places\n",
        "            #print(f\"\\nScheduled Wait Time (SWT) for stop point {stop_point_id}: {scheduled_wait_time:.2f} minutes\")\n",
        "\n",
        "            # Print number of buses scheduled for this hour at stop point\n",
        "            #print(f\"\\nNumber of buses scheduled for this hour at stop point {stop_point_id}: {total_buses_this_hour}\")\n",
        "\n",
        "            # Print timetable for the current hour\n",
        "            #print(f\"\\nTimetable for stop point {stop_point_id} at hour {current_hour}:\")\n",
        "            #for journey in slots[current_hour]:\n",
        "                #journey_hour = str(journey['hour']).zfill(2)\n",
        "                #journey_minute = str(journey['minute']).zfill(2)\n",
        "                #time_slot = f\"{journey_hour}:{journey_minute}\"\n",
        "                #print(f\"{time_slot}   {lineID}    {stop_point_id}  {direction.capitalize()}\")\n",
        "\n",
        "    # Create DataFrame for SWT data\n",
        "    swt_df = pd.DataFrame(swt_data)\n",
        "\n",
        "    # Print the SWT DataFrame\n",
        "    #print (\"\\n_____________________________________________\")\n",
        "    print(\"\\n\\nSWT DataFrame:\")\n",
        "    print(swt_df)\n",
        "    #print (\"_____________________________________________\\n\")\n",
        "    # Wait for the next hour (3600 seconds = 1 hour)\n",
        "    time.sleep(3600)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "f2531c0a-27b4-4b7a-d075-0bb32f1871b8",
        "id": "JoheEAL9dxAa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[4mToday is Thursday. The selected Schedule name is Mon-Fri Schooldays.\u001b[0m\n",
            "\n",
            "\n",
            "SWT DataFrame:\n",
            "   Route_Dir_QSI_No          ID  SWT  No_Buses_Sch  SWT_hr1  No_Buses_Sch_hr1  \\\n",
            "0            179_A1  490001063C  6.0             5      6.0                 5   \n",
            "1            179_A2  490007021E  6.0             5      6.0                 5   \n",
            "2            179_A3  490014847S  6.0             5      6.0                 5   \n",
            "3            179_A4  490015122C  5.0             6      6.0                 5   \n",
            "4            179_A5  490005002N  6.0             5      6.0                 5   \n",
            "5            179_A6  490015202N  6.0             5      6.0                 5   \n",
            "6            179_A7  490005699D  6.0             5      6.0                 5   \n",
            "7            179_B1  490007657W  7.5             4      6.0                 5   \n",
            "8            179_B2  490001157G  6.0             5      6.0                 5   \n",
            "9            179_B3  490015202M  6.0             5      6.0                 5   \n",
            "10           179_B4  490012285S  6.0             5      6.0                 5   \n",
            "11           179_B5  490000217E  6.0             5      6.0                 5   \n",
            "12           179_B6  490014847N  6.0             5      6.0                 5   \n",
            "13           179_B7  490007021W  6.0             5      6.0                 5   \n",
            "\n",
            "    SWT_hr2  No_Buses_Sch_hr2  \n",
            "0       6.0                 5  \n",
            "1       6.0                 5  \n",
            "2       5.0                 6  \n",
            "3       6.0                 5  \n",
            "4       5.0                 6  \n",
            "5       6.0                 5  \n",
            "6       6.0                 5  \n",
            "7       6.0                 5  \n",
            "8       6.0                 5  \n",
            "9       6.0                 5  \n",
            "10      6.0                 5  \n",
            "11      6.0                 5  \n",
            "12      6.0                 5  \n",
            "13      6.0                 5  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-47b4cc65ba72>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m#print (\"_____________________________________________\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# Wait for the next hour (3600 seconds = 1 hour)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhCEXHoLjZbO+Gcur8pJEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}