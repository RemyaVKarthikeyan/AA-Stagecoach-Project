{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9tULOPZNe9ghJBAafzGvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/16_Aug_2024_Final1_Prediction_steps_LF_17_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCIyhv0rUaia",
        "outputId": "62461082-5d55-4dd4-a648-bf20ac2f13ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Please enter the lineID: d7\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction D7_A\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                    STOP_Name          ID  Bus_Stop_Code\n",
            "0            D7_A1   Poplar / All Saints Church  490011107G          73923\n",
            "1            D7_A2               Stewart Street  490013513S          47950\n",
            "2            D7_A3       Island Gardens Station  490002048Z          76947\n",
            "3            D7_A4  Arnhem Wharf Primary School  490006092N          50948\n",
            "4            D7_A5         East India Dock Road  490004584N          47475\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction D7_B\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                    STOP_Name          ID  Bus_Stop_Code\n",
            "0            D7_B1  Mile End Station / Bow Road  490015151H          48439\n",
            "1            D7_B2         East India Dock Road  490004584S          56224\n",
            "2            D7_B3         Canary Wharf Station  490000038F          76008\n",
            "3            D7_B4  Arnhem Wharf Primary School  490006092S          72536\n",
            "4            D7_B5       Island Gardens Station  490002048X          51363\n",
            "5            D7_B6               Stewart Street  490013513N          49166\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mCombined QSI stop points for directions A and B\u001b[0m\n",
            "\n",
            "   Route_Dir_QSI_No                    STOP_Name          ID  Bus_Stop_Code\n",
            "0             D7_A1   Poplar / All Saints Church  490011107G          73923\n",
            "1             D7_A2               Stewart Street  490013513S          47950\n",
            "2             D7_A3       Island Gardens Station  490002048Z          76947\n",
            "3             D7_A4  Arnhem Wharf Primary School  490006092N          50948\n",
            "4             D7_A5         East India Dock Road  490004584N          47475\n",
            "5             D7_B1  Mile End Station / Bow Road  490015151H          48439\n",
            "6             D7_B2         East India Dock Road  490004584S          56224\n",
            "7             D7_B3         Canary Wharf Station  490000038F          76008\n",
            "8             D7_B4  Arnhem Wharf Primary School  490006092S          72536\n",
            "9             D7_B5       Island Gardens Station  490002048X          51363\n",
            "10            D7_B6               Stewart Street  490013513N          49166\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "from datetime import datetime, timedelta, time as dt_time\n",
        "import pytz\n",
        "import time\n",
        "from difflib import SequenceMatcher\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from datetime import datetime, time as dt_time\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read the Excel file\n",
        "excel_file_path = '/content/drive/MyDrive/Files/QSI points.xlsx'\n",
        "df = pd.read_excel(excel_file_path)\n",
        "df_sheet2 = pd.read_excel(excel_file_path, sheet_name='Sheet2')\n",
        "output_dir = '/content/drive/My Drive/Files/'\n",
        "\n",
        "# Load the training data from Google Drive\n",
        "file_path_train = '/content/drive/My Drive/Files/Training_set.csv'\n",
        "df_train = pd.read_csv(file_path_train)\n",
        "\n",
        "# Get the lineID from the user\n",
        "lineID = input(\"Please enter the lineID: \")\n",
        "\n",
        "# Check if the necessary column is present\n",
        "if 'Route_Dir_QSI_No' not in df.columns:\n",
        "    print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "else:\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Create regular expressions for filtering\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for lineID_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for lineID_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "\n",
        "    # Function to fetch and process route data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Read the bus-stops.csv file\n",
        "    #bus_stops_file_path = '/content/drive/MyDrive/Report/bus-stops.csv'\n",
        "    bus_stops_df = pd.read_excel(excel_file_path, sheet_name='Sheet3')\n",
        "\n",
        "    # Normalize the stop names in the bus stops DataFrame\n",
        "    bus_stops_df['Stop_Name'] = bus_stops_df['Stop_Name'].apply(normalize_stop_name)\n",
        "\n",
        "    # Match QSI point IDs with bus stop codes\n",
        "    def match_qsi_with_bus_stops(matched_df, bus_stops_df):\n",
        "        matched_results = []\n",
        "        for index, row in matched_df.iterrows():\n",
        "            stop_id = row['ID']\n",
        "            matched_stop = bus_stops_df[bus_stops_df['Naptan_Atco'] == stop_id]\n",
        "            if not matched_stop.empty:\n",
        "                bus_stop_code = matched_stop.iloc[0]['Bus_Stop_Code']\n",
        "                matched_results.append({\n",
        "                    'Route_Dir_QSI_No': row['Route_Dir_QSI_No'],\n",
        "                    'STOP_Name': row['STOP_Name'],\n",
        "                    'ID': row['ID'],\n",
        "                    'Bus_Stop_Code': bus_stop_code\n",
        "                })\n",
        "        return pd.DataFrame(matched_results)\n",
        "\n",
        "    # Perform the matching for direction A\n",
        "    matched_results_df_A = match_qsi_with_bus_stops(matched_results_df_A, bus_stops_df)\n",
        "\n",
        "    # Perform the matching for direction B\n",
        "    matched_results_df_B = match_qsi_with_bus_stops(matched_results_df_B, bus_stops_df)\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID', 'Bus_Stop_Code']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID', 'Bus_Stop_Code']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # Display the combined DataFrame\n",
        "    print(\"\\n\\n\\033[1m\\033[4mCombined QSI stop points for directions A and B\\033[0m\\n\")\n",
        "    print(combined_df[['Route_Dir_QSI_No', 'STOP_Name', 'ID', 'Bus_Stop_Code']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Function to fetch data from the TfL API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "            slots[hour].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# Function to select the preferred schedule name based on the current day of the week\n",
        "def select_preferred_schedule(schedule_names_dict, day_of_week):\n",
        "    if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "    elif day_of_week.lower() == 'friday':\n",
        "        preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "    elif day_of_week.lower() == 'saturday':\n",
        "        preferred_schedule_names = ['Saturday']\n",
        "    elif day_of_week.lower() == 'sunday':\n",
        "        preferred_schedule_names = ['Sunday']\n",
        "    else:\n",
        "        preferred_schedule_names = [day_of_week]\n",
        "\n",
        "    for preferred_name in preferred_schedule_names:\n",
        "        if preferred_name in schedule_names_dict:\n",
        "            return preferred_name\n",
        "    return None\n",
        "\n",
        "\n",
        "# Function to display the timetable for each stop point\n",
        "def display_timetable_for_stop_points(combined_df, lineID):\n",
        "    timetable_dict = {}\n",
        "\n",
        "    # Fetch the current time in BST\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    current_hour = now.hour\n",
        "    current_minute = now.minute\n",
        "\n",
        "    # Get the current day of the week\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "        stop_name = row['STOP_Name']\n",
        "\n",
        "        # Determine the direction\n",
        "        if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "            direction = 'outbound'\n",
        "        elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "            direction = 'inbound'\n",
        "        else:\n",
        "            continue  # Skip if direction cannot be determined\n",
        "\n",
        "        # Fetch timetable data for the stop point\n",
        "        url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "        data = fetch_data(url)\n",
        "\n",
        "        # Extract schedule names\n",
        "        schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "        # Select the preferred schedule name based on the current day of the week\n",
        "\n",
        "        selected_schedule_name = select_preferred_schedule(schedule_names_dict, day_of_week)\n",
        "\n",
        "        if selected_schedule_name:\n",
        "            # Categorize the timetable into hourly slots\n",
        "            timetable = schedule_names_dict[selected_schedule_name]\n",
        "            slots = categorize_into_slots(timetable)\n",
        "\n",
        "            # Prepare a DataFrame for the timetable for the specified hours\n",
        "            timetable_list = []\n",
        "\n",
        "            for hour in range(24):\n",
        "                for journey in slots[hour]:\n",
        "                    journey_hour = str(journey['hour']).zfill(2)\n",
        "                    journey_minute = str(journey['minute']).zfill(2)\n",
        "                    time = f\"{journey_hour}:{journey_minute}\"\n",
        "                    timetable_list.append({\n",
        "                        'Line': lineID,\n",
        "                        #'Stop Point': stop_name,\n",
        "                        'Stop Point ID': stop_point_id,\n",
        "                        'Direction': direction,\n",
        "                        'Scheduled Time': time\n",
        "                    })\n",
        "\n",
        "            timetable_df = pd.DataFrame(timetable_list)\n",
        "            timetable_dict[stop_point_id] = timetable_df\n",
        "\n",
        "    return timetable_dict\n",
        "\n",
        "\n",
        "# Display the timetable\n",
        "timetable_dict = display_timetable_for_stop_points(combined_df, lineID)\n",
        "\n",
        "\n",
        "# Save the timetable dictionary to files\n",
        "for stop_point_id, timetable_df in timetable_dict.items():\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    timetable_df.to_csv(f'{output_dir}timetable_{stop_point_id}.csv', index=False)\n",
        "    # Save the DataFrame to a CSV file\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mTimetable for {stop_point_id}:\\033[0m\\n\")\n",
        "    print(timetable_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB38NxJzPA-s",
        "outputId": "9a49de3b-649d-4140-8054-6b17a1b3ca8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490011107G:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490011107G  outbound          04:32\n",
            "  D7    490011107G  outbound          04:52\n",
            "  D7    490011107G  outbound          05:12\n",
            "  D7    490011107G  outbound          05:32\n",
            "  D7    490011107G  outbound          05:52\n",
            "  D7    490011107G  outbound          06:07\n",
            "  D7    490011107G  outbound          06:22\n",
            "  D7    490011107G  outbound          06:32\n",
            "  D7    490011107G  outbound          06:43\n",
            "  D7    490011107G  outbound          06:54\n",
            "  D7    490011107G  outbound          07:05\n",
            "  D7    490011107G  outbound          07:16\n",
            "  D7    490011107G  outbound          07:27\n",
            "  D7    490011107G  outbound          07:38\n",
            "  D7    490011107G  outbound          07:49\n",
            "  D7    490011107G  outbound          08:00\n",
            "  D7    490011107G  outbound          08:11\n",
            "  D7    490011107G  outbound          08:22\n",
            "  D7    490011107G  outbound          08:33\n",
            "  D7    490011107G  outbound          08:45\n",
            "  D7    490011107G  outbound          08:57\n",
            "  D7    490011107G  outbound          09:09\n",
            "  D7    490011107G  outbound          09:21\n",
            "  D7    490011107G  outbound          09:33\n",
            "  D7    490011107G  outbound          09:45\n",
            "  D7    490011107G  outbound          09:57\n",
            "  D7    490011107G  outbound          10:09\n",
            "  D7    490011107G  outbound          10:21\n",
            "  D7    490011107G  outbound          10:33\n",
            "  D7    490011107G  outbound          10:45\n",
            "  D7    490011107G  outbound          10:57\n",
            "  D7    490011107G  outbound          11:09\n",
            "  D7    490011107G  outbound          11:21\n",
            "  D7    490011107G  outbound          11:33\n",
            "  D7    490011107G  outbound          11:45\n",
            "  D7    490011107G  outbound          11:57\n",
            "  D7    490011107G  outbound          12:09\n",
            "  D7    490011107G  outbound          12:21\n",
            "  D7    490011107G  outbound          12:33\n",
            "  D7    490011107G  outbound          12:45\n",
            "  D7    490011107G  outbound          12:57\n",
            "  D7    490011107G  outbound          13:09\n",
            "  D7    490011107G  outbound          13:21\n",
            "  D7    490011107G  outbound          13:33\n",
            "  D7    490011107G  outbound          13:45\n",
            "  D7    490011107G  outbound          13:58\n",
            "  D7    490011107G  outbound          14:10\n",
            "  D7    490011107G  outbound          14:22\n",
            "  D7    490011107G  outbound          14:34\n",
            "  D7    490011107G  outbound          14:46\n",
            "  D7    490011107G  outbound          14:57\n",
            "  D7    490011107G  outbound          15:08\n",
            "  D7    490011107G  outbound          15:19\n",
            "  D7    490011107G  outbound          15:31\n",
            "  D7    490011107G  outbound          15:43\n",
            "  D7    490011107G  outbound          15:55\n",
            "  D7    490011107G  outbound          16:07\n",
            "  D7    490011107G  outbound          16:19\n",
            "  D7    490011107G  outbound          16:31\n",
            "  D7    490011107G  outbound          16:43\n",
            "  D7    490011107G  outbound          16:55\n",
            "  D7    490011107G  outbound          17:07\n",
            "  D7    490011107G  outbound          17:19\n",
            "  D7    490011107G  outbound          17:31\n",
            "  D7    490011107G  outbound          17:43\n",
            "  D7    490011107G  outbound          17:55\n",
            "  D7    490011107G  outbound          18:07\n",
            "  D7    490011107G  outbound          18:19\n",
            "  D7    490011107G  outbound          18:31\n",
            "  D7    490011107G  outbound          18:43\n",
            "  D7    490011107G  outbound          18:55\n",
            "  D7    490011107G  outbound          19:07\n",
            "  D7    490011107G  outbound          19:19\n",
            "  D7    490011107G  outbound          19:31\n",
            "  D7    490011107G  outbound          19:43\n",
            "  D7    490011107G  outbound          19:55\n",
            "  D7    490011107G  outbound          20:08\n",
            "  D7    490011107G  outbound          20:21\n",
            "  D7    490011107G  outbound          20:34\n",
            "  D7    490011107G  outbound          20:49\n",
            "  D7    490011107G  outbound          21:05\n",
            "  D7    490011107G  outbound          21:21\n",
            "  D7    490011107G  outbound          21:36\n",
            "  D7    490011107G  outbound          21:52\n",
            "  D7    490011107G  outbound          22:08\n",
            "  D7    490011107G  outbound          22:24\n",
            "  D7    490011107G  outbound          22:40\n",
            "  D7    490011107G  outbound          22:55\n",
            "  D7    490011107G  outbound          23:10\n",
            "  D7    490011107G  outbound          23:25\n",
            "  D7    490011107G  outbound          23:40\n",
            "  D7    490011107G  outbound          23:55\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490013513S:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490013513S  outbound          04:36\n",
            "  D7    490013513S  outbound          04:56\n",
            "  D7    490013513S  outbound          05:16\n",
            "  D7    490013513S  outbound          05:36\n",
            "  D7    490013513S  outbound          05:56\n",
            "  D7    490013513S  outbound          06:11\n",
            "  D7    490013513S  outbound          06:26\n",
            "  D7    490013513S  outbound          06:36\n",
            "  D7    490013513S  outbound          06:47\n",
            "  D7    490013513S  outbound          06:58\n",
            "  D7    490013513S  outbound          07:10\n",
            "  D7    490013513S  outbound          07:21\n",
            "  D7    490013513S  outbound          07:32\n",
            "  D7    490013513S  outbound          07:43\n",
            "  D7    490013513S  outbound          07:54\n",
            "  D7    490013513S  outbound          08:06\n",
            "  D7    490013513S  outbound          08:17\n",
            "  D7    490013513S  outbound          08:28\n",
            "  D7    490013513S  outbound          08:40\n",
            "  D7    490013513S  outbound          08:52\n",
            "  D7    490013513S  outbound          09:04\n",
            "  D7    490013513S  outbound          09:16\n",
            "  D7    490013513S  outbound          09:28\n",
            "  D7    490013513S  outbound          09:40\n",
            "  D7    490013513S  outbound          09:51\n",
            "  D7    490013513S  outbound          10:03\n",
            "  D7    490013513S  outbound          10:15\n",
            "  D7    490013513S  outbound          10:26\n",
            "  D7    490013513S  outbound          10:38\n",
            "  D7    490013513S  outbound          10:50\n",
            "  D7    490013513S  outbound          11:02\n",
            "  D7    490013513S  outbound          11:14\n",
            "  D7    490013513S  outbound          11:26\n",
            "  D7    490013513S  outbound          11:38\n",
            "  D7    490013513S  outbound          11:50\n",
            "  D7    490013513S  outbound          12:02\n",
            "  D7    490013513S  outbound          12:14\n",
            "  D7    490013513S  outbound          12:26\n",
            "  D7    490013513S  outbound          12:38\n",
            "  D7    490013513S  outbound          12:50\n",
            "  D7    490013513S  outbound          13:02\n",
            "  D7    490013513S  outbound          13:14\n",
            "  D7    490013513S  outbound          13:26\n",
            "  D7    490013513S  outbound          13:38\n",
            "  D7    490013513S  outbound          13:50\n",
            "  D7    490013513S  outbound          14:03\n",
            "  D7    490013513S  outbound          14:15\n",
            "  D7    490013513S  outbound          14:27\n",
            "  D7    490013513S  outbound          14:40\n",
            "  D7    490013513S  outbound          14:52\n",
            "  D7    490013513S  outbound          15:03\n",
            "  D7    490013513S  outbound          15:14\n",
            "  D7    490013513S  outbound          15:26\n",
            "  D7    490013513S  outbound          15:38\n",
            "  D7    490013513S  outbound          15:50\n",
            "  D7    490013513S  outbound          16:02\n",
            "  D7    490013513S  outbound          16:14\n",
            "  D7    490013513S  outbound          16:26\n",
            "  D7    490013513S  outbound          16:38\n",
            "  D7    490013513S  outbound          16:50\n",
            "  D7    490013513S  outbound          17:02\n",
            "  D7    490013513S  outbound          17:14\n",
            "  D7    490013513S  outbound          17:26\n",
            "  D7    490013513S  outbound          17:38\n",
            "  D7    490013513S  outbound          17:50\n",
            "  D7    490013513S  outbound          18:02\n",
            "  D7    490013513S  outbound          18:14\n",
            "  D7    490013513S  outbound          18:26\n",
            "  D7    490013513S  outbound          18:37\n",
            "  D7    490013513S  outbound          18:49\n",
            "  D7    490013513S  outbound          19:01\n",
            "  D7    490013513S  outbound          19:13\n",
            "  D7    490013513S  outbound          19:25\n",
            "  D7    490013513S  outbound          19:37\n",
            "  D7    490013513S  outbound          19:49\n",
            "  D7    490013513S  outbound          20:01\n",
            "  D7    490013513S  outbound          20:13\n",
            "  D7    490013513S  outbound          20:26\n",
            "  D7    490013513S  outbound          20:39\n",
            "  D7    490013513S  outbound          20:54\n",
            "  D7    490013513S  outbound          21:10\n",
            "  D7    490013513S  outbound          21:26\n",
            "  D7    490013513S  outbound          21:41\n",
            "  D7    490013513S  outbound          21:57\n",
            "  D7    490013513S  outbound          22:12\n",
            "  D7    490013513S  outbound          22:28\n",
            "  D7    490013513S  outbound          22:44\n",
            "  D7    490013513S  outbound          22:59\n",
            "  D7    490013513S  outbound          23:14\n",
            "  D7    490013513S  outbound          23:29\n",
            "  D7    490013513S  outbound          23:44\n",
            "  D7    490013513S  outbound          23:59\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490002048Z:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490002048Z  outbound          04:39\n",
            "  D7    490002048Z  outbound          04:59\n",
            "  D7    490002048Z  outbound          05:19\n",
            "  D7    490002048Z  outbound          05:39\n",
            "  D7    490002048Z  outbound          05:59\n",
            "  D7    490002048Z  outbound          06:15\n",
            "  D7    490002048Z  outbound          06:30\n",
            "  D7    490002048Z  outbound          06:40\n",
            "  D7    490002048Z  outbound          06:51\n",
            "  D7    490002048Z  outbound          07:02\n",
            "  D7    490002048Z  outbound          07:14\n",
            "  D7    490002048Z  outbound          07:25\n",
            "  D7    490002048Z  outbound          07:37\n",
            "  D7    490002048Z  outbound          07:48\n",
            "  D7    490002048Z  outbound          07:59\n",
            "  D7    490002048Z  outbound          08:11\n",
            "  D7    490002048Z  outbound          08:23\n",
            "  D7    490002048Z  outbound          08:35\n",
            "  D7    490002048Z  outbound          08:47\n",
            "  D7    490002048Z  outbound          08:59\n",
            "  D7    490002048Z  outbound          09:11\n",
            "  D7    490002048Z  outbound          09:22\n",
            "  D7    490002048Z  outbound          09:34\n",
            "  D7    490002048Z  outbound          09:45\n",
            "  D7    490002048Z  outbound          09:56\n",
            "  D7    490002048Z  outbound          10:08\n",
            "  D7    490002048Z  outbound          10:20\n",
            "  D7    490002048Z  outbound          10:31\n",
            "  D7    490002048Z  outbound          10:43\n",
            "  D7    490002048Z  outbound          10:55\n",
            "  D7    490002048Z  outbound          11:07\n",
            "  D7    490002048Z  outbound          11:19\n",
            "  D7    490002048Z  outbound          11:31\n",
            "  D7    490002048Z  outbound          11:43\n",
            "  D7    490002048Z  outbound          11:55\n",
            "  D7    490002048Z  outbound          12:07\n",
            "  D7    490002048Z  outbound          12:19\n",
            "  D7    490002048Z  outbound          12:31\n",
            "  D7    490002048Z  outbound          12:43\n",
            "  D7    490002048Z  outbound          12:55\n",
            "  D7    490002048Z  outbound          13:08\n",
            "  D7    490002048Z  outbound          13:20\n",
            "  D7    490002048Z  outbound          13:32\n",
            "  D7    490002048Z  outbound          13:44\n",
            "  D7    490002048Z  outbound          13:56\n",
            "  D7    490002048Z  outbound          14:08\n",
            "  D7    490002048Z  outbound          14:20\n",
            "  D7    490002048Z  outbound          14:32\n",
            "  D7    490002048Z  outbound          14:45\n",
            "  D7    490002048Z  outbound          14:57\n",
            "  D7    490002048Z  outbound          15:08\n",
            "  D7    490002048Z  outbound          15:20\n",
            "  D7    490002048Z  outbound          15:32\n",
            "  D7    490002048Z  outbound          15:44\n",
            "  D7    490002048Z  outbound          15:56\n",
            "  D7    490002048Z  outbound          16:08\n",
            "  D7    490002048Z  outbound          16:20\n",
            "  D7    490002048Z  outbound          16:32\n",
            "  D7    490002048Z  outbound          16:44\n",
            "  D7    490002048Z  outbound          16:56\n",
            "  D7    490002048Z  outbound          17:08\n",
            "  D7    490002048Z  outbound          17:19\n",
            "  D7    490002048Z  outbound          17:31\n",
            "  D7    490002048Z  outbound          17:43\n",
            "  D7    490002048Z  outbound          17:55\n",
            "  D7    490002048Z  outbound          18:07\n",
            "  D7    490002048Z  outbound          18:19\n",
            "  D7    490002048Z  outbound          18:31\n",
            "  D7    490002048Z  outbound          18:42\n",
            "  D7    490002048Z  outbound          18:54\n",
            "  D7    490002048Z  outbound          19:06\n",
            "  D7    490002048Z  outbound          19:18\n",
            "  D7    490002048Z  outbound          19:30\n",
            "  D7    490002048Z  outbound          19:41\n",
            "  D7    490002048Z  outbound          19:53\n",
            "  D7    490002048Z  outbound          20:05\n",
            "  D7    490002048Z  outbound          20:17\n",
            "  D7    490002048Z  outbound          20:30\n",
            "  D7    490002048Z  outbound          20:43\n",
            "  D7    490002048Z  outbound          20:58\n",
            "  D7    490002048Z  outbound          21:14\n",
            "  D7    490002048Z  outbound          21:30\n",
            "  D7    490002048Z  outbound          21:45\n",
            "  D7    490002048Z  outbound          22:01\n",
            "  D7    490002048Z  outbound          22:16\n",
            "  D7    490002048Z  outbound          22:32\n",
            "  D7    490002048Z  outbound          22:48\n",
            "  D7    490002048Z  outbound          23:03\n",
            "  D7    490002048Z  outbound          23:17\n",
            "  D7    490002048Z  outbound          23:32\n",
            "  D7    490002048Z  outbound          23:47\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490006092N:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490006092N  outbound          04:42\n",
            "  D7    490006092N  outbound          05:02\n",
            "  D7    490006092N  outbound          05:22\n",
            "  D7    490006092N  outbound          05:42\n",
            "  D7    490006092N  outbound          06:03\n",
            "  D7    490006092N  outbound          06:19\n",
            "  D7    490006092N  outbound          06:34\n",
            "  D7    490006092N  outbound          06:45\n",
            "  D7    490006092N  outbound          06:56\n",
            "  D7    490006092N  outbound          07:07\n",
            "  D7    490006092N  outbound          07:19\n",
            "  D7    490006092N  outbound          07:31\n",
            "  D7    490006092N  outbound          07:43\n",
            "  D7    490006092N  outbound          07:54\n",
            "  D7    490006092N  outbound          08:06\n",
            "  D7    490006092N  outbound          08:18\n",
            "  D7    490006092N  outbound          08:30\n",
            "  D7    490006092N  outbound          08:42\n",
            "  D7    490006092N  outbound          08:54\n",
            "  D7    490006092N  outbound          09:06\n",
            "  D7    490006092N  outbound          09:17\n",
            "  D7    490006092N  outbound          09:28\n",
            "  D7    490006092N  outbound          09:40\n",
            "  D7    490006092N  outbound          09:51\n",
            "  D7    490006092N  outbound          10:02\n",
            "  D7    490006092N  outbound          10:14\n",
            "  D7    490006092N  outbound          10:25\n",
            "  D7    490006092N  outbound          10:36\n",
            "  D7    490006092N  outbound          10:48\n",
            "  D7    490006092N  outbound          11:00\n",
            "  D7    490006092N  outbound          11:12\n",
            "  D7    490006092N  outbound          11:24\n",
            "  D7    490006092N  outbound          11:36\n",
            "  D7    490006092N  outbound          11:48\n",
            "  D7    490006092N  outbound          12:00\n",
            "  D7    490006092N  outbound          12:12\n",
            "  D7    490006092N  outbound          12:24\n",
            "  D7    490006092N  outbound          12:36\n",
            "  D7    490006092N  outbound          12:48\n",
            "  D7    490006092N  outbound          13:00\n",
            "  D7    490006092N  outbound          13:13\n",
            "  D7    490006092N  outbound          13:25\n",
            "  D7    490006092N  outbound          13:37\n",
            "  D7    490006092N  outbound          13:49\n",
            "  D7    490006092N  outbound          14:01\n",
            "  D7    490006092N  outbound          14:13\n",
            "  D7    490006092N  outbound          14:25\n",
            "  D7    490006092N  outbound          14:37\n",
            "  D7    490006092N  outbound          14:50\n",
            "  D7    490006092N  outbound          15:02\n",
            "  D7    490006092N  outbound          15:14\n",
            "  D7    490006092N  outbound          15:26\n",
            "  D7    490006092N  outbound          15:38\n",
            "  D7    490006092N  outbound          15:50\n",
            "  D7    490006092N  outbound          16:02\n",
            "  D7    490006092N  outbound          16:14\n",
            "  D7    490006092N  outbound          16:26\n",
            "  D7    490006092N  outbound          16:38\n",
            "  D7    490006092N  outbound          16:50\n",
            "  D7    490006092N  outbound          17:02\n",
            "  D7    490006092N  outbound          17:14\n",
            "  D7    490006092N  outbound          17:25\n",
            "  D7    490006092N  outbound          17:37\n",
            "  D7    490006092N  outbound          17:49\n",
            "  D7    490006092N  outbound          18:01\n",
            "  D7    490006092N  outbound          18:13\n",
            "  D7    490006092N  outbound          18:25\n",
            "  D7    490006092N  outbound          18:37\n",
            "  D7    490006092N  outbound          18:48\n",
            "  D7    490006092N  outbound          19:00\n",
            "  D7    490006092N  outbound          19:12\n",
            "  D7    490006092N  outbound          19:24\n",
            "  D7    490006092N  outbound          19:35\n",
            "  D7    490006092N  outbound          19:46\n",
            "  D7    490006092N  outbound          19:58\n",
            "  D7    490006092N  outbound          20:10\n",
            "  D7    490006092N  outbound          20:22\n",
            "  D7    490006092N  outbound          20:35\n",
            "  D7    490006092N  outbound          20:47\n",
            "  D7    490006092N  outbound          21:02\n",
            "  D7    490006092N  outbound          21:18\n",
            "  D7    490006092N  outbound          21:34\n",
            "  D7    490006092N  outbound          21:49\n",
            "  D7    490006092N  outbound          22:05\n",
            "  D7    490006092N  outbound          22:20\n",
            "  D7    490006092N  outbound          22:35\n",
            "  D7    490006092N  outbound          22:51\n",
            "  D7    490006092N  outbound          23:06\n",
            "  D7    490006092N  outbound          23:20\n",
            "  D7    490006092N  outbound          23:35\n",
            "  D7    490006092N  outbound          23:50\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490004584N:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490004584N  outbound          04:53\n",
            "  D7    490004584N  outbound          05:13\n",
            "  D7    490004584N  outbound          05:33\n",
            "  D7    490004584N  outbound          05:54\n",
            "  D7    490004584N  outbound          06:15\n",
            "  D7    490004584N  outbound          06:31\n",
            "  D7    490004584N  outbound          06:46\n",
            "  D7    490004584N  outbound          06:58\n",
            "  D7    490004584N  outbound          07:11\n",
            "  D7    490004584N  outbound          07:23\n",
            "  D7    490004584N  outbound          07:35\n",
            "  D7    490004584N  outbound          07:47\n",
            "  D7    490004584N  outbound          07:59\n",
            "  D7    490004584N  outbound          08:12\n",
            "  D7    490004584N  outbound          08:24\n",
            "  D7    490004584N  outbound          08:36\n",
            "  D7    490004584N  outbound          08:48\n",
            "  D7    490004584N  outbound          09:00\n",
            "  D7    490004584N  outbound          09:12\n",
            "  D7    490004584N  outbound          09:24\n",
            "  D7    490004584N  outbound          09:35\n",
            "  D7    490004584N  outbound          09:46\n",
            "  D7    490004584N  outbound          09:57\n",
            "  D7    490004584N  outbound          10:08\n",
            "  D7    490004584N  outbound          10:19\n",
            "  D7    490004584N  outbound          10:30\n",
            "  D7    490004584N  outbound          10:41\n",
            "  D7    490004584N  outbound          10:52\n",
            "  D7    490004584N  outbound          11:04\n",
            "  D7    490004584N  outbound          11:16\n",
            "  D7    490004584N  outbound          11:28\n",
            "  D7    490004584N  outbound          11:40\n",
            "  D7    490004584N  outbound          11:52\n",
            "  D7    490004584N  outbound          12:04\n",
            "  D7    490004584N  outbound          12:16\n",
            "  D7    490004584N  outbound          12:28\n",
            "  D7    490004584N  outbound          12:40\n",
            "  D7    490004584N  outbound          12:52\n",
            "  D7    490004584N  outbound          13:04\n",
            "  D7    490004584N  outbound          13:16\n",
            "  D7    490004584N  outbound          13:29\n",
            "  D7    490004584N  outbound          13:41\n",
            "  D7    490004584N  outbound          13:53\n",
            "  D7    490004584N  outbound          14:05\n",
            "  D7    490004584N  outbound          14:17\n",
            "  D7    490004584N  outbound          14:29\n",
            "  D7    490004584N  outbound          14:41\n",
            "  D7    490004584N  outbound          14:53\n",
            "  D7    490004584N  outbound          15:06\n",
            "  D7    490004584N  outbound          15:19\n",
            "  D7    490004584N  outbound          15:31\n",
            "  D7    490004584N  outbound          15:43\n",
            "  D7    490004584N  outbound          15:55\n",
            "  D7    490004584N  outbound          16:07\n",
            "  D7    490004584N  outbound          16:19\n",
            "  D7    490004584N  outbound          16:31\n",
            "  D7    490004584N  outbound          16:43\n",
            "  D7    490004584N  outbound          16:55\n",
            "  D7    490004584N  outbound          17:07\n",
            "  D7    490004584N  outbound          17:19\n",
            "  D7    490004584N  outbound          17:31\n",
            "  D7    490004584N  outbound          17:43\n",
            "  D7    490004584N  outbound          17:55\n",
            "  D7    490004584N  outbound          18:07\n",
            "  D7    490004584N  outbound          18:19\n",
            "  D7    490004584N  outbound          18:31\n",
            "  D7    490004584N  outbound          18:43\n",
            "  D7    490004584N  outbound          18:54\n",
            "  D7    490004584N  outbound          19:05\n",
            "  D7    490004584N  outbound          19:17\n",
            "  D7    490004584N  outbound          19:28\n",
            "  D7    490004584N  outbound          19:39\n",
            "  D7    490004584N  outbound          19:50\n",
            "  D7    490004584N  outbound          20:01\n",
            "  D7    490004584N  outbound          20:13\n",
            "  D7    490004584N  outbound          20:25\n",
            "  D7    490004584N  outbound          20:37\n",
            "  D7    490004584N  outbound          20:49\n",
            "  D7    490004584N  outbound          21:01\n",
            "  D7    490004584N  outbound          21:16\n",
            "  D7    490004584N  outbound          21:32\n",
            "  D7    490004584N  outbound          21:47\n",
            "  D7    490004584N  outbound          22:02\n",
            "  D7    490004584N  outbound          22:17\n",
            "  D7    490004584N  outbound          22:32\n",
            "  D7    490004584N  outbound          22:47\n",
            "  D7    490004584N  outbound          23:03\n",
            "  D7    490004584N  outbound          23:18\n",
            "  D7    490004584N  outbound          23:32\n",
            "  D7    490004584N  outbound          23:47\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490015151H:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490015151H   inbound          05:05\n",
            "  D7    490015151H   inbound          05:25\n",
            "  D7    490015151H   inbound          05:45\n",
            "  D7    490015151H   inbound          06:05\n",
            "  D7    490015151H   inbound          06:25\n",
            "  D7    490015151H   inbound          06:40\n",
            "  D7    490015151H   inbound          06:54\n",
            "  D7    490015151H   inbound          07:05\n",
            "  D7    490015151H   inbound          07:15\n",
            "  D7    490015151H   inbound          07:25\n",
            "  D7    490015151H   inbound          07:35\n",
            "  D7    490015151H   inbound          07:45\n",
            "  D7    490015151H   inbound          07:55\n",
            "  D7    490015151H   inbound          08:05\n",
            "  D7    490015151H   inbound          08:17\n",
            "  D7    490015151H   inbound          08:29\n",
            "  D7    490015151H   inbound          08:42\n",
            "  D7    490015151H   inbound          08:55\n",
            "  D7    490015151H   inbound          09:08\n",
            "  D7    490015151H   inbound          09:21\n",
            "  D7    490015151H   inbound          09:33\n",
            "  D7    490015151H   inbound          09:45\n",
            "  D7    490015151H   inbound          09:57\n",
            "  D7    490015151H   inbound          10:09\n",
            "  D7    490015151H   inbound          10:21\n",
            "  D7    490015151H   inbound          10:33\n",
            "  D7    490015151H   inbound          10:45\n",
            "  D7    490015151H   inbound          10:57\n",
            "  D7    490015151H   inbound          11:09\n",
            "  D7    490015151H   inbound          11:21\n",
            "  D7    490015151H   inbound          11:33\n",
            "  D7    490015151H   inbound          11:45\n",
            "  D7    490015151H   inbound          11:57\n",
            "  D7    490015151H   inbound          12:09\n",
            "  D7    490015151H   inbound          12:21\n",
            "  D7    490015151H   inbound          12:33\n",
            "  D7    490015151H   inbound          12:45\n",
            "  D7    490015151H   inbound          12:57\n",
            "  D7    490015151H   inbound          13:09\n",
            "  D7    490015151H   inbound          13:21\n",
            "  D7    490015151H   inbound          13:33\n",
            "  D7    490015151H   inbound          13:45\n",
            "  D7    490015151H   inbound          13:57\n",
            "  D7    490015151H   inbound          14:09\n",
            "  D7    490015151H   inbound          14:20\n",
            "  D7    490015151H   inbound          14:31\n",
            "  D7    490015151H   inbound          14:41\n",
            "  D7    490015151H   inbound          14:51\n",
            "  D7    490015151H   inbound          15:02\n",
            "  D7    490015151H   inbound          15:13\n",
            "  D7    490015151H   inbound          15:25\n",
            "  D7    490015151H   inbound          15:37\n",
            "  D7    490015151H   inbound          15:49\n",
            "  D7    490015151H   inbound          16:01\n",
            "  D7    490015151H   inbound          16:13\n",
            "  D7    490015151H   inbound          16:25\n",
            "  D7    490015151H   inbound          16:37\n",
            "  D7    490015151H   inbound          16:49\n",
            "  D7    490015151H   inbound          17:01\n",
            "  D7    490015151H   inbound          17:13\n",
            "  D7    490015151H   inbound          17:26\n",
            "  D7    490015151H   inbound          17:39\n",
            "  D7    490015151H   inbound          17:51\n",
            "  D7    490015151H   inbound          18:03\n",
            "  D7    490015151H   inbound          18:15\n",
            "  D7    490015151H   inbound          18:27\n",
            "  D7    490015151H   inbound          18:40\n",
            "  D7    490015151H   inbound          18:52\n",
            "  D7    490015151H   inbound          19:05\n",
            "  D7    490015151H   inbound          19:18\n",
            "  D7    490015151H   inbound          19:31\n",
            "  D7    490015151H   inbound          19:44\n",
            "  D7    490015151H   inbound          19:57\n",
            "  D7    490015151H   inbound          20:10\n",
            "  D7    490015151H   inbound          20:22\n",
            "  D7    490015151H   inbound          20:34\n",
            "  D7    490015151H   inbound          20:46\n",
            "  D7    490015151H   inbound          21:01\n",
            "  D7    490015151H   inbound          21:16\n",
            "  D7    490015151H   inbound          21:31\n",
            "  D7    490015151H   inbound          21:46\n",
            "  D7    490015151H   inbound          22:01\n",
            "  D7    490015151H   inbound          22:16\n",
            "  D7    490015151H   inbound          22:32\n",
            "  D7    490015151H   inbound          22:47\n",
            "  D7    490015151H   inbound          23:02\n",
            "  D7    490015151H   inbound          23:17\n",
            "  D7    490015151H   inbound          23:32\n",
            "  D7    490015151H   inbound          23:47\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490004584S:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490004584S   inbound          05:09\n",
            "  D7    490004584S   inbound          05:29\n",
            "  D7    490004584S   inbound          05:49\n",
            "  D7    490004584S   inbound          06:09\n",
            "  D7    490004584S   inbound          06:29\n",
            "  D7    490004584S   inbound          06:45\n",
            "  D7    490004584S   inbound          06:59\n",
            "  D7    490004584S   inbound          07:10\n",
            "  D7    490004584S   inbound          07:20\n",
            "  D7    490004584S   inbound          07:30\n",
            "  D7    490004584S   inbound          07:41\n",
            "  D7    490004584S   inbound          07:51\n",
            "  D7    490004584S   inbound          08:01\n",
            "  D7    490004584S   inbound          08:12\n",
            "  D7    490004584S   inbound          08:24\n",
            "  D7    490004584S   inbound          08:36\n",
            "  D7    490004584S   inbound          08:49\n",
            "  D7    490004584S   inbound          09:02\n",
            "  D7    490004584S   inbound          09:15\n",
            "  D7    490004584S   inbound          09:27\n",
            "  D7    490004584S   inbound          09:39\n",
            "  D7    490004584S   inbound          09:51\n",
            "  D7    490004584S   inbound          10:03\n",
            "  D7    490004584S   inbound          10:15\n",
            "  D7    490004584S   inbound          10:27\n",
            "  D7    490004584S   inbound          10:39\n",
            "  D7    490004584S   inbound          10:51\n",
            "  D7    490004584S   inbound          11:03\n",
            "  D7    490004584S   inbound          11:15\n",
            "  D7    490004584S   inbound          11:27\n",
            "  D7    490004584S   inbound          11:39\n",
            "  D7    490004584S   inbound          11:51\n",
            "  D7    490004584S   inbound          12:03\n",
            "  D7    490004584S   inbound          12:15\n",
            "  D7    490004584S   inbound          12:27\n",
            "  D7    490004584S   inbound          12:39\n",
            "  D7    490004584S   inbound          12:51\n",
            "  D7    490004584S   inbound          13:03\n",
            "  D7    490004584S   inbound          13:15\n",
            "  D7    490004584S   inbound          13:27\n",
            "  D7    490004584S   inbound          13:39\n",
            "  D7    490004584S   inbound          13:51\n",
            "  D7    490004584S   inbound          14:03\n",
            "  D7    490004584S   inbound          14:15\n",
            "  D7    490004584S   inbound          14:27\n",
            "  D7    490004584S   inbound          14:38\n",
            "  D7    490004584S   inbound          14:48\n",
            "  D7    490004584S   inbound          14:58\n",
            "  D7    490004584S   inbound          15:09\n",
            "  D7    490004584S   inbound          15:21\n",
            "  D7    490004584S   inbound          15:33\n",
            "  D7    490004584S   inbound          15:45\n",
            "  D7    490004584S   inbound          15:57\n",
            "  D7    490004584S   inbound          16:09\n",
            "  D7    490004584S   inbound          16:21\n",
            "  D7    490004584S   inbound          16:33\n",
            "  D7    490004584S   inbound          16:45\n",
            "  D7    490004584S   inbound          16:57\n",
            "  D7    490004584S   inbound          17:09\n",
            "  D7    490004584S   inbound          17:21\n",
            "  D7    490004584S   inbound          17:33\n",
            "  D7    490004584S   inbound          17:46\n",
            "  D7    490004584S   inbound          17:58\n",
            "  D7    490004584S   inbound          18:10\n",
            "  D7    490004584S   inbound          18:22\n",
            "  D7    490004584S   inbound          18:34\n",
            "  D7    490004584S   inbound          18:47\n",
            "  D7    490004584S   inbound          18:59\n",
            "  D7    490004584S   inbound          19:12\n",
            "  D7    490004584S   inbound          19:25\n",
            "  D7    490004584S   inbound          19:38\n",
            "  D7    490004584S   inbound          19:50\n",
            "  D7    490004584S   inbound          20:03\n",
            "  D7    490004584S   inbound          20:16\n",
            "  D7    490004584S   inbound          20:28\n",
            "  D7    490004584S   inbound          20:40\n",
            "  D7    490004584S   inbound          20:52\n",
            "  D7    490004584S   inbound          21:07\n",
            "  D7    490004584S   inbound          21:22\n",
            "  D7    490004584S   inbound          21:37\n",
            "  D7    490004584S   inbound          21:52\n",
            "  D7    490004584S   inbound          22:07\n",
            "  D7    490004584S   inbound          22:22\n",
            "  D7    490004584S   inbound          22:37\n",
            "  D7    490004584S   inbound          22:52\n",
            "  D7    490004584S   inbound          23:07\n",
            "  D7    490004584S   inbound          23:22\n",
            "  D7    490004584S   inbound          23:37\n",
            "  D7    490004584S   inbound          23:52\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490000038F:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490000038F   inbound          05:13\n",
            "  D7    490000038F   inbound          05:33\n",
            "  D7    490000038F   inbound          05:53\n",
            "  D7    490000038F   inbound          06:13\n",
            "  D7    490000038F   inbound          06:34\n",
            "  D7    490000038F   inbound          06:50\n",
            "  D7    490000038F   inbound          07:04\n",
            "  D7    490000038F   inbound          07:15\n",
            "  D7    490000038F   inbound          07:26\n",
            "  D7    490000038F   inbound          07:36\n",
            "  D7    490000038F   inbound          07:47\n",
            "  D7    490000038F   inbound          07:57\n",
            "  D7    490000038F   inbound          08:07\n",
            "  D7    490000038F   inbound          08:19\n",
            "  D7    490000038F   inbound          08:31\n",
            "  D7    490000038F   inbound          08:43\n",
            "  D7    490000038F   inbound          08:55\n",
            "  D7    490000038F   inbound          09:08\n",
            "  D7    490000038F   inbound          09:21\n",
            "  D7    490000038F   inbound          09:33\n",
            "  D7    490000038F   inbound          09:45\n",
            "  D7    490000038F   inbound          09:57\n",
            "  D7    490000038F   inbound          10:09\n",
            "  D7    490000038F   inbound          10:21\n",
            "  D7    490000038F   inbound          10:33\n",
            "  D7    490000038F   inbound          10:45\n",
            "  D7    490000038F   inbound          10:57\n",
            "  D7    490000038F   inbound          11:09\n",
            "  D7    490000038F   inbound          11:21\n",
            "  D7    490000038F   inbound          11:33\n",
            "  D7    490000038F   inbound          11:45\n",
            "  D7    490000038F   inbound          11:57\n",
            "  D7    490000038F   inbound          12:09\n",
            "  D7    490000038F   inbound          12:21\n",
            "  D7    490000038F   inbound          12:33\n",
            "  D7    490000038F   inbound          12:45\n",
            "  D7    490000038F   inbound          12:57\n",
            "  D7    490000038F   inbound          13:09\n",
            "  D7    490000038F   inbound          13:21\n",
            "  D7    490000038F   inbound          13:33\n",
            "  D7    490000038F   inbound          13:45\n",
            "  D7    490000038F   inbound          13:57\n",
            "  D7    490000038F   inbound          14:09\n",
            "  D7    490000038F   inbound          14:21\n",
            "  D7    490000038F   inbound          14:33\n",
            "  D7    490000038F   inbound          14:44\n",
            "  D7    490000038F   inbound          14:54\n",
            "  D7    490000038F   inbound          15:04\n",
            "  D7    490000038F   inbound          15:15\n",
            "  D7    490000038F   inbound          15:27\n",
            "  D7    490000038F   inbound          15:39\n",
            "  D7    490000038F   inbound          15:51\n",
            "  D7    490000038F   inbound          16:03\n",
            "  D7    490000038F   inbound          16:15\n",
            "  D7    490000038F   inbound          16:27\n",
            "  D7    490000038F   inbound          16:39\n",
            "  D7    490000038F   inbound          16:51\n",
            "  D7    490000038F   inbound          17:03\n",
            "  D7    490000038F   inbound          17:15\n",
            "  D7    490000038F   inbound          17:27\n",
            "  D7    490000038F   inbound          17:39\n",
            "  D7    490000038F   inbound          17:52\n",
            "  D7    490000038F   inbound          18:04\n",
            "  D7    490000038F   inbound          18:16\n",
            "  D7    490000038F   inbound          18:28\n",
            "  D7    490000038F   inbound          18:40\n",
            "  D7    490000038F   inbound          18:53\n",
            "  D7    490000038F   inbound          19:05\n",
            "  D7    490000038F   inbound          19:18\n",
            "  D7    490000038F   inbound          19:31\n",
            "  D7    490000038F   inbound          19:44\n",
            "  D7    490000038F   inbound          19:56\n",
            "  D7    490000038F   inbound          20:09\n",
            "  D7    490000038F   inbound          20:21\n",
            "  D7    490000038F   inbound          20:33\n",
            "  D7    490000038F   inbound          20:45\n",
            "  D7    490000038F   inbound          20:57\n",
            "  D7    490000038F   inbound          21:12\n",
            "  D7    490000038F   inbound          21:27\n",
            "  D7    490000038F   inbound          21:42\n",
            "  D7    490000038F   inbound          21:57\n",
            "  D7    490000038F   inbound          22:12\n",
            "  D7    490000038F   inbound          22:27\n",
            "  D7    490000038F   inbound          22:42\n",
            "  D7    490000038F   inbound          22:57\n",
            "  D7    490000038F   inbound          23:12\n",
            "  D7    490000038F   inbound          23:27\n",
            "  D7    490000038F   inbound          23:42\n",
            "  D7    490000038F   inbound          23:57\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490006092S:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490006092S   inbound          05:19\n",
            "  D7    490006092S   inbound          05:39\n",
            "  D7    490006092S   inbound          05:59\n",
            "  D7    490006092S   inbound          06:20\n",
            "  D7    490006092S   inbound          06:41\n",
            "  D7    490006092S   inbound          06:57\n",
            "  D7    490006092S   inbound          07:11\n",
            "  D7    490006092S   inbound          07:22\n",
            "  D7    490006092S   inbound          07:34\n",
            "  D7    490006092S   inbound          07:45\n",
            "  D7    490006092S   inbound          07:56\n",
            "  D7    490006092S   inbound          08:06\n",
            "  D7    490006092S   inbound          08:17\n",
            "  D7    490006092S   inbound          08:29\n",
            "  D7    490006092S   inbound          08:41\n",
            "  D7    490006092S   inbound          08:53\n",
            "  D7    490006092S   inbound          09:05\n",
            "  D7    490006092S   inbound          09:17\n",
            "  D7    490006092S   inbound          09:30\n",
            "  D7    490006092S   inbound          09:42\n",
            "  D7    490006092S   inbound          09:54\n",
            "  D7    490006092S   inbound          10:06\n",
            "  D7    490006092S   inbound          10:18\n",
            "  D7    490006092S   inbound          10:30\n",
            "  D7    490006092S   inbound          10:42\n",
            "  D7    490006092S   inbound          10:54\n",
            "  D7    490006092S   inbound          11:06\n",
            "  D7    490006092S   inbound          11:18\n",
            "  D7    490006092S   inbound          11:30\n",
            "  D7    490006092S   inbound          11:42\n",
            "  D7    490006092S   inbound          11:54\n",
            "  D7    490006092S   inbound          12:06\n",
            "  D7    490006092S   inbound          12:18\n",
            "  D7    490006092S   inbound          12:30\n",
            "  D7    490006092S   inbound          12:42\n",
            "  D7    490006092S   inbound          12:54\n",
            "  D7    490006092S   inbound          13:06\n",
            "  D7    490006092S   inbound          13:18\n",
            "  D7    490006092S   inbound          13:30\n",
            "  D7    490006092S   inbound          13:42\n",
            "  D7    490006092S   inbound          13:54\n",
            "  D7    490006092S   inbound          14:06\n",
            "  D7    490006092S   inbound          14:18\n",
            "  D7    490006092S   inbound          14:30\n",
            "  D7    490006092S   inbound          14:42\n",
            "  D7    490006092S   inbound          14:53\n",
            "  D7    490006092S   inbound          15:03\n",
            "  D7    490006092S   inbound          15:14\n",
            "  D7    490006092S   inbound          15:25\n",
            "  D7    490006092S   inbound          15:37\n",
            "  D7    490006092S   inbound          15:49\n",
            "  D7    490006092S   inbound          16:01\n",
            "  D7    490006092S   inbound          16:13\n",
            "  D7    490006092S   inbound          16:25\n",
            "  D7    490006092S   inbound          16:37\n",
            "  D7    490006092S   inbound          16:49\n",
            "  D7    490006092S   inbound          17:01\n",
            "  D7    490006092S   inbound          17:13\n",
            "  D7    490006092S   inbound          17:26\n",
            "  D7    490006092S   inbound          17:38\n",
            "  D7    490006092S   inbound          17:50\n",
            "  D7    490006092S   inbound          18:03\n",
            "  D7    490006092S   inbound          18:15\n",
            "  D7    490006092S   inbound          18:27\n",
            "  D7    490006092S   inbound          18:39\n",
            "  D7    490006092S   inbound          18:51\n",
            "  D7    490006092S   inbound          19:04\n",
            "  D7    490006092S   inbound          19:16\n",
            "  D7    490006092S   inbound          19:28\n",
            "  D7    490006092S   inbound          19:41\n",
            "  D7    490006092S   inbound          19:54\n",
            "  D7    490006092S   inbound          20:06\n",
            "  D7    490006092S   inbound          20:18\n",
            "  D7    490006092S   inbound          20:30\n",
            "  D7    490006092S   inbound          20:42\n",
            "  D7    490006092S   inbound          20:54\n",
            "  D7    490006092S   inbound          21:06\n",
            "  D7    490006092S   inbound          21:21\n",
            "  D7    490006092S   inbound          21:36\n",
            "  D7    490006092S   inbound          21:50\n",
            "  D7    490006092S   inbound          22:05\n",
            "  D7    490006092S   inbound          22:20\n",
            "  D7    490006092S   inbound          22:35\n",
            "  D7    490006092S   inbound          22:50\n",
            "  D7    490006092S   inbound          23:05\n",
            "  D7    490006092S   inbound          23:20\n",
            "  D7    490006092S   inbound          23:34\n",
            "  D7    490006092S   inbound          23:49\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490002048X:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490002048X   inbound          05:22\n",
            "  D7    490002048X   inbound          05:42\n",
            "  D7    490002048X   inbound          06:03\n",
            "  D7    490002048X   inbound          06:24\n",
            "  D7    490002048X   inbound          06:45\n",
            "  D7    490002048X   inbound          07:01\n",
            "  D7    490002048X   inbound          07:15\n",
            "  D7    490002048X   inbound          07:26\n",
            "  D7    490002048X   inbound          07:38\n",
            "  D7    490002048X   inbound          07:50\n",
            "  D7    490002048X   inbound          08:01\n",
            "  D7    490002048X   inbound          08:12\n",
            "  D7    490002048X   inbound          08:24\n",
            "  D7    490002048X   inbound          08:36\n",
            "  D7    490002048X   inbound          08:48\n",
            "  D7    490002048X   inbound          09:00\n",
            "  D7    490002048X   inbound          09:11\n",
            "  D7    490002048X   inbound          09:23\n",
            "  D7    490002048X   inbound          09:35\n",
            "  D7    490002048X   inbound          09:47\n",
            "  D7    490002048X   inbound          09:59\n",
            "  D7    490002048X   inbound          10:11\n",
            "  D7    490002048X   inbound          10:23\n",
            "  D7    490002048X   inbound          10:35\n",
            "  D7    490002048X   inbound          10:47\n",
            "  D7    490002048X   inbound          10:59\n",
            "  D7    490002048X   inbound          11:11\n",
            "  D7    490002048X   inbound          11:23\n",
            "  D7    490002048X   inbound          11:35\n",
            "  D7    490002048X   inbound          11:47\n",
            "  D7    490002048X   inbound          11:59\n",
            "  D7    490002048X   inbound          12:11\n",
            "  D7    490002048X   inbound          12:23\n",
            "  D7    490002048X   inbound          12:35\n",
            "  D7    490002048X   inbound          12:47\n",
            "  D7    490002048X   inbound          12:59\n",
            "  D7    490002048X   inbound          13:11\n",
            "  D7    490002048X   inbound          13:23\n",
            "  D7    490002048X   inbound          13:35\n",
            "  D7    490002048X   inbound          13:47\n",
            "  D7    490002048X   inbound          13:59\n",
            "  D7    490002048X   inbound          14:11\n",
            "  D7    490002048X   inbound          14:23\n",
            "  D7    490002048X   inbound          14:35\n",
            "  D7    490002048X   inbound          14:47\n",
            "  D7    490002048X   inbound          14:58\n",
            "  D7    490002048X   inbound          15:09\n",
            "  D7    490002048X   inbound          15:21\n",
            "  D7    490002048X   inbound          15:32\n",
            "  D7    490002048X   inbound          15:44\n",
            "  D7    490002048X   inbound          15:56\n",
            "  D7    490002048X   inbound          16:08\n",
            "  D7    490002048X   inbound          16:20\n",
            "  D7    490002048X   inbound          16:32\n",
            "  D7    490002048X   inbound          16:44\n",
            "  D7    490002048X   inbound          16:56\n",
            "  D7    490002048X   inbound          17:08\n",
            "  D7    490002048X   inbound          17:20\n",
            "  D7    490002048X   inbound          17:33\n",
            "  D7    490002048X   inbound          17:45\n",
            "  D7    490002048X   inbound          17:57\n",
            "  D7    490002048X   inbound          18:09\n",
            "  D7    490002048X   inbound          18:21\n",
            "  D7    490002048X   inbound          18:33\n",
            "  D7    490002048X   inbound          18:45\n",
            "  D7    490002048X   inbound          18:57\n",
            "  D7    490002048X   inbound          19:10\n",
            "  D7    490002048X   inbound          19:22\n",
            "  D7    490002048X   inbound          19:33\n",
            "  D7    490002048X   inbound          19:46\n",
            "  D7    490002048X   inbound          19:59\n",
            "  D7    490002048X   inbound          20:11\n",
            "  D7    490002048X   inbound          20:23\n",
            "  D7    490002048X   inbound          20:35\n",
            "  D7    490002048X   inbound          20:47\n",
            "  D7    490002048X   inbound          20:59\n",
            "  D7    490002048X   inbound          21:11\n",
            "  D7    490002048X   inbound          21:26\n",
            "  D7    490002048X   inbound          21:40\n",
            "  D7    490002048X   inbound          21:54\n",
            "  D7    490002048X   inbound          22:09\n",
            "  D7    490002048X   inbound          22:24\n",
            "  D7    490002048X   inbound          22:39\n",
            "  D7    490002048X   inbound          22:54\n",
            "  D7    490002048X   inbound          23:09\n",
            "  D7    490002048X   inbound          23:24\n",
            "  D7    490002048X   inbound          23:38\n",
            "  D7    490002048X   inbound          23:53\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mTimetable for 490013513N:\u001b[0m\n",
            "\n",
            "Line Stop Point ID Direction Scheduled Time\n",
            "  D7    490013513N   inbound          05:25\n",
            "  D7    490013513N   inbound          05:46\n",
            "  D7    490013513N   inbound          06:07\n",
            "  D7    490013513N   inbound          06:28\n",
            "  D7    490013513N   inbound          06:49\n",
            "  D7    490013513N   inbound          07:05\n",
            "  D7    490013513N   inbound          07:19\n",
            "  D7    490013513N   inbound          07:31\n",
            "  D7    490013513N   inbound          07:43\n",
            "  D7    490013513N   inbound          07:55\n",
            "  D7    490013513N   inbound          08:06\n",
            "  D7    490013513N   inbound          08:18\n",
            "  D7    490013513N   inbound          08:30\n",
            "  D7    490013513N   inbound          08:42\n",
            "  D7    490013513N   inbound          08:54\n",
            "  D7    490013513N   inbound          09:06\n",
            "  D7    490013513N   inbound          09:17\n",
            "  D7    490013513N   inbound          09:28\n",
            "  D7    490013513N   inbound          09:40\n",
            "  D7    490013513N   inbound          09:52\n",
            "  D7    490013513N   inbound          10:04\n",
            "  D7    490013513N   inbound          10:16\n",
            "  D7    490013513N   inbound          10:28\n",
            "  D7    490013513N   inbound          10:40\n",
            "  D7    490013513N   inbound          10:52\n",
            "  D7    490013513N   inbound          11:04\n",
            "  D7    490013513N   inbound          11:16\n",
            "  D7    490013513N   inbound          11:28\n",
            "  D7    490013513N   inbound          11:40\n",
            "  D7    490013513N   inbound          11:52\n",
            "  D7    490013513N   inbound          12:04\n",
            "  D7    490013513N   inbound          12:16\n",
            "  D7    490013513N   inbound          12:28\n",
            "  D7    490013513N   inbound          12:40\n",
            "  D7    490013513N   inbound          12:52\n",
            "  D7    490013513N   inbound          13:04\n",
            "  D7    490013513N   inbound          13:16\n",
            "  D7    490013513N   inbound          13:28\n",
            "  D7    490013513N   inbound          13:40\n",
            "  D7    490013513N   inbound          13:52\n",
            "  D7    490013513N   inbound          14:04\n",
            "  D7    490013513N   inbound          14:16\n",
            "  D7    490013513N   inbound          14:28\n",
            "  D7    490013513N   inbound          14:40\n",
            "  D7    490013513N   inbound          14:52\n",
            "  D7    490013513N   inbound          15:03\n",
            "  D7    490013513N   inbound          15:15\n",
            "  D7    490013513N   inbound          15:27\n",
            "  D7    490013513N   inbound          15:38\n",
            "  D7    490013513N   inbound          15:50\n",
            "  D7    490013513N   inbound          16:02\n",
            "  D7    490013513N   inbound          16:14\n",
            "  D7    490013513N   inbound          16:26\n",
            "  D7    490013513N   inbound          16:38\n",
            "  D7    490013513N   inbound          16:50\n",
            "  D7    490013513N   inbound          17:02\n",
            "  D7    490013513N   inbound          17:14\n",
            "  D7    490013513N   inbound          17:26\n",
            "  D7    490013513N   inbound          17:38\n",
            "  D7    490013513N   inbound          17:50\n",
            "  D7    490013513N   inbound          18:02\n",
            "  D7    490013513N   inbound          18:14\n",
            "  D7    490013513N   inbound          18:26\n",
            "  D7    490013513N   inbound          18:38\n",
            "  D7    490013513N   inbound          18:50\n",
            "  D7    490013513N   inbound          19:02\n",
            "  D7    490013513N   inbound          19:15\n",
            "  D7    490013513N   inbound          19:27\n",
            "  D7    490013513N   inbound          19:38\n",
            "  D7    490013513N   inbound          19:50\n",
            "  D7    490013513N   inbound          20:03\n",
            "  D7    490013513N   inbound          20:15\n",
            "  D7    490013513N   inbound          20:27\n",
            "  D7    490013513N   inbound          20:39\n",
            "  D7    490013513N   inbound          20:51\n",
            "  D7    490013513N   inbound          21:03\n",
            "  D7    490013513N   inbound          21:15\n",
            "  D7    490013513N   inbound          21:30\n",
            "  D7    490013513N   inbound          21:44\n",
            "  D7    490013513N   inbound          21:58\n",
            "  D7    490013513N   inbound          22:13\n",
            "  D7    490013513N   inbound          22:28\n",
            "  D7    490013513N   inbound          22:43\n",
            "  D7    490013513N   inbound          22:58\n",
            "  D7    490013513N   inbound          23:13\n",
            "  D7    490013513N   inbound          23:28\n",
            "  D7    490013513N   inbound          23:42\n",
            "  D7    490013513N   inbound          23:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cd15c58-2fbc-4e66-cbc4-01a7e2c88b14",
        "id": "ohJa9v0qlMWt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[4mToday is Friday. The selected Schedule name is Monday to Friday.\u001b[0m\n",
            "\n",
            "Arrival Predictions for stop point 490011107G (Poplar / All Saints Church):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    YX68UKD 490011107G  outbound    2024-08-16 23:38:25   1900-01-01 23:38:00  0.0    0.0     0.0\n",
            "  D7    LX61DBY 490011107G  outbound    2024-08-16 23:40:22   1900-01-01 23:40:00  2.0    4.0     4.0\n",
            "  D7    LX61DBV 490011107G  outbound    2024-08-16 23:55:32   1900-01-01 23:55:00 15.0   30.0   225.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)   Gap  2_Gap  Gap_Sq\n",
            "  D7    YX68UKD 490011107G  outbound    2024-08-16 23:38:25   1900-01-01 23:38:00  0.00   0.00    0.00\n",
            "  D7    LX61DBY 490011107G  outbound    2024-08-16 23:40:22   1900-01-01 23:40:00  1.95   3.90    3.80\n",
            "  D7    LX61DBV 490011107G  outbound    2024-08-16 23:55:32   1900-01-01 23:55:00 15.17  30.34  230.13\n",
            "\n",
            "Number of buses observed in the current hour: 3\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "top 20 schedule: 86    23:42:00\n",
            "87    23:56:00\n",
            "Name: Scheduled Time Only, dtype: object\n",
            "Updated top 20 'Scheduled Time Only' values including the time immediately above the first element:\n",
            "0    23:28:00\n",
            "1    23:42:00\n",
            "2    23:56:00\n",
            "Name: Scheduled Time Only, dtype: object\n",
            "\n",
            "Updated cumulative_df with new 'Scheduled Time' column:\n",
            "  Line Vehicle ID  Stop Point Direction Expected Arrival (BST)  \\\n",
            "0   D7    YX68UKD  490011107G  outbound    2024-08-16 23:38:25   \n",
            "1   D7    LX61DBY  490011107G  outbound    2024-08-16 23:40:22   \n",
            "2   D7    LX61DBV  490011107G  outbound    2024-08-16 23:55:32   \n",
            "\n",
            "  Expected Arrival (HM)    Gap  2_Gap  Gap_Sq Scheduled Time  \n",
            "0   1900-01-01 23:38:00   0.00   0.00    0.00       23:28:00  \n",
            "1   1900-01-01 23:40:00   1.95   3.90    3.80       23:42:00  \n",
            "2   1900-01-01 23:55:00  15.17  30.34  230.13       23:56:00  \n",
            "\n",
            "Last row's 'Scheduled Time' in cumulative_df (BST):\n",
            "23:56:00\n",
            "\n",
            "Scheduled times greater than last_row_scheduled_time in BST and within the next 3 hours:\n",
            "Series([], Name: Scheduled Time Only, dtype: object)\n",
            "\n",
            "Updated cumulative_df after appending new rows:\n",
            "  Line Vehicle ID  Stop Point Direction Expected Arrival (BST)  \\\n",
            "0   D7    YX68UKD  490011107G  outbound    2024-08-16 23:38:25   \n",
            "1   D7    LX61DBY  490011107G  outbound    2024-08-16 23:40:22   \n",
            "2   D7    LX61DBV  490011107G  outbound    2024-08-16 23:55:32   \n",
            "\n",
            "  Expected Arrival (HM)    Gap  2_Gap  Gap_Sq Scheduled Time  \n",
            "0   1900-01-01 23:38:00   0.00   0.00    0.00       23:28:00  \n",
            "1   1900-01-01 23:40:00   1.95   3.90    3.80       23:42:00  \n",
            "2   1900-01-01 23:55:00  15.17  30.34  230.13       23:56:00  \n",
            "\n",
            "printing df train1:\n",
            "     Scheduled Time Expected Arrival (BST)\n",
            "0           0:00:06                0:00:09\n",
            "1           0:01:00                0:01:04\n",
            "2           0:02:09                0:02:10\n",
            "3           0:03:00                0:03:04\n",
            "4           0:03:36                0:04:21\n",
            "...             ...                    ...\n",
            "3442       23:54:00               23:51:30\n",
            "3443       23:55:00               23:56:23\n",
            "3444       23:56:57               23:57:20\n",
            "3445       23:57:56               23:58:13\n",
            "3446       23:58:52               23:59:03\n",
            "\n",
            "[3447 rows x 2 columns]\n",
            "\n",
            "printing df train2:\n",
            "     Scheduled Time Expected Arrival (BST)  Scheduled Time (seconds)  \\\n",
            "0           0:00:06                0:00:09                         6   \n",
            "1           0:01:00                0:01:04                        60   \n",
            "2           0:02:09                0:02:10                       129   \n",
            "3           0:03:00                0:03:04                       180   \n",
            "4           0:03:36                0:04:21                       216   \n",
            "...             ...                    ...                       ...   \n",
            "3442       23:54:00               23:51:30                     86040   \n",
            "3443       23:55:00               23:56:23                     86100   \n",
            "3444       23:56:57               23:57:20                     86217   \n",
            "3445       23:57:56               23:58:13                     86276   \n",
            "3446       23:58:52               23:59:03                     86332   \n",
            "\n",
            "      Expected Arrival (BST) (seconds)  \n",
            "0                                    9  \n",
            "1                                   64  \n",
            "2                                  130  \n",
            "3                                  184  \n",
            "4                                  261  \n",
            "...                                ...  \n",
            "3442                             85890  \n",
            "3443                             86183  \n",
            "3444                             86240  \n",
            "3445                             86293  \n",
            "3446                             86343  \n",
            "\n",
            "[3447 rows x 4 columns]\n",
            "\n",
            "printing df train3:\n",
            "     Scheduled Time Expected Arrival (BST)  Scheduled Time (seconds)  \\\n",
            "0           0:00:06                0:00:09                         6   \n",
            "1           0:01:00                0:01:04                        60   \n",
            "2           0:02:09                0:02:10                       129   \n",
            "3           0:03:00                0:03:04                       180   \n",
            "4           0:03:36                0:04:21                       216   \n",
            "...             ...                    ...                       ...   \n",
            "3442       23:54:00               23:51:30                     86040   \n",
            "3443       23:55:00               23:56:23                     86100   \n",
            "3444       23:56:57               23:57:20                     86217   \n",
            "3445       23:57:56               23:58:13                     86276   \n",
            "3446       23:58:52               23:59:03                     86332   \n",
            "\n",
            "      Expected Arrival (BST) (seconds)  \n",
            "0                                    9  \n",
            "1                                   64  \n",
            "2                                  130  \n",
            "3                                  184  \n",
            "4                                  261  \n",
            "...                                ...  \n",
            "3442                             85890  \n",
            "3443                             86183  \n",
            "3444                             86240  \n",
            "3445                             86293  \n",
            "3446                             86343  \n",
            "\n",
            "[3447 rows x 4 columns]\n",
            "\n",
            "printing non_zero_df:\n",
            "  Line Vehicle ID  Stop Point Direction Expected Arrival (BST)  \\\n",
            "0   D7    YX68UKD  490011107G  outbound    2024-08-16 23:38:25   \n",
            "1   D7    LX61DBY  490011107G  outbound    2024-08-16 23:40:22   \n",
            "2   D7    LX61DBV  490011107G  outbound    2024-08-16 23:55:32   \n",
            "\n",
            "  Expected Arrival (HM)    Gap  2_Gap  Gap_Sq Scheduled Time  \n",
            "0   1900-01-01 23:38:00   0.00   0.00    0.00       23:28:00  \n",
            "1   1900-01-01 23:40:00   1.95   3.90    3.80       23:42:00  \n",
            "2   1900-01-01 23:55:00  15.17  30.34  230.13       23:56:00  \n",
            "\n",
            "printing new data 1:\n",
            "  Scheduled Time Expected Arrival (BST)\n",
            "0       23:28:00    2024-08-16 23:38:25\n",
            "1       23:42:00    2024-08-16 23:40:22\n",
            "2       23:56:00    2024-08-16 23:55:32\n",
            "\n",
            "printing new data 2:\n",
            "  Scheduled Time Expected Arrival (BST)  Scheduled Time (seconds)  \\\n",
            "0       23:28:00    2024-08-16 23:38:25                     84480   \n",
            "1       23:42:00    2024-08-16 23:40:22                     85320   \n",
            "2       23:56:00    2024-08-16 23:55:32                     86160   \n",
            "\n",
            "   Expected Arrival (BST) (seconds)  \n",
            "0                             85105  \n",
            "1                             85222  \n",
            "2                             86132  \n",
            "\n",
            "printing new data 3:\n",
            "  Scheduled Time Expected Arrival (BST)  Scheduled Time (seconds)  \\\n",
            "0       23:28:00    2024-08-16 23:38:25                     84480   \n",
            "1       23:42:00    2024-08-16 23:40:22                     85320   \n",
            "2       23:56:00    2024-08-16 23:55:32                     86160   \n",
            "\n",
            "   Expected Arrival (BST) (seconds)  \n",
            "0                             85105  \n",
            "1                             85222  \n",
            "2                             86132  \n",
            "\n",
            "printing df train4:\n",
            "     Scheduled Time Expected Arrival (BST)  Scheduled Time (seconds)  \\\n",
            "0           0:00:06                0:00:09                         6   \n",
            "1           0:01:00                0:01:04                        60   \n",
            "2           0:02:09                0:02:10                       129   \n",
            "3           0:03:00                0:03:04                       180   \n",
            "4           0:03:36                0:04:21                       216   \n",
            "...             ...                    ...                       ...   \n",
            "3445       23:57:56               23:58:13                     86276   \n",
            "3446       23:58:52               23:59:03                     86332   \n",
            "3447       23:28:00    2024-08-16 23:38:25                     84480   \n",
            "3448       23:42:00    2024-08-16 23:40:22                     85320   \n",
            "3449       23:56:00    2024-08-16 23:55:32                     86160   \n",
            "\n",
            "      Expected Arrival (BST) (seconds)  \n",
            "0                                    9  \n",
            "1                                   64  \n",
            "2                                  130  \n",
            "3                                  184  \n",
            "4                                  261  \n",
            "...                                ...  \n",
            "3445                             86293  \n",
            "3446                             86343  \n",
            "3447                             85105  \n",
            "3448                             85222  \n",
            "3449                             86132  \n",
            "\n",
            "[3450 rows x 4 columns]\n",
            "\n",
            "printing X :\n",
            "      Scheduled Time (seconds)\n",
            "0                            6\n",
            "1                           60\n",
            "2                          129\n",
            "3                          180\n",
            "4                          216\n",
            "...                        ...\n",
            "3445                     86276\n",
            "3446                     86332\n",
            "3447                     84480\n",
            "3448                     85320\n",
            "3449                     86160\n",
            "\n",
            "[3450 rows x 1 columns]\n",
            "\n",
            "printing y:\n",
            "0           9\n",
            "1          64\n",
            "2         130\n",
            "3         184\n",
            "4         261\n",
            "        ...  \n",
            "3445    86293\n",
            "3446    86343\n",
            "3447    85105\n",
            "3448    85222\n",
            "3449    86132\n",
            "Name: Expected Arrival (BST) (seconds), Length: 3450, dtype: int64\n",
            "\n",
            "printing zero_arrival_df:\n",
            "Empty DataFrame\n",
            "Columns: [Line, Vehicle ID, Stop Point, Direction, Expected Arrival (BST), Expected Arrival (HM), Gap, 2_Gap, Gap_Sq, Scheduled Time]\n",
            "Index: []\n",
            "\n",
            "printing new_scheduled_times2:\n",
            "[]\n",
            "\n",
            "printing new_scheduled_times3:\n",
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-b7fdff1ce556>:401: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  cumulative_df_new = pd.concat([cumulative_df_new, new_rows], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-b7fdff1ce556>\u001b[0m in \u001b[0;36m<cell line: 805>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-b7fdff1ce556>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_scheduled_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0;31m# Predict expected arrival times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mpredicted_seconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Scheduled Time (seconds)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_scheduled_times_seconds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nprinting predicted_seconds:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \"\"\"\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    968\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from datetime import datetime, timedelta, time as dt_time\n",
        "\n",
        "# Function to fetch arrival predictions\n",
        "def fetch_arrival_predictions(line_id, stop_point_id, direction):\n",
        "    try:\n",
        "        base_url = f\"https://api.tfl.gov.uk/Line/{line_id}/Arrivals/{stop_point_id}\"\n",
        "        params = {'direction': direction}\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if len(data) == 0:\n",
        "            return pd.DataFrame(), None  # No data available\n",
        "        station_name = data[0]['stationName']\n",
        "        predictions = []\n",
        "        for item in data:\n",
        "            arrival_time = datetime.strptime(item['expectedArrival'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            arrival_time_bst = arrival_time + timedelta(hours=1)\n",
        "            predictions.append({\n",
        "                'Line': item['lineName'],\n",
        "                'Vehicle ID': item['vehicleId'],\n",
        "                'Stop Point': stop_point_id,\n",
        "                'Direction': direction,\n",
        "                'Expected Arrival (BST)': arrival_time_bst,\n",
        "                'Expected Arrival (HM)': arrival_time_bst.strftime('%H:%M')\n",
        "            })\n",
        "        df = pd.DataFrame(predictions)\n",
        "        df = df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "        df['Expected Arrival (BST)'] = pd.to_datetime(df['Expected Arrival (BST)'])  # Convert to datetime\n",
        "        df['Expected Arrival (HM)'] = pd.to_datetime(df['Expected Arrival (HM)'], format='%H:%M')\n",
        "        df['Gap'] = df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "        df['2_Gap'] = (df['Gap'] * 2).round(2)\n",
        "        df['Gap_Sq'] = (df['Gap'] * df['Gap']).round(2)\n",
        "        return df, station_name\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def fetch_current_hour_swt(route_swt_df):\n",
        "    current_hour = datetime.now(pytz.timezone('Europe/London')).hour\n",
        "\n",
        "    current_swt = route_swt_df[route_swt_df['Hour'] == current_hour]\n",
        "    if not current_swt.empty:\n",
        "        route_swt_a = current_swt['Route SWT A'].values[0]\n",
        "        route_swt_b = current_swt['Route SWT B'].values[0]\n",
        "\n",
        "        # Calculate double headway\n",
        "        double_headway_a = route_swt_a * 2\n",
        "        double_headway_b = route_swt_b * 2 * 2\n",
        "\n",
        "        print(f\"Route SWT A for the current hour ({current_hour}): {route_swt_a}\")\n",
        "        print(f\"Route SWT B for the current hour ({current_hour}): {route_swt_b}\")\n",
        "        print(f\"Double Headway for Route A: {double_headway_a}\")\n",
        "        print(f\"Double Headway for Route B: {double_headway_b}\")\n",
        "        return double_headway_a, double_headway_b\n",
        "    else:\n",
        "        print(f\"No SWT data available for the current hour ({current_hour}).\")\n",
        "\n",
        "def check_gaps_against_double_headway(cumulative_dataframes, double_headway_a, double_headway_b, combined_df, lineID):\n",
        "    results = []\n",
        "\n",
        "    # Create a mapping from ID to Bus_Stop_Code\n",
        "    id_to_code = combined_df.set_index('ID')['Bus_Stop_Code'].to_dict()\n",
        "\n",
        "    # Loop through each stop point ID in the cumulative dataframes\n",
        "    for stop_point_id, cumulative_df in cumulative_dataframes.items():\n",
        "        direction = 'A' if combined_df[combined_df['ID'] == stop_point_id]['Route_Dir_QSI_No'].iloc[0].startswith(lineID + '_A') else 'B'\n",
        "        double_headway = double_headway_a if direction == 'A' else double_headway_b\n",
        "\n",
        "        # Check if any 'Gap' is greater than the corresponding double headway\n",
        "        gaps_exceeding_headway = cumulative_df[cumulative_df['Gap'] > double_headway]\n",
        "\n",
        "        if not gaps_exceeding_headway.empty:\n",
        "            # Extract the relevant Vehicle ID and Stop Point\n",
        "            for _, row in gaps_exceeding_headway.iterrows():\n",
        "                results.append({ 'Line': lineID,\n",
        "                                'Vehicle ID': row['Vehicle ID'],\n",
        "                                'Stop Point': row['Stop Point']\n",
        "                              })\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    if not results_df.empty:\n",
        "        # Add Bus_Stop_Code to results_df\n",
        "        results_df['Bus_Stop_Code'] = results_df['Stop Point'].map(id_to_code)\n",
        "    if results_df.empty:\n",
        "        print(\"\\nNo Vehicle IDs and Stop Points where Gap exceeds Double Headway.\")\n",
        "    else:\n",
        "        print(\"\\nVehicle IDs and Stop Points where Gap exceeds Double Headway:\")\n",
        "        print(results_df.to_string(index=False))\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Function to calculate Scheduled Wait Time (SWT) for all hours\n",
        "    def calculate_swt_for_all_hours(slots):\n",
        "        swt_per_hour = []\n",
        "        for hour in range(24):\n",
        "            total_buses = len(slots[hour])\n",
        "            scheduled_wait_time = 60 / (total_buses * 2) if total_buses > 0 else None  # Use None to indicate no buses\n",
        "            swt_per_hour.append((scheduled_wait_time, total_buses))\n",
        "        return swt_per_hour\n",
        "\n",
        "    # Main logic to fetch and calculate SWT\n",
        "    def main(combined_df, lineID):\n",
        "        bst = pytz.timezone('Europe/London')\n",
        "        swt_data = {\n",
        "            'Route_Dir_QSI_No': [],\n",
        "            'ID': [],\n",
        "        }\n",
        "        # Initialize keys for all 24 hours in the dictionary\n",
        "        for hour in range(24):\n",
        "            swt_data[f'SWT_{hour}'] = []\n",
        "            swt_data[f'Sch_{hour}'] = []\n",
        "\n",
        "        # Update current time and hour\n",
        "        current_time = datetime.now(bst)\n",
        "        day_of_week = get_day_of_week()\n",
        "\n",
        "        # Store selected schedule name to ensure it's printed only once\n",
        "        selected_schedule_name = None\n",
        "        printed_schedule_name = False\n",
        "\n",
        "        for index, row in combined_df.iterrows():\n",
        "            stop_point_id = row['ID']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "            if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "                direction = 'outbound'\n",
        "            elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "                direction = 'inbound'\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "            data = fetch_data(url)\n",
        "\n",
        "            schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "            if not selected_schedule_name:\n",
        "                selected_schedule_name = select_preferred_schedule(schedule_names_dict, day_of_week)\n",
        "\n",
        "            if selected_schedule_name and not printed_schedule_name:\n",
        "                print(f\"\\n\\033[1m\\033[4mToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\\033[0m\")\n",
        "                printed_schedule_name = True\n",
        "\n",
        "            if selected_schedule_name:\n",
        "                timetable = schedule_names_dict[selected_schedule_name]\n",
        "                slots = categorize_into_slots(timetable)\n",
        "\n",
        "                # Calculate SWT for all hours\n",
        "                swt_per_hour = calculate_swt_for_all_hours(slots)\n",
        "\n",
        "                # Store SWT data for all hours\n",
        "                swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "                swt_data['ID'].append(stop_point_id)\n",
        "                for hour in range(24):\n",
        "                    swt, total_buses = swt_per_hour[hour]\n",
        "                    swt_data[f'SWT_{hour}'].append(swt)\n",
        "                    swt_data[f'Sch_{hour}'].append(total_buses)\n",
        "\n",
        "        # Create DataFrame for SWT data\n",
        "        swt_df = pd.DataFrame(swt_data)\n",
        "\n",
        "        # Calculate Route SWT for each hour for directions A and B\n",
        "        route_swt_data = { 'Line' : [] ,\n",
        "            'Hour': [],\n",
        "            'Route SWT A': [],\n",
        "            'Route SWT B': []\n",
        "        }\n",
        "\n",
        "        for hour in range(24):\n",
        "            # Calculate Route SWT for direction A\n",
        "            swt_a = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_A')]\n",
        "            valid_swt_a = swt_a[pd.notna(swt_a[f'SWT_{hour}'])]  # Filter out NaN values\n",
        "            weighted_sum_a = sum(valid_swt_a[f'SWT_{hour}'] * valid_swt_a[f'Sch_{hour}']) if not valid_swt_a.empty else 0\n",
        "            total_buses_a = sum(valid_swt_a[f'Sch_{hour}']) if not valid_swt_a.empty else 0\n",
        "            route_swt_a = round(weighted_sum_a / total_buses_a, 2) if total_buses_a > 0 else None\n",
        "\n",
        "\n",
        "            # Calculate Route SWT for direction B\n",
        "            swt_b = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_B')]\n",
        "            valid_swt_b = swt_b[pd.notna(swt_b[f'SWT_{hour}'])]  # Filter out NaN values\n",
        "            weighted_sum_b = sum(valid_swt_b[f'SWT_{hour}'] * valid_swt_b[f'Sch_{hour}']) if not valid_swt_b.empty else 0\n",
        "            total_buses_b = sum(valid_swt_b[f'Sch_{hour}']) if not valid_swt_b.empty else 0\n",
        "            route_swt_b = round(weighted_sum_b / total_buses_b, 2) if total_buses_b > 0 else None\n",
        "\n",
        "            route_swt_data['Line'].append(lineID)\n",
        "            route_swt_data['Hour'].append(hour)\n",
        "            route_swt_data['Route SWT A'].append(route_swt_a)\n",
        "            route_swt_data['Route SWT B'].append(route_swt_b)\n",
        "\n",
        "        route_swt_df = pd.DataFrame(route_swt_data)\n",
        "        return route_swt_df\n",
        "\n",
        "    route_swt_df = main(combined_df, lineID)\n",
        "    # Example dictionary to hold cumulative dataframes for each stop point\n",
        "\n",
        "    cumulative_dataframes = {}\n",
        "    cumulative_dataframes_new = {}\n",
        "    # Dictionary to hold the number of buses observed per stop point\n",
        "    buses_observed = {}\n",
        "    buses_observed_new = {}\n",
        "    # DataFrame to store Route AWT data\n",
        "    route_awt_df = pd.DataFrame(columns=['Hour', 'Route AWT A', 'Route AWT B'])\n",
        "\n",
        "    # Loop through unique stop points in combined_df\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        direction = 'outbound' if row['Route_Dir_QSI_No'].startswith(lineID + '_A') else 'inbound'\n",
        "\n",
        "        cumulative_df = pd.DataFrame(columns=[\n",
        "            'Line', 'Vehicle ID', 'Stop Point', 'Direction',\n",
        "            'Expected Arrival (BST)', 'Expected Arrival (HM)',\n",
        "            'Gap', '2_Gap', 'Gap_Sq'\n",
        "        ])\n",
        "        cumulative_df_new = cumulative_df\n",
        "        cumulative_dataframes[stop_point_id] = cumulative_df  # Initialize cumulative dataframe\n",
        "        cumulative_dataframes_new[stop_point_id] = cumulative_df_new\n",
        "        buses_observed[stop_point_id] = (0, 0, 0, 0)  # Initialize with zero values\n",
        "        buses_observed_new[stop_point_id] = (0, 0, 0, 0)  # Initialize with zero values\n",
        "\n",
        "    while True:\n",
        "        for stop_point_id, cumulative_df in cumulative_dataframes.items():\n",
        "            direction = 'outbound' if combined_df[combined_df['ID'] == stop_point_id]['Route_Dir_QSI_No'].iloc[0].startswith(lineID + '_A') else 'inbound'\n",
        "\n",
        "            arrival_predictions_df, station_name = fetch_arrival_predictions(lineID, stop_point_id, direction)\n",
        "\n",
        "            if arrival_predictions_df is not None and not arrival_predictions_df.empty:\n",
        "                current_hour = datetime.now(pytz.timezone('Europe/London')).hour\n",
        "\n",
        "                for _, row in arrival_predictions_df.iterrows():\n",
        "                    vehicle_id = row['Vehicle ID']\n",
        "\n",
        "                    mask = cumulative_df['Vehicle ID'] == vehicle_id\n",
        "\n",
        "                    if cumulative_df[mask].empty:\n",
        "                        # If vehicle ID is not present in cumulative DataFrame, append the row\n",
        "                        cumulative_df = pd.concat([cumulative_df, row.to_frame().T], ignore_index=True)\n",
        "                    else:\n",
        "                        # If vehicle ID is present, overwrite the row\n",
        "                        cumulative_df.loc[mask, ['Line', 'Stop Point', 'Direction', 'Expected Arrival (BST)', 'Expected Arrival (HM)', 'Gap', '2_Gap', 'Gap_Sq']] = row[['Line', 'Stop Point', 'Direction', 'Expected Arrival (BST)', 'Expected Arrival (HM)', 'Gap', '2_Gap', 'Gap_Sq']].values\n",
        "\n",
        "                # Convert to datetime\n",
        "                cumulative_df['Expected Arrival (BST)'] = pd.to_datetime(cumulative_df['Expected Arrival (BST)'])\n",
        "                cumulative_df['Expected Arrival (HM)'] = pd.to_datetime(cumulative_df['Expected Arrival (HM)'], format='%H:%M')\n",
        "\n",
        "                # Sort the DataFrame\n",
        "                cumulative_df = cumulative_df.sort_values(by='Expected Arrival (BST)', ascending=True).reset_index(drop=True)\n",
        "\n",
        "                # Calculate gaps\n",
        "                cumulative_df['Gap'] = (cumulative_df['Expected Arrival (BST)'].diff().dt.total_seconds() / 60).round(2)\n",
        "                cumulative_df.loc[0, 'Gap'] = 0  # First row gap should be zero\n",
        "                cumulative_df['2_Gap'] = (cumulative_df['Gap'] * 2).round(2)\n",
        "                cumulative_df['Gap_Sq'] = (cumulative_df['Gap'] * cumulative_df['Gap']).round(2)\n",
        "\n",
        "                # Update number of buses observed in the current hour\n",
        "                num_buses_observed = len(cumulative_df[cumulative_df['Expected Arrival (BST)'].dt.hour == current_hour]['Vehicle ID'].unique())\n",
        "                total_Gap_Sq = cumulative_df[cumulative_df['Expected Arrival (BST)'].dt.hour == current_hour]['Gap_Sq'].sum()\n",
        "                total_2_Gap = cumulative_df[cumulative_df['Expected Arrival (BST)'].dt.hour == current_hour]['2_Gap'].sum()\n",
        "                AWT = round(total_Gap_Sq / total_2_Gap, 2) if total_2_Gap > 0 else 0\n",
        "                buses_observed[stop_point_id] = (num_buses_observed, total_Gap_Sq, total_2_Gap, AWT)\n",
        "\n",
        "                print(f\"\\nArrival Predictions for stop point {stop_point_id} ({station_name}):\")\n",
        "                print(arrival_predictions_df.to_string(index=False))\n",
        "                print(\"\\nCumulative DataFrame:\")\n",
        "                print(cumulative_df.to_string(index=False))\n",
        "                print(f\"\\nNumber of buses observed in the current hour: {num_buses_observed}\")\n",
        "            else:\n",
        "                print(\"No arrival predictions available.\")\n",
        "\n",
        "            print(\"Refreshing data in 30 seconds...\\n\")\n",
        "            time.sleep(30)\n",
        "\n",
        "            # Update cumulative dataframe in dictionary\n",
        "            cumulative_dataframes[stop_point_id] = cumulative_df\n",
        "            cumulative_df_new = cumulative_df\n",
        "            cumulative_dataframes_new[stop_point_id] = cumulative_df_new\n",
        "            if not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "            cumulative_df.to_csv(f'{output_dir}cumulative_data_stop_{stop_point_id}.csv', index=False)\n",
        "\n",
        "            if cumulative_df_new.empty:\n",
        "                print(\"No data available in cumulative_df_new.\")\n",
        "                first_row = None  # Assign None or handle the absence of data appropriately\n",
        "            else:\n",
        "                first_row = cumulative_df_new.iloc[0]\n",
        "                #print(first_row)\n",
        "                # Retrieve the 'Expected Arrival (BST)' value and extract the time part\n",
        "                expected_arrival_time = first_row['Expected Arrival (BST)'].time()\n",
        "                #print(f\"Expected arrival time: {expected_arrival_time}\")\n",
        "\n",
        "                timetable_dict[stop_point_id] = timetable_df\n",
        "                #print(f\"timetable: {timetable_df}\")\n",
        "\n",
        "                # Create a function to convert 'Scheduled Time' to a datetime.time object\n",
        "                def to_time(time_str):\n",
        "                    return datetime.strptime(time_str, '%H:%M').time()\n",
        "\n",
        "                # Apply the function to the 'Scheduled Time' column\n",
        "                timetable_df['Scheduled Time Only'] = timetable_df['Scheduled Time'].apply(to_time)\n",
        "\n",
        "                # Filter the rows where 'Scheduled Time Only' is greater than 'expected_arrival_time'\n",
        "                filtered_df = timetable_df[timetable_df['Scheduled Time Only'] > expected_arrival_time]\n",
        "\n",
        "                # Select the top 10 'Scheduled Time Only' values\n",
        "                top_20_scheduled_time = filtered_df['Scheduled Time Only'].head(20)\n",
        "                print(f\"top 20 schedule: {top_20_scheduled_time}\")\n",
        "\n",
        "                # Find the first row's scheduled time from top_20_scheduled_time\n",
        "                first_time = top_20_scheduled_time.iloc[0]\n",
        "\n",
        "                # Find the index of this time in the original timetable_df\n",
        "                index_of_first_time = timetable_df[timetable_df['Scheduled Time Only'] == first_time].index[0]\n",
        "\n",
        "                # Get the scheduled time immediately above it\n",
        "                if index_of_first_time > 0:\n",
        "                    previous_time = timetable_df.iloc[index_of_first_time - 1]['Scheduled Time Only']\n",
        "                else:\n",
        "                    # If it's the first element, there's no previous time\n",
        "                    previous_time = None\n",
        "\n",
        "                # Create a new DataFrame to include the previous time\n",
        "                if previous_time:\n",
        "                    top_21_scheduled_time = pd.concat([\n",
        "                        pd.Series([previous_time], name='Scheduled Time Only'),\n",
        "                        top_20_scheduled_time\n",
        "                    ]).drop_duplicates().reset_index(drop=True)\n",
        "                else:\n",
        "                    top_21_scheduled_time = top_20_scheduled_time.reset_index(drop=True)\n",
        "\n",
        "                # Print the result\n",
        "                print(\"Updated top 20 'Scheduled Time Only' values including the time immediately above the first element:\")\n",
        "                print(top_21_scheduled_time)\n",
        "\n",
        "                # Number of rows in cumulative_df\n",
        "                num_rows_cumulative_new = len(cumulative_df_new)\n",
        "\n",
        "                # Fetch the first 'num_rows_cumulative' scheduled times from top_21_scheduled_time\n",
        "                scheduled_times_to_add = top_21_scheduled_time.head(num_rows_cumulative_new)\n",
        "\n",
        "                # Add these scheduled times as a new column in cumulative_df\n",
        "                cumulative_df_new['Scheduled Time'] = scheduled_times_to_add.values\n",
        "\n",
        "                # Print the updated cumulative_df\n",
        "                print(\"\\nUpdated cumulative_df with new 'Scheduled Time' column:\")\n",
        "                print(cumulative_df_new)\n",
        "\n",
        "                # Define the BST timezone\n",
        "                bst = pytz.timezone('Europe/London')\n",
        "\n",
        "                # Get the current time in BST\n",
        "                current_time_bst = datetime.now(bst)\n",
        "\n",
        "                # Fetch the current hour in BST\n",
        "                current_hour_bst = current_time_bst.hour\n",
        "\n",
        "                # Fetch the last row's 'Scheduled Time' from the updated cumulative_df\n",
        "                last_row_scheduled_time = cumulative_df_new['Scheduled Time'].iloc[-1]\n",
        "\n",
        "                # Convert the last_row_scheduled_time to BST if it's not already\n",
        "                # Assuming last_row_scheduled_time is naive (no timezone info)\n",
        "                last_row_scheduled_time_bst = last_row_scheduled_time.replace(tzinfo=bst)\n",
        "\n",
        "                # Print the last row's 'Scheduled Time'\n",
        "                print(\"\\nLast row's 'Scheduled Time' in cumulative_df (BST):\")\n",
        "                print(last_row_scheduled_time_bst)\n",
        "\n",
        "                # Fetch the scheduled times from timetable_df that meet the criteria\n",
        "                filtered_times = timetable_df[\n",
        "                    (timetable_df['Scheduled Time Only'] > last_row_scheduled_time_bst) &\n",
        "                    (timetable_df['Scheduled Time Only'].apply(lambda x: x.hour).isin([current_hour_bst, current_hour_bst + 1, current_hour_bst + 2]))\n",
        "                ]\n",
        "\n",
        "                # Print the filtered scheduled times\n",
        "                print(\"\\nScheduled times greater than last_row_scheduled_time in BST and within the next 3 hours:\")\n",
        "                print(filtered_times['Scheduled Time Only'])\n",
        "\n",
        "                # Step 1: Find the shape of `filtered_times['Scheduled Time Only']`\n",
        "                filtered_times_shape = filtered_times['Scheduled Time Only'].shape[0]\n",
        "\n",
        "                # Step 2: Create new rows with the filtered scheduled times\n",
        "                new_rows = pd.DataFrame({\n",
        "                    'Scheduled Time': filtered_times['Scheduled Time Only'].values,\n",
        "                    'Line': [cumulative_df_new['Line'].iloc[-1]] * filtered_times_shape,\n",
        "                    'Stop Point': [cumulative_df_new['Stop Point'].iloc[-1]] * filtered_times_shape,\n",
        "                    'Direction': [cumulative_df_new['Direction'].iloc[-1]] * filtered_times_shape,\n",
        "                    'Vehicle ID': [f\"{str(cumulative_df_new['Stop Point'].iloc[-1])[-4:]}_{i+1}\" for i in range(filtered_times_shape)],\n",
        "                    'Expected Arrival (BST)': [0] * filtered_times_shape,\n",
        "                    'Expected Arrival (HM)': [0] * filtered_times_shape,\n",
        "                    'Gap': [0] * filtered_times_shape,\n",
        "                    '2_Gap': [0] * filtered_times_shape,\n",
        "                    'Gap_Sq': [0] * filtered_times_shape\n",
        "                })\n",
        "\n",
        "                # Step 3: Append the new rows to the `cumulative_df`\n",
        "                cumulative_df_new = pd.concat([cumulative_df_new, new_rows], ignore_index=True)\n",
        "\n",
        "                # Step 4: Print the updated cumulative_df\n",
        "                print(\"\\nUpdated cumulative_df after appending new rows:\")\n",
        "                print(cumulative_df_new)\n",
        "\n",
        "                #print(\"\\nData types of each column in cumulative_df_new:\")\n",
        "                #print(cumulative_df_new.dtypes)\n",
        "\n",
        "\n",
        "\n",
        "                # Function to convert time string to seconds since start of day\n",
        "                def time_to_seconds(time_input):\n",
        "                    if isinstance(time_input, str):\n",
        "                        # Parse string to datetime.time\n",
        "                        t = datetime.strptime(time_input, '%H:%M:%S').time()\n",
        "                    elif isinstance(time_input, dt_time):\n",
        "                        # If it's already a datetime.time object\n",
        "                        t = time_input\n",
        "                    else:\n",
        "                        raise TypeError(f\"Unexpected type: {type(time_input)}\")\n",
        "                    return t.hour * 3600 + t.minute * 60 + t.second\n",
        "\n",
        "                # Function to convert seconds to time string with current date\n",
        "                def seconds_to_time(seconds, date_str):\n",
        "                    return (datetime.strptime(date_str, '%Y-%m-%d') + timedelta(seconds=seconds)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "                # Function to format the time string to hours and minutes with `00` for seconds\n",
        "                def format_time_str(time_str):\n",
        "                    try:\n",
        "                        return f\"{time_str.split(':')[0]}:{time_str.split(':')[1]}:00\"\n",
        "                    except IndexError:\n",
        "                        return '00:00:00'\n",
        "\n",
        "                # Convert 'Scheduled Time' and 'Expected Arrival (BST)' in the training data to seconds\n",
        "                # Function to convert time string or Timestamp to seconds\n",
        "                def convert_to_seconds(time_input):\n",
        "                    if isinstance(time_input, str):\n",
        "                        try:\n",
        "                            # Extract the time part from the string\n",
        "                            time_part = time_input.split()[1]\n",
        "                            return time_to_seconds(time_part)\n",
        "                        except IndexError:\n",
        "                            return np.nan\n",
        "                    elif isinstance(time_input, pd.Timestamp):\n",
        "                        # Convert Timestamp to time string\n",
        "                        time_str = time_input.time().strftime('%H:%M:%S')\n",
        "                        return time_to_seconds(time_str)\n",
        "                    elif isinstance(time_input, int):\n",
        "                        # If it's already an integer, assume it's in seconds\n",
        "                        return time_input\n",
        "                    else:\n",
        "                        raise TypeError(f\"Unexpected type: {type(time_input)}\")\n",
        "\n",
        "                # Load the training data from Google Drive\n",
        "                file_path_train = '/content/drive/My Drive/Files/Training_set.csv'\n",
        "                df_train = pd.read_csv(file_path_train)\n",
        "\n",
        "                #printing new_data\n",
        "                print(\"\\nprinting df train1:\")\n",
        "                print(df_train)\n",
        "\n",
        "                # Convert 'Scheduled Time' and 'Expected Arrival (BST)' in the training data to seconds\n",
        "                df_train['Scheduled Time (seconds)'] = df_train['Scheduled Time'].apply(time_to_seconds)\n",
        "\n",
        "                # Convert 'Expected Arrival (BST)' to seconds, handling cases where the value doesn't split correctly\n",
        "                df_train['Expected Arrival (BST) (seconds)'] = df_train['Expected Arrival (BST)'].apply(time_to_seconds)\n",
        "\n",
        "\n",
        "                #printing new_data\n",
        "                print(\"\\nprinting df train2:\")\n",
        "                print(df_train)\n",
        "\n",
        "                # Filter out rows with NaN in 'Expected Arrival (BST) (seconds)' column\n",
        "                df_train = df_train.dropna(subset=['Expected Arrival (BST) (seconds)'])\n",
        "\n",
        "                #printing new_data\n",
        "                print(\"\\nprinting df train3:\")\n",
        "                print(df_train)\n",
        "\n",
        "\n",
        "                # Assuming cumulative_df_new is already defined and available\n",
        "                # Filter cumulative_df_new to get rows where Expected Arrival (BST) is not zero\n",
        "                # For numeric data types (int or float)\n",
        "                non_zero_df = cumulative_df_new[cumulative_df_new['Expected Arrival (BST)'] != 0]\n",
        "\n",
        "                print(\"\\nprinting non_zero_df:\")\n",
        "                print(non_zero_df)\n",
        "\n",
        "                # Extract scheduled time and expected arrival from cumulative_df_new into new_data DataFrame\n",
        "                new_data = pd.DataFrame({\n",
        "                    'Scheduled Time': non_zero_df['Scheduled Time'],\n",
        "                    'Expected Arrival (BST)': non_zero_df['Expected Arrival (BST)']\n",
        "                })\n",
        "\n",
        "                print(\"\\nprinting new data 1:\")\n",
        "                print(new_data)\n",
        "\n",
        "\n",
        "                # Convert new_data columns to seconds\n",
        "                new_data['Scheduled Time (seconds)'] = new_data['Scheduled Time'].apply(time_to_seconds)\n",
        "                new_data['Expected Arrival (BST) (seconds)'] = new_data['Expected Arrival (BST)'].apply(convert_to_seconds)\n",
        "\n",
        "                print(\"\\nprinting new data 2:\")\n",
        "                print(new_data)\n",
        "\n",
        "                # Filter out rows with NaN in the new_data DataFrame\n",
        "                new_data = new_data.dropna(subset=['Expected Arrival (BST) (seconds)'])\n",
        "                print(\"\\nprinting new data 3:\")\n",
        "                print(new_data)\n",
        "\n",
        "\n",
        "\n",
        "                # Append new_data to your existing DataFrame for training\n",
        "                df_train = pd.concat([df_train, new_data], ignore_index=True)\n",
        "                print(\"\\nprinting df train4:\")\n",
        "                print(df_train)\n",
        "\n",
        "                # Define features (X) and target (y) for training\n",
        "                X = df_train[['Scheduled Time (seconds)']]\n",
        "                y = df_train['Expected Arrival (BST) (seconds)']\n",
        "\n",
        "                print(\"\\nprinting X :\")\n",
        "                print(X)\n",
        "                print(\"\\nprinting y:\")\n",
        "                print(y)\n",
        "                # Initialize and train the Linear Regression model\n",
        "                model = LinearRegression()\n",
        "                model.fit(X, y)\n",
        "\n",
        "                # Extract scheduled times where Expected Arrival (BST) is zero\n",
        "                zero_arrival_df = cumulative_df_new[cumulative_df_new['Expected Arrival (BST)'] == 0]\n",
        "                print(\"\\nprinting zero_arrival_df:\")\n",
        "                print(zero_arrival_df)\n",
        "\n",
        "                #new_scheduled_times = zero_arrival_df['Scheduled Time'].tolist()\n",
        "                #print(\"\\nprinting new_scheduled_times1:\")\n",
        "                #print(new_scheduled_times)\n",
        "                new_scheduled_times = [str(time).zfill(8) for time in zero_arrival_df['Scheduled Time']]\n",
        "                print(\"\\nprinting new_scheduled_times2:\")\n",
        "                print(new_scheduled_times)\n",
        "                # Convert new scheduled times to seconds\n",
        "                new_scheduled_times_seconds = [time_to_seconds(t) for t in new_scheduled_times]\n",
        "                print(\"\\nprinting new_scheduled_times3:\")\n",
        "                print(new_scheduled_times)\n",
        "                # Predict expected arrival times\n",
        "                predicted_seconds = model.predict(pd.DataFrame({'Scheduled Time (seconds)': new_scheduled_times_seconds}))\n",
        "                print(\"\\nprinting predicted_seconds:\")\n",
        "                print(predicted_seconds)\n",
        "                # Adjust predictions\n",
        "                adjusted_predictions_seconds = []\n",
        "                previous_expected_seconds = new_scheduled_times_seconds[0]\n",
        "                print(\"\\nprinting previous_expected_seconds:\")\n",
        "                print(previous_expected_seconds)\n",
        "\n",
        "                #for i, (scheduled_sec, predicted_sec) in enumerate(zip(new_scheduled_times_seconds, predicted_seconds)):\n",
        "                    #if predicted_sec <= scheduled_sec:\n",
        "                        #predicted_sec = scheduled_sec + 60\n",
        "                    #if i > 0 and predicted_sec <= adjusted_predictions_seconds[-1]:\n",
        "                        #predicted_sec = adjusted_predictions_seconds[-1] + 60\n",
        "                    #adjusted_predictions_seconds.append(predicted_sec)\n",
        "\n",
        "\n",
        "                for i, (scheduled_sec, predicted_sec) in enumerate(zip(new_scheduled_times_seconds, predicted_seconds)):\n",
        "                    while predicted_sec <= scheduled_sec or (i > 0 and predicted_sec <= adjusted_predictions_seconds[-1]):\n",
        "                        predicted_sec += 60  # Add 1 minute\n",
        "                    adjusted_predictions_seconds.append(predicted_sec)\n",
        "\n",
        "                # Get current date\n",
        "                current_date = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "                # Convert adjusted predictions to time strings with the current date\n",
        "                adjusted_times = [seconds_to_time(sec, current_date) for sec in adjusted_predictions_seconds]\n",
        "                print(\"\\nprinting adjusted_times:\")\n",
        "                print(adjusted_times)\n",
        "                # Update cumulative_df_new with the adjusted times\n",
        "                cumulative_df_new.loc[zero_arrival_df.index, 'Expected Arrival (BST)'] = adjusted_times\n",
        "                print(\"\\nprinting cumulative_df with adjusted_times2:\")\n",
        "                print(cumulative_df_new)\n",
        "                # Update 'Expected Arrival (HM)' for rows where value is '0'\n",
        "                # Extract the date from the first non-zero 'Expected Arrival (HM)' element\n",
        "                #first_hm_date = cumulative_df_new.loc[cumulative_df_new['Expected Arrival (HM)'] != '0', 'Expected Arrival (HM)'].iloc[0].split()[0]\n",
        "                first_hm_date = '1900-01-01'\n",
        "                print(\"\\nprinting first_hm_date:\")\n",
        "                print(first_hm_date)\n",
        "                print(\"\\nData type of first_hm_date:\", type(first_hm_date))\n",
        "                def update_hm(row):\n",
        "                    if row['Expected Arrival (HM)'] == 0:\n",
        "                        bst_time = row['Expected Arrival (BST)'].split()[1]\n",
        "                        return f\"{first_hm_date} {format_time_str(bst_time)}\"\n",
        "                    return row['Expected Arrival (HM)']\n",
        "                print(\"\\nprinting cumulative_df with before Expected arrival HM modified:\")\n",
        "                print(cumulative_df_new)\n",
        "                cumulative_df_new['Expected Arrival (HM)'] = cumulative_df_new.apply(update_hm, axis=1)\n",
        "                print(\"\\nprinting cumulative_df with Expected arrival HM modified:\")\n",
        "                print(cumulative_df_new)\n",
        "                # Select the last 10 columns\n",
        "                #cumulative_df_new_10 = cumulative_df_new.iloc[:, -10:]\n",
        "\n",
        "\n",
        "                #print(\"\\nprinting cumulative_df with last 10 columns:\")\n",
        "                #print(cumulative_df_new_10)\n",
        "\n",
        "\n",
        "\n",
        "                # Calculate 'Gap', '2_Gap', and 'Gap_Sq'\n",
        "                # Convert 'Expected Arrival (BST)' to datetime\n",
        "                cumulative_df_new['Expected Arrival (BST)'] = pd.to_datetime(cumulative_df_new['Expected Arrival (BST)'], format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "                # Calculate 'Gap' as the difference between successive 'Expected Arrival (BST)' times in minutes\n",
        "                cumulative_df_new['Gap'] = cumulative_df_new['Expected Arrival (BST)'].diff().dt.total_seconds() / 60\n",
        "                cumulative_df_new['Gap'] = cumulative_df_new['Gap'].round(2)\n",
        "\n",
        "                # Set the first row 'Gap' to 0\n",
        "                cumulative_df_new.loc[0, 'Gap'] = 0.0\n",
        "\n",
        "                # Calculate '2_Gap' as twice the 'Gap'\n",
        "                cumulative_df_new['2_Gap'] = (cumulative_df_new['Gap'] * 2).round(2)\n",
        "\n",
        "                # Calculate 'Gap_Sq' as the square of the 'Gap'\n",
        "                cumulative_df_new['Gap_Sq'] = (cumulative_df_new['Gap'] * cumulative_df_new['Gap']).round(2)\n",
        "\n",
        "                # Print the updated cumulative_df_new with calculated values\n",
        "                print(\"\\nprinting cumulative_df with last 10 columns:\")\n",
        "                print(cumulative_df_new)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\nRoute {lineID} SWT DataFrame:\")\n",
        "        print(route_swt_df)\n",
        "        double_headway_a, double_headway_b = fetch_current_hour_swt(route_swt_df)\n",
        "\n",
        "        if double_headway_a is not None and double_headway_b is not None:\n",
        "          results_df = check_gaps_against_double_headway(cumulative_dataframes, double_headway_a, double_headway_b, combined_df, lineID)\n",
        "\n",
        "          #print(\"\\nVehicle IDs and Stop Points where Gap exceeds Double Headway:\")\n",
        "          #print(results_df.to_string(index=False))\n",
        "\n",
        "        # Create DataFrame to show number of buses observed for each stop point\n",
        "        buses_observed_df = pd.DataFrame(list(buses_observed.items()), columns=['Stop Point', 'Metrics'])\n",
        "        buses_observed_df_new = pd.DataFrame(list(buses_observed_new.items()), columns=['Stop Point', 'Metrics'])\n",
        "\n",
        "        # Split 'Metrics' into separate columns\n",
        "        buses_observed_df[['Num of Buses Observed', 'Total Gap Sq', 'Total 2 Gap', 'AWT']] = pd.DataFrame(\n",
        "            buses_observed_df['Metrics'].tolist(), index=buses_observed_df.index\n",
        "        )\n",
        "\n",
        "        buses_observed_df_new[['Num of Buses Observed', 'Total Gap Sq', 'Total 2 Gap', 'AWT']] = pd.DataFrame(\n",
        "            buses_observed_df_new['Metrics'].tolist(), index=buses_observed_df_new.index\n",
        "        )\n",
        "\n",
        "        # Calculate WAWT as the product of AWT and Num of Buses Observed\n",
        "        buses_observed_df['WAWT'] = buses_observed_df['AWT'] * buses_observed_df['Num of Buses Observed']\n",
        "        buses_observed_df_new['WAWT'] = buses_observed_df_new['AWT'] * buses_observed_df_new['Num of Buses Observed']\n",
        "\n",
        "        # Drop the 'Metrics' column\n",
        "        buses_observed_df.drop(columns=['Metrics'], inplace=True)\n",
        "        buses_observed_df_new.drop(columns=['Metrics'], inplace=True)\n",
        "\n",
        "        current_hour = datetime.now(pytz.timezone('Europe/London')).hour\n",
        "        next_hour = (current_hour + 1)\n",
        "\n",
        "        buses_observed_df['Line'] = lineID\n",
        "        buses_observed_df['Hour'] = current_hour\n",
        "\n",
        "        buses_observed_df_new['Line'] = lineID\n",
        "        buses_observed_df_new['Hour'] = next_hour\n",
        "\n",
        "        # Reorder columns to make 'Hour' the first column\n",
        "        columns_order = ['Line'] + ['Hour'] + [col for col in buses_observed_df.columns if col not in ['Hour', 'Line']]\n",
        "        buses_observed_df = buses_observed_df[columns_order]\n",
        "\n",
        "\n",
        "        columns_order_new = ['Line'] + ['Hour'] + [col for col in buses_observed_df_new.columns if col not in ['Hour', 'Line']]\n",
        "        buses_observed_df_new = buses_observed_df_new[columns_order_new]\n",
        "\n",
        "        print(f\"\\nNumber of Buses Observed DataFrame for Route:{lineID}\")\n",
        "        print(buses_observed_df)\n",
        "\n",
        "        print(f\"\\nNumber of Buses Forecasted DataFrame for Route:{lineID}\")\n",
        "        print(buses_observed_df_new)\n",
        "\n",
        "        # Calculate Route AWT A and Route AWT B\n",
        "        pattern_A = f\"^{lineID}_A\\\\d+$\"\n",
        "        pattern_B = f\"^{lineID}_B\\\\d+$\"\n",
        "\n",
        "        buses_observed_df_A = buses_observed_df[buses_observed_df['Stop Point'].isin(combined_df[combined_df['Route_Dir_QSI_No'].str.match(pattern_A)]['ID'])]\n",
        "        buses_observed_df_B = buses_observed_df[buses_observed_df['Stop Point'].isin(combined_df[combined_df['Route_Dir_QSI_No'].str.match(pattern_B)]['ID'])]\n",
        "\n",
        "        sum_WAWT_A = buses_observed_df_A['WAWT'].sum()\n",
        "        sum_buses_observed_A = buses_observed_df_A['Num of Buses Observed'].sum()\n",
        "        route_AWT_A = round(sum_WAWT_A / sum_buses_observed_A, 2) if sum_buses_observed_A > 0 else 0\n",
        "\n",
        "        sum_WAWT_B = buses_observed_df_B['WAWT'].sum()\n",
        "        sum_buses_observed_B = buses_observed_df_B['Num of Buses Observed'].sum()\n",
        "        route_AWT_B = round(sum_WAWT_B / sum_buses_observed_B, 2) if sum_buses_observed_B > 0 else 0\n",
        "\n",
        "        if 'Route' not in route_awt_df.columns:\n",
        "          route_awt_df['Route'] = lineID\n",
        "\n",
        "        # Check if the current hour's data is already present\n",
        "        if current_hour in route_awt_df['Hour'].values:\n",
        "            route_awt_df.loc[route_awt_df['Hour'] == current_hour, ['Route AWT A', 'Route AWT B']] = [route_AWT_A, route_AWT_B]\n",
        "        else:\n",
        "            new_row = pd.DataFrame({\n",
        "                'Route': [lineID],\n",
        "                'Hour': [current_hour],\n",
        "                'Route AWT A': [route_AWT_A],\n",
        "                'Route AWT B': [route_AWT_B]\n",
        "            })\n",
        "            route_awt_df = pd.concat([route_awt_df, new_row], ignore_index=True)\n",
        "\n",
        "\n",
        "        columns_order = ['Route'] + [col for col in route_awt_df.columns if col != 'Route']\n",
        "        route_awt_df = route_awt_df[columns_order]\n",
        "\n",
        "\n",
        "        route_ewt_df = pd.DataFrame(columns=['Route','Hour', 'Route EWT A', 'Route EWT B'])\n",
        "        current_hour = datetime.now(pytz.timezone('Europe/London')).hour\n",
        "        route_ewt_df = pd.DataFrame([[lineID,current_hour, None, None]], columns=['Route','Hour', 'Route EWT A','Route EWT B'])\n",
        "\n",
        "        # Merge route_awt_df and route_swt_df on 'Hour'\n",
        "        merged_df = pd.merge(route_awt_df, route_swt_df, on='Hour')\n",
        "\n",
        "\n",
        "        # Calculate the 'Route EWT A' and 'Route EWT B' columns\n",
        "        merged_df['Route EWT A'] = merged_df['Route AWT A'] - merged_df['Route SWT A']\n",
        "        merged_df['Route EWT B'] = merged_df['Route AWT B'] - merged_df['Route SWT B']\n",
        "\n",
        "        lineID_sheet2 = str(lineID)\n",
        "        df_sheet2['Route'] = df_sheet2['Route'].astype(str)\n",
        "        MPS_data = df_sheet2[(df_sheet2['Route'] == lineID_sheet2) | (df_sheet2['Route'] == lineID)]\n",
        "        MPS = MPS_data['MPS'].iloc[0]\n",
        "        print(f\"\\n\\033[1m\\033[4mMPS for Route {lineID} is {MPS}\\033[0m\\n\")\n",
        "\n",
        "        # Calculate the 'Route EWT (var) A' and 'Route EWT (var) B' columns\n",
        "        merged_df['Route EWT VAR A'] = merged_df['Route EWT A'] - MPS\n",
        "        merged_df['Route EWT VAR B'] = merged_df['Route EWT B'] - MPS\n",
        "\n",
        "        # Reorder the columns so that 'Route EWT A' and 'Route EWT B' are after 'Route SWT B'\n",
        "        new_columns_order = ['Route', 'Hour', 'Route SWT A', 'Route AWT A', 'Route EWT A', 'Route EWT VAR A', 'Route SWT B', 'Route AWT B', 'Route EWT B' , 'Route EWT VAR B']\n",
        "        merged_df = merged_df[new_columns_order]\n",
        "\n",
        "        # Split the DataFrame for Route A and Route B\n",
        "        route_A_df = merged_df[['Route','Hour', 'Route SWT A', 'Route AWT A', 'Route EWT A', 'Route EWT VAR A']]\n",
        "        route_B_df = merged_df[['Route','Hour', 'Route SWT B', 'Route AWT B', 'Route EWT B', 'Route EWT VAR B']]\n",
        "\n",
        "        route_A_df = route_A_df.rename(columns={'Route': 'Line'})\n",
        "        route_B_df = route_B_df.rename(columns={'Route': 'Line'})\n",
        "\n",
        "        print(f\"\\nSWT, AWT, and EWT of Route {lineID} in direction A:\")\n",
        "        print(route_A_df)\n",
        "\n",
        "        print(f\"\\nSWT, AWT, and EWT of Route {lineID} in direction B:\")\n",
        "        print(route_B_df)\n",
        "\n",
        "        # Save DataFrames to CSV\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Save DataFrames to Google Drive\n",
        "        route_swt_df.to_csv(os.path.join(output_dir, 'route_swt_df.csv'), index=False)\n",
        "        results_df.to_csv(os.path.join(output_dir, 'results_df.csv'), index=False)\n",
        "        route_A_df.to_csv(os.path.join(output_dir, 'route_A_df.csv'), index=False)\n",
        "        route_B_df.to_csv(os.path.join(output_dir, 'route_B_df.csv'), index=False)\n",
        "\n",
        "\n",
        "        print(f\"CSV files saved to 'output' directory.\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}