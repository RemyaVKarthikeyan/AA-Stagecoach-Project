{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/Merging_codes_19_07_2024_12_00_Route_AWT_A_and_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9d1YrLY32J8"
      },
      "source": [
        "with dataframe showing the number of buses observed in an hr and AWT calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFDa5DVspn8"
      },
      "source": [
        "19/07/2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c611ccf2-7dc3-4ad8-e437-f4c0cff91283",
        "id": "B96pX7wQp0Nl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the lineID: d7\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction D7_A\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                    STOP_Name          ID\n",
            "0            D7_A1   Poplar / All Saints Church  490011107G\n",
            "1            D7_A2               Stewart Street  490013513S\n",
            "2            D7_A3       Island Gardens Station  490002048Z\n",
            "3            D7_A4  Arnhem Wharf Primary School  490006092N\n",
            "5            D7_A5         East India Dock Road  490004584N\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction D7_B\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                    STOP_Name          ID\n",
            "0            D7_B1  Mile End Station / Bow Road  490015151H\n",
            "2            D7_B2         East India Dock Road  490004584S\n",
            "3            D7_B3         Canary Wharf Station  490000038F\n",
            "5            D7_B4  Arnhem Wharf Primary School  490006092S\n",
            "6            D7_B5       Island Gardens Station  490002048X\n",
            "7            D7_B6               Stewart Street  490013513N\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mCombined QSI stop points for directions A and B\u001b[0m\n",
            "\n",
            "   Route_Dir_QSI_No                    STOP_Name          ID\n",
            "0             D7_A1   Poplar / All Saints Church  490011107G\n",
            "1             D7_A2               Stewart Street  490013513S\n",
            "2             D7_A3       Island Gardens Station  490002048Z\n",
            "3             D7_A4  Arnhem Wharf Primary School  490006092N\n",
            "4             D7_A5         East India Dock Road  490004584N\n",
            "5             D7_B1  Mile End Station / Bow Road  490015151H\n",
            "6             D7_B2         East India Dock Road  490004584S\n",
            "7             D7_B3         Canary Wharf Station  490000038F\n",
            "8             D7_B4  Arnhem Wharf Primary School  490006092S\n",
            "9             D7_B5       Island Gardens Station  490002048X\n",
            "10            D7_B6               Stewart Street  490013513N\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Modify this path accordingly\n",
        "file_path = '/content/QSI points.xlsx'\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Get the lineID from the user\n",
        "lineID = input(\"Please enter the lineID: \")\n",
        "\n",
        "# Check if the necessary column is present\n",
        "if 'Route_Dir_QSI_No' not in df.columns:\n",
        "    print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "else:\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Create regular expressions for filtering\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for lineID_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for lineID_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "\n",
        "    # Function to fetch and process route sequence data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    matched_results_df_A = matched_results_df_A[matched_results_df_A['Route_Dir_QSI_No'].str.match(pattern_A)]\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    matched_results_df_B = matched_results_df_B[matched_results_df_B['Route_Dir_QSI_No'].str.match(pattern_B)]\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # Display the combined DataFrame\n",
        "    print(\"\\n\\n\\033[1m\\033[4mCombined QSI stop points for directions A and B\\033[0m\\n\")\n",
        "    print(combined_df[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import time\n",
        "\n",
        "# Function to fetch arrival predictions\n",
        "def fetch_arrival_predictions(line_id, stop_point_id, direction):\n",
        "    try:\n",
        "        base_url = f\"https://api.tfl.gov.uk/Line/{line_id}/Arrivals/{stop_point_id}\"\n",
        "        params = {'direction': direction}\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if len(data) == 0:\n",
        "            return pd.DataFrame(), None  # No data available\n",
        "        station_name = data[0]['stationName']\n",
        "        predictions = []\n",
        "        for item in data:\n",
        "            arrival_time = datetime.strptime(item['expectedArrival'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            arrival_time_bst = arrival_time + timedelta(hours=1)\n",
        "            predictions.append({\n",
        "                'Line': item['lineName'],\n",
        "                'Vehicle ID': item['vehicleId'],\n",
        "                'Stop Point': stop_point_id,\n",
        "                'Direction': direction,\n",
        "                'Expected Arrival (BST)': arrival_time_bst,\n",
        "                'Expected Arrival (HM)': arrival_time_bst.strftime('%H:%M')\n",
        "            })\n",
        "        df = pd.DataFrame(predictions)\n",
        "        df = df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "        df['Expected Arrival (BST)'] = pd.to_datetime(df['Expected Arrival (BST)'])  # Convert to datetime\n",
        "        df['Expected Arrival (HM)'] = pd.to_datetime(df['Expected Arrival (HM)'], format='%H:%M')\n",
        "        df['Gap'] = df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "        df['2_Gap'] = (df['Gap'] * 2).round(2)\n",
        "        df['Gap_Sq'] = (df['Gap'] * df['Gap']).round(2)\n",
        "        return df, station_name\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    # Assuming combined_df is generated from the previous cell\n",
        "    # combined_df should have columns like 'Route_Dir_QSI_No', 'STOP_Name', 'ID'\n",
        "    import pandas as pd\n",
        "    import requests\n",
        "    from datetime import datetime\n",
        "    import pytz\n",
        "\n",
        "    # Function to normalize stop names\n",
        "    def normalize_stop_name(name):\n",
        "        return ' '.join(name.lower().split())\n",
        "\n",
        "    # Function to fetch data from the API\n",
        "    def fetch_data(url):\n",
        "        response = requests.get(url)\n",
        "        return response.json()\n",
        "\n",
        "    # Function to extract schedule names\n",
        "    def extract_schedule_names(data, schedule_names_dict={}):\n",
        "        if isinstance(data, dict):\n",
        "            if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "                if 'name' in data:\n",
        "                    schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "            for key, value in data.items():\n",
        "                extract_schedule_names(value, schedule_names_dict)\n",
        "        elif isinstance(data, list):\n",
        "            for item in data:\n",
        "                extract_schedule_names(item, schedule_names_dict)\n",
        "        return schedule_names_dict\n",
        "\n",
        "    # Function to categorize journeys into hourly slots\n",
        "    def categorize_into_slots(timetable):\n",
        "        slots = [[] for _ in range(24)]\n",
        "        for journey in timetable:\n",
        "            hour = int(journey['hour'])  # Convert hour to integer\n",
        "            if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "                slots[hour].append(journey)\n",
        "        return slots\n",
        "\n",
        "    # Function to fetch the current day of the week\n",
        "    def get_day_of_week():\n",
        "        bst = pytz.timezone('Europe/London')\n",
        "        now = datetime.now(bst)\n",
        "        return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "    # Function to calculate Scheduled Wait Time (SWT) for all hours\n",
        "    def calculate_swt_for_all_hours(slots):\n",
        "        swt_per_hour = []\n",
        "        for hour in range(24):\n",
        "            total_buses = len(slots[hour])\n",
        "            scheduled_wait_time = 60 / (total_buses * 2) if total_buses > 0 else None  # Use None to indicate no buses\n",
        "            swt_per_hour.append((scheduled_wait_time, total_buses))\n",
        "        return swt_per_hour\n",
        "\n",
        "    # Function to select the preferred schedule name based on the current day of the week\n",
        "    def select_preferred_schedule(schedule_names_dict, day_of_week):\n",
        "        if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "            preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "        elif day_of_week.lower() == 'friday':\n",
        "            preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "        elif day_of_week.lower() == 'saturday':\n",
        "            preferred_schedule_names = ['Saturday']\n",
        "        elif day_of_week.lower() == 'sunday':\n",
        "            preferred_schedule_names = ['Sunday']\n",
        "        else:\n",
        "            preferred_schedule_names = [day_of_week]\n",
        "\n",
        "        for preferred_name in preferred_schedule_names:\n",
        "            if preferred_name in schedule_names_dict:\n",
        "                return preferred_name\n",
        "        return None\n",
        "\n",
        "    # Main logic to fetch and calculate SWT\n",
        "    def main(combined_df, lineID):\n",
        "        bst = pytz.timezone('Europe/London')\n",
        "        swt_data = {\n",
        "            'Route_Dir_QSI_No': [],\n",
        "            'ID': [],\n",
        "        }\n",
        "        # Initialize keys for all 24 hours in the dictionary\n",
        "        for hour in range(24):\n",
        "            swt_data[f'SWT_{hour}'] = []\n",
        "            swt_data[f'Sch_{hour}'] = []\n",
        "\n",
        "        # Update current time and hour\n",
        "        current_time = datetime.now(bst)\n",
        "        day_of_week = get_day_of_week()\n",
        "\n",
        "        # Store selected schedule name to ensure it's printed only once\n",
        "        selected_schedule_name = None\n",
        "        printed_schedule_name = False\n",
        "\n",
        "        for index, row in combined_df.iterrows():\n",
        "            stop_point_id = row['ID']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "            if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "                direction = 'outbound'\n",
        "            elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "                direction = 'inbound'\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "            data = fetch_data(url)\n",
        "\n",
        "            schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "            if not selected_schedule_name:\n",
        "                selected_schedule_name = select_preferred_schedule(schedule_names_dict, day_of_week)\n",
        "\n",
        "            if selected_schedule_name and not printed_schedule_name:\n",
        "                print(f\"\\n\\033[1m\\033[4mToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\\033[0m\")\n",
        "                printed_schedule_name = True\n",
        "\n",
        "            if selected_schedule_name:\n",
        "                timetable = schedule_names_dict[selected_schedule_name]\n",
        "                slots = categorize_into_slots(timetable)\n",
        "\n",
        "                # Calculate SWT for all hours\n",
        "                swt_per_hour = calculate_swt_for_all_hours(slots)\n",
        "\n",
        "                # Store SWT data for all hours\n",
        "                swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "                swt_data['ID'].append(stop_point_id)\n",
        "                for hour in range(24):\n",
        "                    swt, total_buses = swt_per_hour[hour]\n",
        "                    swt_data[f'SWT_{hour}'].append(swt)\n",
        "                    swt_data[f'Sch_{hour}'].append(total_buses)\n",
        "\n",
        "        # Create DataFrame for SWT data\n",
        "        swt_df = pd.DataFrame(swt_data)\n",
        "\n",
        "        # Calculate Route SWT for each hour for directions A and B\n",
        "        route_swt_data = {\n",
        "            'Hour': [],\n",
        "            'Route SWT A': [],\n",
        "            'Route SWT B': []\n",
        "        }\n",
        "\n",
        "        for hour in range(24):\n",
        "            # Calculate Route SWT for direction A\n",
        "            swt_a = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_A')]\n",
        "            valid_swt_a = swt_a[pd.notna(swt_a[f'SWT_{hour}'])]  # Filter out NaN values\n",
        "            weighted_sum_a = sum(valid_swt_a[f'SWT_{hour}'] * valid_swt_a[f'Sch_{hour}']) if not valid_swt_a.empty else 0\n",
        "            total_buses_a = sum(valid_swt_a[f'Sch_{hour}']) if not valid_swt_a.empty else 0\n",
        "            route_swt_a = round(weighted_sum_a / total_buses_a, 2) if total_buses_a > 0 else None\n",
        "\n",
        "\n",
        "            # Calculate Route SWT for direction B\n",
        "            swt_b = swt_df[swt_df['Route_Dir_QSI_No'].str.contains(f'{lineID}_B')]\n",
        "            valid_swt_b = swt_b[pd.notna(swt_b[f'SWT_{hour}'])]  # Filter out NaN values\n",
        "            weighted_sum_b = sum(valid_swt_b[f'SWT_{hour}'] * valid_swt_b[f'Sch_{hour}']) if not valid_swt_b.empty else 0\n",
        "            total_buses_b = sum(valid_swt_b[f'Sch_{hour}']) if not valid_swt_b.empty else 0\n",
        "            route_swt_b = round(weighted_sum_b / total_buses_b, 2) if total_buses_b > 0 else None\n",
        "\n",
        "            route_swt_data['Hour'].append(hour)\n",
        "            route_swt_data['Route SWT A'].append(route_swt_a)\n",
        "            route_swt_data['Route SWT B'].append(route_swt_b)\n",
        "\n",
        "        route_swt_df = pd.DataFrame(route_swt_data)\n",
        "        return route_swt_df\n",
        "        # Print the Route SWT DataFrame\n",
        "        print(\"\\n\\nRoute SWT DataFrame:\")\n",
        "        print(route_swt_df.to_string())\n",
        "\n",
        "    # Assuming combined_df and lineID are defined and available\n",
        "    # combined_df = ... (from previous code)\n",
        "    # lineID = ... (from user input)\n",
        "    route_swt_df = main(combined_df, lineID)\n",
        "    # Example dictionary to hold cumulative dataframes for each stop point\n",
        "    cumulative_dataframes = {}\n",
        "\n",
        "    # Dictionary to hold the number of buses observed per stop point\n",
        "    buses_observed = {}\n",
        "\n",
        "    # DataFrame to store Route AWT data\n",
        "    route_awt_df = pd.DataFrame(columns=['Hour', 'Route AWT A', 'Route AWT B'])\n",
        "\n",
        "    # Loop through unique stop points in combined_df\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        direction = 'outbound' if row['Route_Dir_QSI_No'].startswith(lineID + '_A') else 'inbound'\n",
        "\n",
        "        cumulative_df = pd.DataFrame(columns=[\n",
        "            'Line', 'Vehicle ID', 'Stop Point', 'Direction',\n",
        "            'Expected Arrival (BST)', 'Expected Arrival (HM)',\n",
        "            'Gap', '2_Gap', 'Gap_Sq'\n",
        "        ])\n",
        "\n",
        "        cumulative_dataframes[stop_point_id] = cumulative_df  # Initialize cumulative dataframe\n",
        "        buses_observed[stop_point_id] = (0, 0, 0, 0)  # Initialize with zero values\n",
        "\n",
        "    while True:\n",
        "        for stop_point_id, cumulative_df in cumulative_dataframes.items():\n",
        "            direction = 'outbound' if combined_df[combined_df['ID'] == stop_point_id]['Route_Dir_QSI_No'].iloc[0].startswith(lineID + '_A') else 'inbound'\n",
        "\n",
        "            arrival_predictions_df, station_name = fetch_arrival_predictions(lineID, stop_point_id, direction)\n",
        "\n",
        "            if arrival_predictions_df is not None and not arrival_predictions_df.empty:\n",
        "                current_hour = datetime.now(pytz.timezone('Europe/London')).hour\n",
        "\n",
        "                for _, row in arrival_predictions_df.iterrows():\n",
        "                    vehicle_id = row['Vehicle ID']\n",
        "                    expected_hour = row['Expected Arrival (BST)'].hour\n",
        "\n",
        "                    mask = cumulative_df['Vehicle ID'] == vehicle_id\n",
        "\n",
        "                    if cumulative_df[mask].empty:\n",
        "                        cumulative_df = pd.concat([cumulative_df, row.to_frame().T], ignore_index=True)\n",
        "                    else:\n",
        "                        existing_hour = cumulative_df.loc[mask, 'Expected Arrival (BST)'].iloc[0].hour\n",
        "\n",
        "                        if expected_hour > existing_hour + 1:\n",
        "                            cumulative_df = pd.concat([cumulative_df, row.to_frame().T], ignore_index=True)\n",
        "                        else:\n",
        "                            cumulative_df.loc[mask, ['Line', 'Stop Point', 'Direction', 'Expected Arrival (BST)', 'Expected Arrival (HM)', 'Gap', '2_Gap', 'Gap_Sq']] = row[['Line', 'Stop Point', 'Direction', 'Expected Arrival (BST)', 'Expected Arrival (HM)', 'Gap', '2_Gap', 'Gap_Sq']].values\n",
        "\n",
        "                cumulative_df = cumulative_df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "                cumulative_df['Expected Arrival (BST)'] = pd.to_datetime(cumulative_df['Expected Arrival (BST)'])\n",
        "                cumulative_df['Expected Arrival (HM)'] = pd.to_datetime(cumulative_df['Expected Arrival (HM)'], format='%H:%M')\n",
        "\n",
        "                cumulative_df['Gap'] = cumulative_df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "                cumulative_df['2_Gap'] = (cumulative_df['Gap'] * 2).round(2)\n",
        "                cumulative_df['Gap_Sq'] = (cumulative_df['Gap'] * cumulative_df['Gap']).round(2)\n",
        "\n",
        "                # Update number of buses observed in the current hour\n",
        "                num_buses_observed = cumulative_df[cumulative_df['Expected Arrival (BST)'].dt.hour == current_hour].shape[0]\n",
        "                total_Gap_Sq = cumulative_df[cumulative_df['Expected Arrival (BST)'].dt.hour == current_hour]['Gap_Sq'].sum()\n",
        "                total_2_Gap = cumulative_df[cumulative_df['Expected Arrival (BST)'].dt.hour == current_hour]['2_Gap'].sum()\n",
        "                AWT = round(total_Gap_Sq / total_2_Gap, 2) if total_2_Gap > 0 else 0\n",
        "                buses_observed[stop_point_id] = (num_buses_observed, total_Gap_Sq, total_2_Gap, AWT)\n",
        "\n",
        "                print(f\"\\nArrival Predictions for stop point {stop_point_id} ({station_name}):\")\n",
        "                print(arrival_predictions_df.to_string(index=False))\n",
        "                print(\"\\nCumulative DataFrame:\")\n",
        "                print(cumulative_df.to_string(index=False))\n",
        "                print(f\"\\nNumber of buses observed in the current hour: {num_buses_observed}\")\n",
        "            else:\n",
        "                print(\"No arrival predictions available.\")\n",
        "\n",
        "            print(\"Refreshing data in 30 seconds...\\n\")\n",
        "            time.sleep(30)\n",
        "\n",
        "            # Update cumulative dataframe in dictionary\n",
        "            cumulative_dataframes[stop_point_id] = cumulative_df\n",
        "\n",
        "        print(\"\\nRoute SWT DataFrame:\")\n",
        "        print(route_swt_df)\n",
        "\n",
        "        # Create DataFrame to show number of buses observed for each stop point\n",
        "        buses_observed_df = pd.DataFrame(list(buses_observed.items()), columns=['Stop Point', 'Metrics'])\n",
        "\n",
        "        # Split 'Metrics' into separate columns\n",
        "        buses_observed_df[['Num of Buses Observed', 'Total Gap Sq', 'Total 2 Gap', 'AWT']] = pd.DataFrame(\n",
        "            buses_observed_df['Metrics'].tolist(), index=buses_observed_df.index\n",
        "        )\n",
        "\n",
        "        # Calculate WAWT as the product of AWT and Num of Buses Observed\n",
        "        buses_observed_df['WAWT'] = buses_observed_df['AWT'] * buses_observed_df['Num of Buses Observed']\n",
        "\n",
        "        # Drop the 'Metrics' column\n",
        "        buses_observed_df.drop(columns=['Metrics'], inplace=True)\n",
        "\n",
        "        print(\"\\nNumber of Buses Observed DataFrame:\")\n",
        "        print(buses_observed_df)\n",
        "\n",
        "        # Calculate Route AWT A and Route AWT B\n",
        "        pattern_A = f\"^{lineID}_A\\\\d+$\"\n",
        "        pattern_B = f\"^{lineID}_B\\\\d+$\"\n",
        "\n",
        "        buses_observed_df_A = buses_observed_df[buses_observed_df['Stop Point'].isin(combined_df[combined_df['Route_Dir_QSI_No'].str.match(pattern_A)]['ID'])]\n",
        "        buses_observed_df_B = buses_observed_df[buses_observed_df['Stop Point'].isin(combined_df[combined_df['Route_Dir_QSI_No'].str.match(pattern_B)]['ID'])]\n",
        "\n",
        "        sum_WAWT_A = buses_observed_df_A['WAWT'].sum()\n",
        "        sum_buses_observed_A = buses_observed_df_A['Num of Buses Observed'].sum()\n",
        "        route_AWT_A = round(sum_WAWT_A / sum_buses_observed_A, 2) if sum_buses_observed_A > 0 else 0\n",
        "\n",
        "        sum_WAWT_B = buses_observed_df_B['WAWT'].sum()\n",
        "        sum_buses_observed_B = buses_observed_df_B['Num of Buses Observed'].sum()\n",
        "        route_AWT_B = round(sum_WAWT_B / sum_buses_observed_B, 2) if sum_buses_observed_B > 0 else 0\n",
        "\n",
        "        current_hour = datetime.now(pytz.timezone('Europe/London')).hour\n",
        "\n",
        "        # Check if the current hour's data is already present\n",
        "        if current_hour in route_awt_df['Hour'].values:\n",
        "            route_awt_df.loc[route_awt_df['Hour'] == current_hour, ['Route AWT A', 'Route AWT B']] = [route_AWT_A, route_AWT_B]\n",
        "        else:\n",
        "            new_row = pd.DataFrame({\n",
        "                'Hour': [current_hour],\n",
        "                'Route AWT A': [route_AWT_A],\n",
        "                'Route AWT B': [route_AWT_B]\n",
        "            })\n",
        "            route_awt_df = pd.concat([route_awt_df, new_row], ignore_index=True)\n",
        "\n",
        "        #print(\"\\nRoute SWT DataFrame:\")\n",
        "        #print(route_swt_df)\n",
        "\n",
        "        print(\"\\nRoute AWT DataFrame:\")\n",
        "        print(route_awt_df)\n",
        "        route_ewt_df = pd.DataFrame(columns=['Hour', 'Route EWT A', 'Route EWT Var A', 'Route EWT B', 'Route EWT Var B'])\n",
        "        current_hour = datetime.now().hour\n",
        "        route_ewt_df = pd.DataFrame([[current_hour, None, None, None, None]], columns=['Hour', 'Route EWT A', 'Route EWT Var A', 'Route EWT B', 'Route EWT Var B'])\n",
        "        #route_swt_df= main(combined_df, lineID)\n",
        "        # Merge route_awt_df and route_swt_df on 'Hour'\n",
        "        merged_df = pd.merge(route_awt_df, route_swt_df, on='Hour')\n",
        "\n",
        "        # Calculate the 'Route EWT A' and 'Route EWT B' columns\n",
        "        merged_df['Route EWT A'] = merged_df['Route AWT A'] - merged_df['Route SWT A']\n",
        "        merged_df['Route EWT B'] = merged_df['Route AWT B'] - merged_df['Route SWT B']\n",
        "\n",
        "        # Update route_ewt_df with the calculated values for the current hour\n",
        "        route_ewt_df = pd.merge(route_ewt_df, merged_df[['Hour', 'Route EWT A', 'Route EWT B']], on='Hour', how='left')\n",
        "\n",
        "        # Display the updated DataFrame\n",
        "        print(route_ewt_df)\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d625b192-3464-40e9-c13f-50b6ce8033b9",
        "id": "RgKA1ftYpuub"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[4mToday is Friday. The selected Schedule name is Monday to Friday.\u001b[0m\n",
            "\n",
            "Arrival Predictions for stop point 490011107G (Poplar / All Saints Church):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490011107G  outbound    2024-07-19 12:09:34   1900-01-01 12:09:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490011107G  outbound    2024-07-19 12:21:34   1900-01-01 12:21:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490011107G  outbound    2024-07-19 12:09:34   1900-01-01 12:09:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490011107G  outbound    2024-07-19 12:21:34   1900-01-01 12:21:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 2\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490013513S (Stewart Street):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490013513S  outbound    2024-07-19 12:14:24   1900-01-01 12:14:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490013513S  outbound    2024-07-19 12:26:35   1900-01-01 12:26:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490013513S  outbound    2024-07-19 12:14:24   1900-01-01 12:14:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490013513S  outbound    2024-07-19 12:26:35   1900-01-01 12:26:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 2\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490002048Z (Island Gardens Station):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX12DDE 490002048Z  outbound    2024-07-19 12:07:36   1900-01-01 12:07:00  0.0    0.0     0.0\n",
            "  D7    LX11BEY 490002048Z  outbound    2024-07-19 12:19:58   1900-01-01 12:19:00 12.0   24.0   144.0\n",
            "  D7    LX11BJO 490002048Z  outbound    2024-07-19 12:31:58   1900-01-01 12:31:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX12DDE 490002048Z  outbound    2024-07-19 12:07:36   1900-01-01 12:07:00  0.0    0.0     0.0\n",
            "  D7    LX11BEY 490002048Z  outbound    2024-07-19 12:19:58   1900-01-01 12:19:00 12.0   24.0   144.0\n",
            "  D7    LX11BJO 490002048Z  outbound    2024-07-19 12:31:58   1900-01-01 12:31:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 3\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490006092N (Arnhem Wharf Primary School):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX12DDE 490006092N  outbound    2024-07-19 12:12:23   1900-01-01 12:12:00  0.0    0.0     0.0\n",
            "  D7    LX11BEY 490006092N  outbound    2024-07-19 12:24:55   1900-01-01 12:24:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX12DDE 490006092N  outbound    2024-07-19 12:12:23   1900-01-01 12:12:00  0.0    0.0     0.0\n",
            "  D7    LX11BEY 490006092N  outbound    2024-07-19 12:24:55   1900-01-01 12:24:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 2\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490004584N (East India Dock Road):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BFF 490004584N  outbound    2024-07-19 12:08:36   1900-01-01 12:08:00  0.0    0.0     0.0\n",
            "  D7    LX11BJV 490004584N  outbound    2024-07-19 12:10:51   1900-01-01 12:10:00  2.0    4.0     4.0\n",
            "  D7    LX12DDE 490004584N  outbound    2024-07-19 12:27:01   1900-01-01 12:27:00 17.0   34.0   289.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BFF 490004584N  outbound    2024-07-19 12:08:36   1900-01-01 12:08:00  0.0    0.0     0.0\n",
            "  D7    LX11BJV 490004584N  outbound    2024-07-19 12:10:51   1900-01-01 12:10:00  2.0    4.0     4.0\n",
            "  D7    LX12DDE 490004584N  outbound    2024-07-19 12:27:01   1900-01-01 12:27:00 17.0   34.0   289.0\n",
            "\n",
            "Number of buses observed in the current hour: 3\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490015151H (Mile End Station / Bow Road):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBO 490015151H   inbound    2024-07-19 12:05:00   1900-01-01 12:05:00  0.0    0.0     0.0\n",
            "  D7    LX61DBY 490015151H   inbound    2024-07-19 12:09:48   1900-01-01 12:09:00  4.0    8.0    16.0\n",
            "  D7    LX11BFF 490015151H   inbound    2024-07-19 12:22:02   1900-01-01 12:22:00 13.0   26.0   169.0\n",
            "  D7    LX11BJV 490015151H   inbound    2024-07-19 12:34:02   1900-01-01 12:34:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBO 490015151H   inbound    2024-07-19 12:05:00   1900-01-01 12:05:00  0.0    0.0     0.0\n",
            "  D7    LX61DBY 490015151H   inbound    2024-07-19 12:09:48   1900-01-01 12:09:00  4.0    8.0    16.0\n",
            "  D7    LX11BFF 490015151H   inbound    2024-07-19 12:22:02   1900-01-01 12:22:00 13.0   26.0   169.0\n",
            "  D7    LX11BJV 490015151H   inbound    2024-07-19 12:34:02   1900-01-01 12:34:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 4\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490004584S (East India Dock Road):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBO 490004584S   inbound    2024-07-19 12:12:14   1900-01-01 12:12:00  0.0    0.0     0.0\n",
            "  D7    LX61DBY 490004584S   inbound    2024-07-19 12:16:17   1900-01-01 12:16:00  4.0    8.0    16.0\n",
            "  D7    LX11BFF 490004584S   inbound    2024-07-19 12:28:41   1900-01-01 12:28:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBO 490004584S   inbound    2024-07-19 12:12:14   1900-01-01 12:12:00  0.0    0.0     0.0\n",
            "  D7    LX61DBY 490004584S   inbound    2024-07-19 12:16:17   1900-01-01 12:16:00  4.0    8.0    16.0\n",
            "  D7    LX11BFF 490004584S   inbound    2024-07-19 12:28:41   1900-01-01 12:28:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 3\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490000038F (Canary Wharf Station):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBO 490000038F   inbound    2024-07-19 12:16:25   1900-01-01 12:16:00  0.0    0.0     0.0\n",
            "  D7    LX61DBY 490000038F   inbound    2024-07-19 12:21:31   1900-01-01 12:21:00  5.0   10.0    25.0\n",
            "  D7    LX11BFF 490000038F   inbound    2024-07-19 12:33:52   1900-01-01 12:33:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBO 490000038F   inbound    2024-07-19 12:16:25   1900-01-01 12:16:00  0.0    0.0     0.0\n",
            "  D7    LX61DBY 490000038F   inbound    2024-07-19 12:21:31   1900-01-01 12:21:00  5.0   10.0    25.0\n",
            "  D7    LX11BFF 490000038F   inbound    2024-07-19 12:33:52   1900-01-01 12:33:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 3\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490006092S (Arnhem Wharf Primary School):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBU 490006092S   inbound    2024-07-19 12:07:10   1900-01-01 12:07:00  0.0    0.0     0.0\n",
            "  D7    LX61DBO 490006092S   inbound    2024-07-19 12:22:46   1900-01-01 12:22:00 15.0   30.0   225.0\n",
            "  D7    LX61DBY 490006092S   inbound    2024-07-19 12:30:14   1900-01-01 12:30:00  8.0   16.0    64.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBU 490006092S   inbound    2024-07-19 12:07:10   1900-01-01 12:07:00  0.0    0.0     0.0\n",
            "  D7    LX61DBO 490006092S   inbound    2024-07-19 12:22:46   1900-01-01 12:22:00 15.0   30.0   225.0\n",
            "  D7    LX61DBY 490006092S   inbound    2024-07-19 12:30:14   1900-01-01 12:30:00  8.0   16.0    64.0\n",
            "\n",
            "Number of buses observed in the current hour: 3\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490002048X (Island Gardens Station):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBU 490002048X   inbound    2024-07-19 12:11:17   1900-01-01 12:11:00  0.0    0.0     0.0\n",
            "  D7    LX61DBO 490002048X   inbound    2024-07-19 12:28:34   1900-01-01 12:28:00 17.0   34.0   289.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBU 490002048X   inbound    2024-07-19 12:11:17   1900-01-01 12:11:00  0.0    0.0     0.0\n",
            "  D7    LX61DBO 490002048X   inbound    2024-07-19 12:28:34   1900-01-01 12:28:00 17.0   34.0   289.0\n",
            "\n",
            "Number of buses observed in the current hour: 2\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490013513N (Stewart Street):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBU 490013513N   inbound    2024-07-19 12:16:42   1900-01-01 12:16:00  0.0    0.0     0.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX61DBU 490013513N   inbound    2024-07-19 12:16:42   1900-01-01 12:16:00  0.0    0.0     0.0\n",
            "\n",
            "Number of buses observed in the current hour: 1\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Route SWT DataFrame:\n",
            "    Hour  Route SWT A  Route SWT B\n",
            "0      0          NaN          NaN\n",
            "1      1          NaN          NaN\n",
            "2      2          NaN          NaN\n",
            "3      3          NaN          NaN\n",
            "4      4        18.75          NaN\n",
            "5      5        10.00        11.25\n",
            "6      6         6.52         8.57\n",
            "7      7         5.77         5.81\n",
            "8      8         6.00         6.00\n",
            "9      9         5.77         5.81\n",
            "10    10         6.00         6.00\n",
            "11    11         6.00         6.00\n",
            "12    12         6.00         6.00\n",
            "13    13         6.00         6.00\n",
            "14    14         6.00         5.62\n",
            "15    15         6.00         6.00\n",
            "16    16         6.00         6.00\n",
            "17    17         6.00         6.00\n",
            "18    18         6.00         6.00\n",
            "19    19         5.77         6.43\n",
            "20    20         6.52         6.21\n",
            "21    21         7.89         7.20\n",
            "22    22         7.50         7.50\n",
            "23    23         7.50         7.50\n",
            "\n",
            "Number of Buses Observed DataFrame:\n",
            "    Stop Point  Num of Buses Observed  Total Gap Sq  Total 2 Gap   AWT   WAWT\n",
            "0   490011107G                      2         144.0         24.0  6.00  12.00\n",
            "1   490013513S                      2         144.0         24.0  6.00  12.00\n",
            "2   490002048Z                      3         288.0         48.0  6.00  18.00\n",
            "3   490006092N                      2         144.0         24.0  6.00  12.00\n",
            "4   490004584N                      3         293.0         38.0  7.71  23.13\n",
            "5   490015151H                      4         329.0         58.0  5.67  22.68\n",
            "6   490004584S                      3         160.0         32.0  5.00  15.00\n",
            "7   490000038F                      3         169.0         34.0  4.97  14.91\n",
            "8   490006092S                      3         289.0         46.0  6.28  18.84\n",
            "9   490002048X                      2         289.0         34.0  8.50  17.00\n",
            "10  490013513N                      1           0.0          0.0  0.00   0.00\n",
            "\n",
            "Route AWT DataFrame:\n",
            "  Hour  Route AWT A  Route AWT B\n",
            "0   12         6.43         5.53\n",
            "  Hour Route EWT A_x Route EWT Var A Route EWT B_x Route EWT Var B  \\\n",
            "0   11          None            None          None            None   \n",
            "\n",
            "   Route EWT A_y  Route EWT B_y  \n",
            "0            NaN            NaN  \n",
            "\n",
            "Arrival Predictions for stop point 490011107G (Poplar / All Saints Church):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490011107G  outbound    2024-07-19 12:09:34   1900-01-01 12:09:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490011107G  outbound    2024-07-19 12:21:34   1900-01-01 12:21:00 12.0   24.0   144.0\n",
            "  D7    LX61DBU 490011107G  outbound    2024-07-19 12:33:33   1900-01-01 12:33:00 12.0   24.0   144.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490011107G  outbound    2024-07-19 12:09:34   1900-01-01 12:09:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490011107G  outbound    2024-07-19 12:21:34   1900-01-01 12:21:00 12.0   24.0   144.0\n",
            "  D7    LX61DBU 490011107G  outbound    2024-07-19 12:33:33   1900-01-01 12:33:00 12.0   24.0   144.0\n",
            "\n",
            "Number of buses observed in the current hour: 3\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Arrival Predictions for stop point 490013513S (Stewart Street):\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490013513S  outbound    2024-07-19 12:12:09   1900-01-01 12:12:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490013513S  outbound    2024-07-19 12:26:35   1900-01-01 12:26:00 14.0   28.0   196.0\n",
            "\n",
            "Cumulative DataFrame:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST) Expected Arrival (HM)  Gap  2_Gap  Gap_Sq\n",
            "  D7    LX11BEY 490013513S  outbound    2024-07-19 12:12:09   1900-01-01 12:12:00  0.0    0.0     0.0\n",
            "  D7    LX11BJO 490013513S  outbound    2024-07-19 12:26:35   1900-01-01 12:26:00 14.0   28.0   196.0\n",
            "\n",
            "Number of buses observed in the current hour: 2\n",
            "Refreshing data in 30 seconds...\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX25Nf/KMkAJ/SuFbbNx4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}