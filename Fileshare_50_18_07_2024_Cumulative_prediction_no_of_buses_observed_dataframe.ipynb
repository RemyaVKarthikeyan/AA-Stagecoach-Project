{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/Fileshare_50_18_07_2024_Cumulative_prediction_no_of_buses_observed_dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Modify this path accordingly\n",
        "file_path = '/content/QSI points.xlsx'\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Get the lineID from the user\n",
        "lineID = input(\"Please enter the lineID: \")\n",
        "\n",
        "# Check if the necessary column is present\n",
        "if 'Route_Dir_QSI_No' not in df.columns:\n",
        "    print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "else:\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Create regular expressions for filtering\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for lineID_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for lineID_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)][['Route_Dir_QSI_No', 'STOP_NAME']]\n",
        "\n",
        "    # Function to fetch and process route sequence data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    matched_results_df_A = matched_results_df_A[matched_results_df_A['Route_Dir_QSI_No'].str.match(pattern_A)]\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    matched_results_df_B = matched_results_df_B[matched_results_df_B['Route_Dir_QSI_No'].str.match(pattern_B)]\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # Display the combined DataFrame\n",
        "    print(\"\\n\\n\\033[1m\\033[4mCombined QSI stop points for directions A and B\\033[0m\\n\")\n",
        "    print(combined_df[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a76d64-88ad-4861-c2d4-9869fce72559",
        "id": "7YH0gajXuMuI"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the lineID: d7\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction D7_A\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                    STOP_Name          ID\n",
            "0            D7_A1   Poplar / All Saints Church  490011107G\n",
            "1            D7_A2               Stewart Street  490013513S\n",
            "2            D7_A3       Island Gardens Station  490002048Z\n",
            "3            D7_A4  Arnhem Wharf Primary School  490006092N\n",
            "5            D7_A5         East India Dock Road  490004584N\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mQSI stop points for direction D7_B\u001b[0m\n",
            "\n",
            "  Route_Dir_QSI_No                    STOP_Name          ID\n",
            "0            D7_B1  Mile End Station / Bow Road  490015151H\n",
            "2            D7_B2         East India Dock Road  490004584S\n",
            "3            D7_B3         Canary Wharf Station  490000038F\n",
            "5            D7_B4  Arnhem Wharf Primary School  490006092S\n",
            "6            D7_B5       Island Gardens Station  490002048X\n",
            "7            D7_B6               Stewart Street  490013513N\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[4mCombined QSI stop points for directions A and B\u001b[0m\n",
            "\n",
            "   Route_Dir_QSI_No                    STOP_Name          ID\n",
            "0             D7_A1   Poplar / All Saints Church  490011107G\n",
            "1             D7_A2               Stewart Street  490013513S\n",
            "2             D7_A3       Island Gardens Station  490002048Z\n",
            "3             D7_A4  Arnhem Wharf Primary School  490006092N\n",
            "4             D7_A5         East India Dock Road  490004584N\n",
            "5             D7_B1  Mile End Station / Bow Road  490015151H\n",
            "6             D7_B2         East India Dock Road  490004584S\n",
            "7             D7_B3         Canary Wharf Station  490000038F\n",
            "8             D7_B4  Arnhem Wharf Primary School  490006092S\n",
            "9             D7_B5       Island Gardens Station  490002048X\n",
            "10            D7_B6               Stewart Street  490013513N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import time\n",
        "\n",
        "# Function to fetch arrival predictions\n",
        "def fetch_arrival_predictions(line_id, stop_point_id, direction):\n",
        "    try:\n",
        "        base_url = f\"https://api.tfl.gov.uk/Line/{line_id}/Arrivals/{stop_point_id}\"\n",
        "        params = {'direction': direction}\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if len(data) == 0:\n",
        "            return pd.DataFrame(), None  # No data available\n",
        "        station_name = data[0]['stationName']\n",
        "        predictions = []\n",
        "        for item in data:\n",
        "            arrival_time = datetime.strptime(item['expectedArrival'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            arrival_time_bst = arrival_time + timedelta(hours=1)\n",
        "            predictions.append({\n",
        "                'Line': item['lineName'],\n",
        "                'Vehicle ID': item['vehicleId'],\n",
        "                'Stop Point': stop_point_id,\n",
        "                'Direction': direction,\n",
        "                'Expected Arrival (BST)': arrival_time_bst,\n",
        "                'Expected Arrival (HM)': arrival_time_bst.strftime('%H:%M')\n",
        "            })\n",
        "        df = pd.DataFrame(predictions)\n",
        "        df = df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "        df['Expected Arrival (BST)'] = pd.to_datetime(df['Expected Arrival (BST)'])  # Convert to datetime\n",
        "        df['Expected Arrival (HM)'] = pd.to_datetime(df['Expected Arrival (HM)'], format='%H:%M')\n",
        "        df['Gap'] = df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "        df['2_Gap'] = (df['Gap'] * 2).round(2)\n",
        "        df['Gap_Sq'] = (df['Gap'] * df['Gap']).round(2)\n",
        "        return df, station_name\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    # Assuming combined_df is generated from the previous cell\n",
        "    # combined_df should have columns like 'Route_Dir_QSI_No', 'STOP_Name', 'ID'\n",
        "\n",
        "    # Example dictionary to hold cumulative dataframes for each stop point\n",
        "    cumulative_dataframes = {}\n",
        "\n",
        "    # Dictionary to hold the number of buses observed per stop point\n",
        "    buses_observed = {}\n",
        "\n",
        "    # Loop through unique stop points in combined_df\n",
        "    for index, row in combined_df.iterrows():\n",
        "        stop_point_id = row['ID']\n",
        "        direction = 'outbound' if row['Route_Dir_QSI_No'].startswith(lineID + '_A') else 'inbound'\n",
        "\n",
        "        cumulative_df = pd.DataFrame(columns=[\n",
        "            'Line', 'Vehicle ID', 'Stop Point', 'Direction',\n",
        "            'Expected Arrival (BST)', 'Expected Arrival (HM)',\n",
        "            'Gap', '2_Gap', 'Gap_Sq'\n",
        "        ])\n",
        "\n",
        "        cumulative_dataframes[stop_point_id] = cumulative_df  # Initialize cumulative dataframe\n",
        "        buses_observed[stop_point_id] = 0  # Initialize number of buses observed to 0\n",
        "\n",
        "    while True:\n",
        "        for stop_point_id, cumulative_df in cumulative_dataframes.items():\n",
        "            direction = 'outbound' if combined_df[combined_df['ID'] == stop_point_id]['Route_Dir_QSI_No'].iloc[0].startswith(lineID + '_A') else 'inbound'\n",
        "\n",
        "            arrival_predictions_df, station_name = fetch_arrival_predictions(lineID, stop_point_id, direction)\n",
        "\n",
        "            if arrival_predictions_df is not None and not arrival_predictions_df.empty:\n",
        "                current_hour = datetime.now(pytz.timezone('Europe/London')).hour\n",
        "\n",
        "                for _, row in arrival_predictions_df.iterrows():\n",
        "                    vehicle_id = row['Vehicle ID']\n",
        "                    expected_hour = row['Expected Arrival (BST)'].hour\n",
        "\n",
        "                    mask = cumulative_df['Vehicle ID'] == vehicle_id\n",
        "\n",
        "                    if cumulative_df[mask].empty:\n",
        "                        cumulative_df = pd.concat([cumulative_df, row.to_frame().T], ignore_index=True)\n",
        "                    else:\n",
        "                        existing_hour = cumulative_df.loc[mask, 'Expected Arrival (BST)'].iloc[0].hour\n",
        "\n",
        "                        if expected_hour > existing_hour + 1:\n",
        "                            cumulative_df = pd.concat([cumulative_df, row.to_frame().T], ignore_index=True)\n",
        "                        else:\n",
        "                            cumulative_df.loc[mask, ['Line', 'Stop Point', 'Direction', 'Expected Arrival (BST)', 'Expected Arrival (HM)', 'Gap', '2_Gap', 'Gap_Sq']] = row[['Line', 'Stop Point', 'Direction', 'Expected Arrival (BST)', 'Expected Arrival (HM)', 'Gap', '2_Gap', 'Gap_Sq']].values\n",
        "\n",
        "                cumulative_df = cumulative_df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "                cumulative_df['Expected Arrival (BST)'] = pd.to_datetime(cumulative_df['Expected Arrival (BST)'])\n",
        "                cumulative_df['Expected Arrival (HM)'] = pd.to_datetime(cumulative_df['Expected Arrival (HM)'], format='%H:%M')\n",
        "\n",
        "                cumulative_df['Gap'] = cumulative_df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "                cumulative_df['2_Gap'] = (cumulative_df['Gap'] * 2).round(2)\n",
        "                cumulative_df['Gap_Sq'] = (cumulative_df['Gap'] * cumulative_df['Gap']).round(2)\n",
        "\n",
        "                # Update number of buses observed in the current hour\n",
        "                num_buses_observed = cumulative_df[cumulative_df['Expected Arrival (BST)'].dt.hour == current_hour].shape[0]\n",
        "                buses_observed[stop_point_id] = num_buses_observed\n",
        "\n",
        "                print(f\"\\nArrival Predictions for stop point {stop_point_id} ({station_name}):\")\n",
        "                print(arrival_predictions_df.to_string(index=False))\n",
        "                print(\"\\nCumulative DataFrame:\")\n",
        "                print(cumulative_df.to_string(index=False))\n",
        "                print(f\"\\nNumber of buses observed in the current hour: {num_buses_observed}\")\n",
        "            else:\n",
        "                print(\"No arrival predictions available.\")\n",
        "\n",
        "            print(\"Refreshing data in 30 seconds...\\n\")\n",
        "            time.sleep(30)\n",
        "\n",
        "            # Update cumulative dataframe in dictionary\n",
        "            cumulative_dataframes[stop_point_id] = cumulative_df\n",
        "\n",
        "        # Create DataFrame to show number of buses observed for each stop point\n",
        "        buses_observed_df = pd.DataFrame(list(buses_observed.items()), columns=['Stop Point', 'Num of Buses Observed'])\n",
        "\n",
        "        print(\"\\nNumber of Buses Observed DataFrame:\")\n",
        "        print(buses_observed_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVKcITfCp5L5",
        "outputId": "4219ca7f-2de5-42ef-d9b2-5cfa3c921dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Number of Buses Observed DataFrame:\n",
            "    Stop Point  Num of Buses Observed\n",
            "0   490011107G                      0\n",
            "1   490013513S                      0\n",
            "2   490002048Z                      0\n",
            "3   490006092N                      0\n",
            "4   490004584N                      0\n",
            "5   490015151H                      0\n",
            "6   490004584S                      0\n",
            "7   490000038F                      0\n",
            "8   490006092S                      0\n",
            "9   490002048X                      0\n",
            "10  490013513N                      0\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Number of Buses Observed DataFrame:\n",
            "    Stop Point  Num of Buses Observed\n",
            "0   490011107G                      0\n",
            "1   490013513S                      0\n",
            "2   490002048Z                      0\n",
            "3   490006092N                      0\n",
            "4   490004584N                      0\n",
            "5   490015151H                      0\n",
            "6   490004584S                      0\n",
            "7   490000038F                      0\n",
            "8   490006092S                      0\n",
            "9   490002048X                      0\n",
            "10  490013513N                      0\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Number of Buses Observed DataFrame:\n",
            "    Stop Point  Num of Buses Observed\n",
            "0   490011107G                      0\n",
            "1   490013513S                      0\n",
            "2   490002048Z                      0\n",
            "3   490006092N                      0\n",
            "4   490004584N                      0\n",
            "5   490015151H                      0\n",
            "6   490004584S                      0\n",
            "7   490000038F                      0\n",
            "8   490006092S                      0\n",
            "9   490002048X                      0\n",
            "10  490013513N                      0\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "\n",
            "Number of Buses Observed DataFrame:\n",
            "    Stop Point  Num of Buses Observed\n",
            "0   490011107G                      0\n",
            "1   490013513S                      0\n",
            "2   490002048Z                      0\n",
            "3   490006092N                      0\n",
            "4   490004584N                      0\n",
            "5   490015151H                      0\n",
            "6   490004584S                      0\n",
            "7   490000038F                      0\n",
            "8   490006092S                      0\n",
            "9   490002048X                      0\n",
            "10  490013513N                      0\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n",
            "No arrival predictions available.\n",
            "Refreshing data in 30 seconds...\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvKUVjZ3qx69cKFkOMaS5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}