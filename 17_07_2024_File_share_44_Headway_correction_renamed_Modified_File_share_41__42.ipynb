{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfCrunZD4wCh21J3OKakQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/17_07_2024_File_share_44_Headway_correction_renamed_Modified_File_share_41__42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ20vvnvY_26"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "y7MpBY6Rsor_",
        "outputId": "4e2fcd00-3ffc-4994-fb2b-3a5fc059d30f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-674bafc07c60>\u001b[0m in \u001b[0;36m<cell line: 622>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;31m# Ask the user to enter a lineID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m     \u001b[0mline_id_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter the lineID: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m     \u001b[0mlineID_sheet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_id_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0mdf_sheet2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Route'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sheet2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Route'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from difflib import SequenceMatcher\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize empty DataFrame for AWT data\n",
        "awt_data = pd.DataFrame(columns=['Route_Dir_QSI_No','Stop Point ID', 'AWT','No_Buses_Obs','EWT'])\n",
        "\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Function to fetch data from the API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        slot = hour % 24  # Map hour to the correct slot\n",
        "        slots[slot].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# Function to retrieve stop names from TfL API and match with Route_Dir_QSI_No\n",
        "def find_route_details(lineID, df):\n",
        "    # Ensure the 'Route_Dir_QSI_No' column exists\n",
        "    if 'Route_Dir_QSI_No' not in df.columns:\n",
        "        print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "        return\n",
        "\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Filter the DataFrame based on the lineID\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for D7_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for D7_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)]\n",
        "\n",
        "    # Function to fetch and process route sequence data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    matched_results_df_A = matched_results_df_A[matched_results_df_A['Route_Dir_QSI_No'].str.match(pattern_A)]\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    matched_results_df_B = matched_results_df_B[matched_results_df_B['Route_Dir_QSI_No'].str.match(pattern_B)]\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # DataFrames to store SWT data\n",
        "    swt_data = {\n",
        "        'Route_Dir_QSI_No': [],\n",
        "        'ID': [],\n",
        "        'SWT': [],\n",
        "        'No_Buses_Sch': [],\n",
        "        'SWT_hr1': [],\n",
        "        'No_Buses_Sch_hr1': [],\n",
        "        'SWT_hr2': [],\n",
        "        'No_Buses_Sch_hr2': []\n",
        "    }\n",
        "\n",
        "    # Fetch timetable for each stop point ID and calculate SWT\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    current_hour = datetime.now(bst).hour\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    # Store selected schedule name to ensure it's printed only once\n",
        "    selected_schedule_name = None\n",
        "    printed_schedule_name = False\n",
        "\n",
        "    # Track printed timetable stop IDs\n",
        "    printed_timetable_stop_ids = []\n",
        "\n",
        "    while True:\n",
        "        # Clear previous awt_data DataFrame\n",
        "        awt_data = pd.DataFrame(columns=['Route_Dir_QSI_No','Stop Point ID','AWT','No_Buses_Obs','EWT'])\n",
        "\n",
        "        # Update current time and hour\n",
        "        now = datetime.now(bst)\n",
        "        current_hour = now.hour\n",
        "        day_of_week = get_day_of_week()\n",
        "\n",
        "        # Clear previous SWT data\n",
        "        swt_data = {\n",
        "            'Route_Dir_QSI_No': [],\n",
        "            'ID': [],\n",
        "            'SWT': [],\n",
        "            'No_Buses_Sch': [],\n",
        "            'SWT_hr1': [],\n",
        "            'No_Buses_Sch_hr1': [],\n",
        "            'SWT_hr2': [],\n",
        "            'No_Buses_Sch_hr2': []\n",
        "        }\n",
        "\n",
        "        for index, row in combined_df.iterrows():\n",
        "            stop_point_id = row['ID']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "            if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "                direction = 'outbound'\n",
        "            elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "                direction = 'inbound'\n",
        "            else:\n",
        "                print(f\"Invalid route direction for Route_Dir_QSI_No: {route_dir_qsi_no}\")\n",
        "                continue\n",
        "\n",
        "            url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "            data = fetch_data(url)\n",
        "\n",
        "            schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "            if not selected_schedule_name:\n",
        "                if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "                    preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "                elif day_of_week.lower() == 'friday':\n",
        "                    preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "                elif day_of_week.lower() == 'saturday':\n",
        "                    preferred_schedule_names = ['Saturday']\n",
        "                elif day_of_week.lower() == 'sunday':\n",
        "                    preferred_schedule_names = ['Sunday']\n",
        "                else:\n",
        "                    preferred_schedule_names = [day_of_week]\n",
        "\n",
        "                for preferred_name in preferred_schedule_names:\n",
        "                    if preferred_name in schedule_names_dict:\n",
        "                        selected_schedule_name = preferred_name\n",
        "                        break\n",
        "\n",
        "            if selected_schedule_name and not printed_schedule_name:\n",
        "                print(f\"\\nToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\")\n",
        "                printed_schedule_name = True\n",
        "\n",
        "            if selected_schedule_name:\n",
        "                timetable = schedule_names_dict[selected_schedule_name]\n",
        "                slots = categorize_into_slots(timetable)\n",
        "\n",
        "                # Calculate Scheduled Wait Time (SWT)\n",
        "                total_buses_this_hour = len(slots[current_hour])\n",
        "                scheduled_wait_time = 60 / (total_buses_this_hour * 2) if total_buses_this_hour > 0 else float('inf')\n",
        "                next_hour = (current_hour + 1) % 24  # Wrap around using modulo operator\n",
        "                total_buses_hr1 = len(slots[next_hour])\n",
        "                scheduled_wait_time_hr1 = 60 / (total_buses_hr1 * 2) if total_buses_hr1 > 0 else float('inf')\n",
        "                next_next_hour = (current_hour + 2) % 24  # Wrap around using modulo operator\n",
        "                total_buses_hr2 = len(slots[next_next_hour])\n",
        "                scheduled_wait_time_hr2 = 60 / (total_buses_hr2 * 2) if total_buses_hr2 > 0 else float('inf')\n",
        "\n",
        "                # Store SWT data\n",
        "                swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "                swt_data['ID'].append(stop_point_id)\n",
        "                swt_data['SWT'].append(scheduled_wait_time)\n",
        "                swt_data['No_Buses_Sch'].append(total_buses_this_hour)\n",
        "                swt_data['SWT_hr1'].append(scheduled_wait_time_hr1)\n",
        "                swt_data['No_Buses_Sch_hr1'].append(total_buses_hr1)\n",
        "                swt_data['SWT_hr2'].append(scheduled_wait_time_hr2)\n",
        "                swt_data['No_Buses_Sch_hr2'].append(total_buses_hr2)\n",
        "                # Fetch arrival predictions based on SWT data for printed timetable stop IDs\n",
        "                if stop_point_id in printed_timetable_stop_ids:\n",
        "                    # Fetch arrival predictions\n",
        "                    arrival_predictions_df, station_name = fetch_arrival_predictions(lineID, stop_point_id, direction)\n",
        "\n",
        "                    if arrival_predictions_df is not None and not arrival_predictions_df.empty:\n",
        "                        print(f\"\\nArrival Predictions for stop point {stop_point_id} ({station_name}):\")\n",
        "                        print(arrival_predictions_df.to_string(index=False))\n",
        "                        print(f\"   \")\n",
        "                        # Calculating summary metrics\n",
        "                        total_Gap_Sq = arrival_predictions_df['Gap_Sq'].sum()\n",
        "                        total_2_Gap = arrival_predictions_df['2_Gap'].sum()\n",
        "                        min_arrival = arrival_predictions_df['Expected Arrival (BST)'].min().replace(second=0, microsecond=0)\n",
        "                        max_arrival = arrival_predictions_df['Expected Arrival (BST)'].max().replace(second=0, microsecond=0)\n",
        "                        time_diff_minutes = (max_arrival - min_arrival).total_seconds() / 60\n",
        "                        num_buses_observed = arrival_predictions_df['Vehicle ID'].nunique()\n",
        "\n",
        "                        # Calculating AWT, SWT, and EWT\n",
        "                        nbph = swt_data['No_Buses_Sch'][swt_data['ID'].index(stop_point_id)]\n",
        "                        swt = swt_data['SWT'][swt_data['ID'].index(stop_point_id)]\n",
        "                        awt = round(total_Gap_Sq / total_2_Gap, 2) if total_2_Gap > 0 else 0\n",
        "                        ewt = round(awt - swt, 2)\n",
        "                        MPS = filtered_data['MPS'].iloc[0]\n",
        "                        ewt_var = round(ewt - MPS,2)\n",
        "                        summary_df = pd.DataFrame({\n",
        "                            'Metric': ['Number of buses scheduled per hour (nbph)', 'Number of buses observed', 'SWT (minutes)','MPS', 'Total_Gap_Sq', 'Total_2_Gap',\n",
        "                                       'Time difference between 1st and last observed buses (minutes)', 'AWT (minutes)', 'EWT (minutes)', 'EWT Variance'],\n",
        "                            'Value': [nbph, num_buses_observed, swt, MPS, total_Gap_Sq, total_2_Gap, time_diff_minutes, awt, ewt, ewt_var]\n",
        "                        })\n",
        "                        print(f\"\\nSummary Metrics for {stop_point_id}:\")\n",
        "                        print(summary_df)\n",
        "\n",
        "                        # Append to awt_data DataFrame\n",
        "                        awt_data.loc[len(awt_data)] = [swt_data['Route_Dir_QSI_No'][swt_data['ID'].index(stop_point_id)],stop_point_id, awt,num_buses_observed,ewt]\n",
        "\n",
        "                    # Remove the stop ID from printed_timetable_stop_ids to avoid redundant fetches\n",
        "                    printed_timetable_stop_ids.remove(stop_point_id)\n",
        "\n",
        "        # Update printed timetable stop IDs\n",
        "        printed_timetable_stop_ids = swt_data['ID']\n",
        "\n",
        "        # Create DataFrame for SWT data\n",
        "        swt_df = pd.DataFrame(swt_data)\n",
        "        awt_df = pd.DataFrame(awt_data)\n",
        "        # Print the SWT DataFrame\n",
        "        print(f\"\\n\\n\\033[1m\\033[4mSWT DataFrame at hour {current_hour}\\033[0m\\n\")\n",
        "        print(swt_df)\n",
        "\n",
        "        print(f\"\\n\\n\\033[1m\\033[4mAWT DataFrame at hour {now.strftime('%H:%M')}\\033[0m\\n\")\n",
        "        print(awt_df)\n",
        "\n",
        "        def update_hourly_EWT(hourly_EWT, current_hour, next_hour, lineID, avg_ewt_A, avg_ewt_B):\n",
        "            # Create the hour slot string\n",
        "            hour_slot = f\"{current_hour}:00 - {next_hour}:00\"\n",
        "\n",
        "            # Create a new entry as a DataFrame\n",
        "            new_entry = pd.DataFrame({\n",
        "                'Hour slot': [hour_slot],\n",
        "                'Line ID': [lineID],\n",
        "                'EWT_A': [round(avg_ewt_A, 2) if avg_ewt_A is not None else None],\n",
        "                'EWT_B': [round(avg_ewt_B, 2) if avg_ewt_B is not None else None]\n",
        "            })\n",
        "\n",
        "            # If hourly_EWT is empty, return the new entry as the DataFrame\n",
        "            if hourly_EWT.empty:\n",
        "                return new_entry\n",
        "\n",
        "            # Check if there is an existing row with the same Hour slot and Line ID\n",
        "            condition = (hourly_EWT['Hour slot'] == hour_slot) & (hourly_EWT['Line ID'] == lineID)\n",
        "\n",
        "            if condition.any():\n",
        "                # Update the existing row\n",
        "                if avg_ewt_A is not None:\n",
        "                    hourly_EWT.loc[condition, 'EWT_A'] = round(avg_ewt_A, 2)\n",
        "                if avg_ewt_B is not None:\n",
        "                    hourly_EWT.loc[condition, 'EWT_B'] = round(avg_ewt_B, 2)\n",
        "            else:\n",
        "                # Append the new entry to the DataFrame\n",
        "                hourly_EWT = pd.concat([hourly_EWT, new_entry], ignore_index=True)\n",
        "\n",
        "            return hourly_EWT\n",
        "\n",
        "        def calculate_route_swt_awt(swt_df, awt_df):\n",
        "\n",
        "            # Filter the swt_df to include only rows where Route_Dir_QSI_No matches the pattern _A** and _B**\n",
        "            filtered_df_A_swt = swt_df[swt_df['Route_Dir_QSI_No'].str.contains('_A')].copy()\n",
        "            filtered_df_B_swt = swt_df[swt_df['Route_Dir_QSI_No'].str.contains('_B')].copy()\n",
        "\n",
        "            # Calculate the product of SWT and No_Buses_Sch for each row\n",
        "            filtered_df_A_swt.loc[:, 'SWT_No_Buses_Sch_Product_A'] = filtered_df_A_swt['SWT'] * filtered_df_A_swt['No_Buses_Sch'].copy()\n",
        "            filtered_df_B_swt.loc[:, 'SWT_No_Buses_Sch_Product_B'] = filtered_df_B_swt['SWT'] * filtered_df_B_swt['No_Buses_Sch'].copy()\n",
        "\n",
        "            # Find the sum of these products (Route SWT)\n",
        "            sum_products_A_swt = filtered_df_A_swt.loc[:, 'SWT_No_Buses_Sch_Product_A'].sum()\n",
        "            sum_products_B_swt = filtered_df_B_swt.loc[:, 'SWT_No_Buses_Sch_Product_B'].sum()\n",
        "\n",
        "            # Calculate the total sum of No_Buses_Sch for the filtered rows\n",
        "            total_no_buses_sch_A_swt = filtered_df_A_swt.loc[:, 'No_Buses_Sch'].sum()\n",
        "            total_no_buses_sch_B_swt = filtered_df_B_swt.loc[:, 'No_Buses_Sch'].sum()\n",
        "\n",
        "            # Compute the Route SWT (direction A)\n",
        "            route_swt_direction_A = sum_products_A_swt / total_no_buses_sch_A_swt if total_no_buses_sch_A_swt > 0 else 0\n",
        "            route_swt_direction_B = sum_products_B_swt / total_no_buses_sch_B_swt if total_no_buses_sch_B_swt > 0 else 0\n",
        "\n",
        "            # Round the results to two decimal places\n",
        "            route_swt_direction_A = round(route_swt_direction_A, 2)\n",
        "            route_swt_direction_B = round(route_swt_direction_B, 2)\n",
        "\n",
        "            # Initialize route_awt_direction_A and route_awt_direction_B\n",
        "            route_awt_direction_A = 0\n",
        "            route_awt_direction_B = 0\n",
        "            route_ewt_direction_A = 0\n",
        "            route_ewt_direction_B = 0\n",
        "\n",
        "            if not awt_df.empty:\n",
        "                # Filter the awt_df to include only rows where Route_Dir_QSI_No matches the pattern _A** and _B**\n",
        "                filtered_df_A_awt = awt_df[awt_df['Route_Dir_QSI_No'].str.contains('_A')].copy()\n",
        "                filtered_df_B_awt = awt_df[awt_df['Route_Dir_QSI_No'].str.contains('_B')].copy()\n",
        "\n",
        "                # Calculate the product of AWT and No_Buses_Obs for each row\n",
        "                filtered_df_A_awt.loc[:, 'AWT_No_Buses_Obs_Product_A'] = filtered_df_A_awt['AWT'] * filtered_df_A_awt['No_Buses_Obs'].copy()\n",
        "                filtered_df_B_awt.loc[:, 'AWT_No_Buses_Obs_Product_B'] = filtered_df_B_awt['AWT'] * filtered_df_B_awt['No_Buses_Obs'].copy()\n",
        "\n",
        "                # Find the sum of these products (Route AWT)\n",
        "                sum_products_A_awt = filtered_df_A_awt.loc[:, 'AWT_No_Buses_Obs_Product_A'].sum()\n",
        "                sum_products_B_awt = filtered_df_B_awt.loc[:, 'AWT_No_Buses_Obs_Product_B'].sum()\n",
        "\n",
        "                # Calculate the total sum of No_Buses_Obs for the filtered rows\n",
        "                total_no_buses_obs_A_awt = filtered_df_A_awt.loc[:, 'No_Buses_Obs'].sum()\n",
        "                total_no_buses_obs_B_awt = filtered_df_B_awt.loc[:, 'No_Buses_Obs'].sum()\n",
        "\n",
        "                # Compute the Route AWT (direction A)\n",
        "                route_awt_direction_A = sum_products_A_awt / total_no_buses_obs_A_awt if total_no_buses_obs_A_awt > 0 else 0\n",
        "                route_awt_direction_B = sum_products_B_awt / total_no_buses_obs_B_awt if total_no_buses_obs_B_awt > 0 else 0\n",
        "\n",
        "                # Round the results to two decimal places\n",
        "                route_awt_direction_A = round(route_awt_direction_A, 2)\n",
        "                route_awt_direction_B = round(route_awt_direction_B, 2)\n",
        "\n",
        "                # Calculate Route EWT (direction A and B)\n",
        "                route_ewt_direction_A = round(route_awt_direction_A - route_swt_direction_A, 2)\n",
        "                route_ewt_direction_B = round(route_awt_direction_B - route_swt_direction_B, 2)\n",
        "\n",
        "                # Prepare Route_EWT_df\n",
        "                route_EWT_df = pd.DataFrame([\n",
        "                    {'Time': now.strftime('%H:%M'), 'Line Id': lineID, 'Direction': 'A', 'SWT': route_swt_direction_A, 'AWT': route_awt_direction_A, 'EWT': route_ewt_direction_A},\n",
        "                    {'Time': now.strftime('%H:%M'), 'Line Id': lineID, 'Direction': 'B', 'SWT': route_swt_direction_B, 'AWT': route_awt_direction_B, 'EWT': route_ewt_direction_B}\n",
        "                ])\n",
        "\n",
        "                # Print the results in the desired format\n",
        "                print(f\"\\n\\033[1m\\033[4mRoute SWT, AWT, EWT at this instant  : {now.strftime('%H:%M')}\\033[0m\\n\")\n",
        "                print(route_EWT_df[['Time', 'Line Id', 'Direction', 'SWT', 'AWT', 'EWT']].to_string(index=False))\n",
        "\n",
        "            else:\n",
        "                # If awt_df is empty, print only SWT and indicate that AWT and EWT could not be calculated\n",
        "\n",
        "                route_EWT_df = pd.DataFrame([\n",
        "                    {'Time': now.strftime('%H:%M'), 'Line Id': lineID, 'Direction': 'A', 'SWT': route_swt_direction_A, 'AWT': '-', 'EWT': '-'},\n",
        "                    {'Time': now.strftime('%H:%M'), 'Line Id': lineID, 'Direction': 'B', 'SWT': route_swt_direction_B, 'AWT': '-', 'EWT': '-'}\n",
        "                ])\n",
        "                print(f\"\\n\\033[1m\\033[4mRoute {lineID} SWT, AWT, EWT at this instant : {now.strftime('%H:%M')}\\033[0m\\n\")\n",
        "                print(route_EWT_df[['Time', 'Line Id', 'Direction', 'SWT', 'AWT', 'EWT']].to_string(index=False))\n",
        "                print(f\"\\n\\033[1m\\033[4mUnable to calculate Route AWT and EWT for direction A and B as the AWT dataframe is not ready\\033[0m\\n\")\n",
        "\n",
        "            return route_EWT_df\n",
        "\n",
        "        def append_route_EWT_df_to_csv(route_EWT_df, csv_file_path='/content/route_ewt.csv'):\n",
        "            # Check if the CSV files for directions A and B exist\n",
        "            csv_file_path_A = '/content/route_EWT_A.csv'\n",
        "            csv_file_path_B = '/content/route_EWT_B.csv'\n",
        "\n",
        "            # Check if the CSV files exist\n",
        "            file_exists_A = os.path.isfile(csv_file_path_A)\n",
        "            file_exists_B = os.path.isfile(csv_file_path_B)\n",
        "\n",
        "            # Split the DataFrame based on 'Direction' column\n",
        "            route_EWT_A_df = route_EWT_df[route_EWT_df['Direction'] == 'A']\n",
        "            route_EWT_B_df = route_EWT_df[route_EWT_df['Direction'] == 'B']\n",
        "\n",
        "            # Append the DataFrame to the respective CSV files\n",
        "            route_EWT_A_df.to_csv(csv_file_path_A, mode='a', header=not file_exists_A, index=False)\n",
        "            route_EWT_B_df.to_csv(csv_file_path_B, mode='a', header=not file_exists_B, index=False)\n",
        "\n",
        "            print(f\"Data appended to {csv_file_path_A} and {csv_file_path_B}\")\n",
        "\n",
        "        def calculate_average_ewt(route_EWT_A_csv, route_EWT_B_csv, lineID, hourly_EWT):\n",
        "\n",
        "            current_hour = now.strftime('%H')\n",
        "            current_hour_int = int(current_hour)\n",
        "            next_hour_int = current_hour_int + 1\n",
        "            next_hour = str(next_hour_int)\n",
        "\n",
        "            # Read CSV files into DataFrames with different names\n",
        "            df_A = pd.read_csv(route_EWT_A_csv)\n",
        "            df_B = pd.read_csv(route_EWT_B_csv)\n",
        "\n",
        "            # Filter df_A for valid EWT and matching time\n",
        "            ewt_A_filtered = df_A[(df_A['EWT'] != '-') & (df_A['Time'].str[:2] == current_hour) & (df_A['Line Id'] == lineID)].copy()\n",
        "            ewt_A_filtered.loc[:, 'EWT'] = pd.to_numeric(ewt_A_filtered['EWT'], errors='coerce')\n",
        "\n",
        "            # Calculate average EWT for direction A\n",
        "            if len(ewt_A_filtered) > 0:\n",
        "                ewt_A_filtered['EWT'] = pd.to_numeric(ewt_A_filtered['EWT'], errors='coerce')\n",
        "                total_ewt_A = ewt_A_filtered['EWT'].sum()\n",
        "                count_ewt_A = len(ewt_A_filtered)\n",
        "                avg_ewt_A = total_ewt_A / count_ewt_A\n",
        "            else:\n",
        "                avg_ewt_A = None\n",
        "\n",
        "            # Filter df_B for valid EWT and matching time\n",
        "            ewt_B_filtered = df_B[(df_B['EWT'] != '-') & (df_B['Time'].str[:2] == current_hour) & (df_B['Line Id'] == lineID)].copy()\n",
        "            ewt_B_filtered.loc[:, 'EWT'] = pd.to_numeric(ewt_B_filtered['EWT'], errors='coerce')\n",
        "\n",
        "            # Calculate average EWT for direction B\n",
        "            if len(ewt_B_filtered) > 0:\n",
        "                ewt_B_filtered['EWT'] = pd.to_numeric(ewt_B_filtered['EWT'], errors='coerce')\n",
        "                total_ewt_B = ewt_B_filtered['EWT'].sum()\n",
        "                count_ewt_B = len(ewt_B_filtered)\n",
        "                avg_ewt_B = total_ewt_B / count_ewt_B\n",
        "            else:\n",
        "                avg_ewt_B = None\n",
        "\n",
        "            # Print the results\n",
        "            print(f\"\\n\\033[1m\\033[4mHourly EWT for time {current_hour}:00 - {next_hour}:00\\033[0m\\n\")\n",
        "\n",
        "            if avg_ewt_A is not None:\n",
        "                print(f\"Direction A: {avg_ewt_A:.2f} minutes\")\n",
        "            else:\n",
        "                print(\"Direction A: No valid data found\")\n",
        "\n",
        "            if avg_ewt_B is not None:\n",
        "                print(f\"Direction B: {avg_ewt_B:.2f} minutes\")\n",
        "            else:\n",
        "                print(\"Direction B: No valid data found\")\n",
        "\n",
        "            # Update the hourly_EWT DataFrame\n",
        "            hourly_EWT = update_hourly_EWT(hourly_EWT, current_hour, next_hour, lineID, avg_ewt_A, avg_ewt_B)\n",
        "\n",
        "            return hourly_EWT\n",
        "\n",
        "        # Main execution\n",
        "\n",
        "        # Assuming swt_df, awt_df, and lineID are already defined\n",
        "        route_EWT_df = calculate_route_swt_awt(swt_df, awt_df)\n",
        "        append_route_EWT_df_to_csv(route_EWT_df, csv_file_path='/content/route_ewt.csv')\n",
        "        if 'hourly_EWT' not in locals():\n",
        "            # Initialize an empty DataFrame for hourly_EWT\n",
        "            hourly_EWT = pd.DataFrame(columns=['Hour slot', 'Line ID', 'EWT_A', 'EWT_B'])\n",
        "        else:\n",
        "            # Optionally, you may choose to clear the existing DataFrame\n",
        "            # hourly_EWT = pd.DataFrame(columns=['Hour slot', 'Line ID', 'EWT_A', 'EWT_B'])\n",
        "            pass\n",
        "        # Calculate average EWT and update hourly_EWT DataFrame\n",
        "        hourly_EWT = calculate_average_ewt('route_EWT_A.csv', 'route_EWT_B.csv', lineID, hourly_EWT)\n",
        "        print(f\"\\n\\n\\033[1m\\033[4mHourly EWT DataFrame\\033[0m\\n\")\n",
        "        print(hourly_EWT)\n",
        "        hourly_EWT.to_csv('/content/hourly_EWT.csv', index=False)\n",
        "        print(\"DataFrame saved to 'hourly_EWT.csv'\")\n",
        "\n",
        "        lineID_sheet2 = str(lineID)\n",
        "        df_sheet2['Route'] = df_sheet2['Route'].astype(str)\n",
        "        filtered_data = df_sheet2[(df_sheet2['Route'] == lineID_sheet2) | (df_sheet2['Route'] == line_id_input)]\n",
        "\n",
        "        # Function to extract start hour from 'Hour slot'\n",
        "        def extract_start_hour(hour_slot):\n",
        "            return int(hour_slot[:2])\n",
        "\n",
        "        # Extracting the start hour for each row\n",
        "        hourly_EWT['start_hour'] = hourly_EWT['Hour slot'].apply(extract_start_hour)\n",
        "        MPS = filtered_data['MPS'].iloc[0]\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        for index, row in hourly_EWT.iterrows():\n",
        "            start_hour = row['start_hour']\n",
        "            end_hour = start_hour + 1\n",
        "\n",
        "            # Plotting EWT_A\n",
        "            plt.plot([start_hour, end_hour], [row['EWT_A'], row['EWT_A']], marker='o', linestyle='-', color='b', label='EWT_A' if index == 0 else \"\", zorder=3)\n",
        "\n",
        "            # Plotting EWT_B\n",
        "            plt.plot([start_hour, end_hour], [row['EWT_B'], row['EWT_B']], marker='o', linestyle='-', color='r', label='EWT_B' if index == 0 else \"\", zorder=2)\n",
        "\n",
        "        plt.axhline(y=MPS, color='g', linestyle='-', label='MPS', zorder=1)\n",
        "        plt.title(f'MPS and Hourly EWT of route {lineID} in direction A and B')\n",
        "        plt.xlabel('Hour Slots')\n",
        "        plt.ylabel('Values')\n",
        "        hours = list(range(24)) + [0]  # Add 0 after 23 for x-axis label\n",
        "        plt.xticks(range(25), hours)  # Set x-axis ticks and labels\n",
        "        plt.legend()  # Show legend\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        # Wait for the next 30 seconds\n",
        "        #clear_output(wait=True)\n",
        "        print(\"\\n\\nWaiting to fetch updated data...\\n\\n\")\n",
        "        time.sleep(15)\n",
        "        #clear_output(wait=True)\n",
        "\n",
        "# Function to fetch arrival predictions with error handling\n",
        "def fetch_arrival_predictions(line_id, stop_point_id, direction):\n",
        "    try:\n",
        "        base_url = f\"https://api.tfl.gov.uk/Line/{line_id}/Arrivals/{stop_point_id}\"\n",
        "        params = {'direction': direction}\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if len(data) == 0:\n",
        "            return pd.DataFrame(), None  # No data available\n",
        "        station_name = data[0]['stationName']\n",
        "        predictions = []\n",
        "        for item in data:\n",
        "            arrival_time = datetime.strptime(item['expectedArrival'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            arrival_time_bst = arrival_time + timedelta(hours=1)\n",
        "            predictions.append({\n",
        "                'Line': item['lineName'],\n",
        "                'Vehicle ID': item['vehicleId'],\n",
        "                'Stop Point': stop_point_id,\n",
        "                'Direction': direction,\n",
        "                'Expected Arrival (BST)': arrival_time_bst,\n",
        "                'Expected Arrival (HM)': arrival_time_bst.strftime('%H:%M')\n",
        "            })\n",
        "        df = pd.DataFrame(predictions)\n",
        "        df = df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "        df['Expected Arrival (BST)'] = pd.to_datetime(df['Expected Arrival (BST)'])  # Convert to datetime\n",
        "        df['Expected Arrival (HM)'] = pd.to_datetime(df['Expected Arrival (HM)'], format='%H:%M')\n",
        "        df['Gap'] = df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "        df['2_Gap'] = (df['Gap'] * 2).round(2)\n",
        "        df['Gap_Sq'] = (df['Gap'] * df['Gap']).round(2)\n",
        "        return df, station_name\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None, None\n",
        "        time.sleep(15)  # Wait for 30 seconds before fetching data again\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the Excel file into a DataFrame\n",
        "    file_path = '/content/QSI points.xlsx'  # Modify this path accordingly\n",
        "    df = pd.read_excel(file_path)\n",
        "    df_sheet2 = pd.read_excel(file_path, sheet_name='Sheet2')\n",
        "\n",
        "\n",
        "    # Ask the user to enter a lineID\n",
        "    line_id_input = input(\"Please enter the lineID: \")\n",
        "    lineID_sheet2 = str(line_id_input.upper())\n",
        "    df_sheet2['Route'] = df_sheet2['Route'].astype(str)\n",
        "    filtered_data = df_sheet2[(df_sheet2['Route'] == lineID_sheet2) | (df_sheet2['Route'] == line_id_input)]\n",
        "    while True:\n",
        "        try:\n",
        "            # Find and display the route details\n",
        "            find_route_details(line_id_input, df)\n",
        "\n",
        "            time.sleep(15)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nExecution interrupted. Exiting the loop.\\n\")\n",
        "            break"
      ]
    }
  ]
}