{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/File_share_26_QSI_points%2C_SWT_dataframe%2C_Summary_metrics_%2C_AWT_dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "05/07/2024"
      ],
      "metadata": {
        "id": "9OMwh670CDLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from difflib import SequenceMatcher\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import time\n",
        "\n",
        "# Initialize empty DataFrame for AWT data\n",
        "awt_data = pd.DataFrame(columns=['Stop Point ID', 'Number of Buses Observed', 'AWT (minutes)'])\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Function to fetch data from the API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "            slots[hour].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# Function to retrieve stop names from TfL API and match with Route_Dir_QSI_No\n",
        "def find_route_details(lineID, df):\n",
        "    # Ensure the 'Route_Dir_QSI_No' column exists\n",
        "    if 'Route_Dir_QSI_No' not in df.columns:\n",
        "        print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "        return\n",
        "\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Filter the DataFrame based on the lineID\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for D7_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for D7_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)]\n",
        "\n",
        "    # Function to fetch and process route sequence data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    matched_results_df_A = matched_results_df_A[matched_results_df_A['Route_Dir_QSI_No'].str.match(pattern_A)]\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    matched_results_df_B = matched_results_df_B[matched_results_df_B['Route_Dir_QSI_No'].str.match(pattern_B)]\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # DataFrames to store SWT data\n",
        "    swt_data = {\n",
        "        'Route_Dir_QSI_No': [],\n",
        "        'ID': [],\n",
        "        'SWT_minutes': [],\n",
        "        'Number_of_buses': []\n",
        "    }\n",
        "\n",
        "    # Fetch timetable for each stop point ID and calculate SWT\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    current_hour = datetime.now(bst).hour\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    # Store selected schedule name to ensure it's printed only once\n",
        "    selected_schedule_name = None\n",
        "    printed_schedule_name = False\n",
        "\n",
        "    # Track printed timetable stop IDs\n",
        "    printed_timetable_stop_ids = []\n",
        "\n",
        "    while True:\n",
        "        # Update current time and hour\n",
        "        now = datetime.now(bst)\n",
        "        current_hour = now.hour\n",
        "        day_of_week = get_day_of_week()\n",
        "\n",
        "        # Clear previous SWT data\n",
        "        swt_data = {\n",
        "            'Route_Dir_QSI_No': [],\n",
        "            'ID': [],\n",
        "            'SWT_minutes': [],\n",
        "            'Number_of_buses': []\n",
        "        }\n",
        "\n",
        "        for index, row in combined_df.iterrows():\n",
        "            stop_point_id = row['ID']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "            if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "                direction = 'outbound'\n",
        "            elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "                direction = 'inbound'\n",
        "            else:\n",
        "                print(f\"Invalid route direction for Route_Dir_QSI_No: {route_dir_qsi_no}\")\n",
        "                continue\n",
        "\n",
        "            url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "            data = fetch_data(url)\n",
        "\n",
        "            schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "            if not selected_schedule_name:\n",
        "                if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "                    preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "                elif day_of_week.lower() == 'friday':\n",
        "                    preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "                elif day_of_week.lower() == 'saturday':\n",
        "                    preferred_schedule_names = ['Saturday']\n",
        "                elif day_of_week.lower() == 'sunday':\n",
        "                    preferred_schedule_names = ['Sunday']\n",
        "                else:\n",
        "                    preferred_schedule_names = [day_of_week]\n",
        "\n",
        "                for preferred_name in preferred_schedule_names:\n",
        "                    if preferred_name in schedule_names_dict:\n",
        "                        selected_schedule_name = preferred_name\n",
        "                        break\n",
        "\n",
        "            if selected_schedule_name and not printed_schedule_name:\n",
        "                print(f\"\\nToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\")\n",
        "                printed_schedule_name = True\n",
        "\n",
        "            if selected_schedule_name:\n",
        "                timetable = schedule_names_dict[selected_schedule_name]\n",
        "                slots = categorize_into_slots(timetable)\n",
        "\n",
        "                # Calculate Scheduled Wait Time (SWT)\n",
        "                total_buses_this_hour = len(slots[current_hour])\n",
        "                if total_buses_this_hour > 0:\n",
        "                    scheduled_wait_time = 60 / (total_buses_this_hour * 2)  # SWT formula\n",
        "                else:\n",
        "                    scheduled_wait_time = float('inf')  # Handle division by zero scenario (though unlikely)\n",
        "\n",
        "                # Store SWT data\n",
        "                swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "                swt_data['ID'].append(stop_point_id)\n",
        "                swt_data['SWT_minutes'].append(scheduled_wait_time)\n",
        "                swt_data['Number_of_buses'].append(total_buses_this_hour)\n",
        "\n",
        "                # Fetch arrival predictions based on SWT data for printed timetable stop IDs\n",
        "                if stop_point_id in printed_timetable_stop_ids:\n",
        "                    # Fetch arrival predictions\n",
        "                    arrival_predictions_df, station_name = fetch_arrival_predictions(lineID, stop_point_id, direction)\n",
        "\n",
        "                    if arrival_predictions_df is not None and not arrival_predictions_df.empty:\n",
        "                        #print(f\"\\nArrival Predictions for stop point {stop_point_id} ({station_name}):\")\n",
        "                        #print(arrival_predictions_df.to_string(index=False))\n",
        "                        print(f\"   \")\n",
        "                        # Calculating summary metrics\n",
        "                        total_wawt = arrival_predictions_df['WAWT'].sum()\n",
        "                        min_arrival = arrival_predictions_df['Expected Arrival (BST)'].min().replace(second=0, microsecond=0)\n",
        "                        max_arrival = arrival_predictions_df['Expected Arrival (BST)'].max().replace(second=0, microsecond=0)\n",
        "                        time_diff_minutes = (max_arrival - min_arrival).total_seconds() / 60\n",
        "                        num_buses_observed = arrival_predictions_df['Vehicle ID'].nunique()\n",
        "\n",
        "                        # Calculating AWT, SWT, and EWT\n",
        "                        nbph = swt_data['Number_of_buses'][swt_data['ID'].index(stop_point_id)]\n",
        "                        swt = swt_data['SWT_minutes'][swt_data['ID'].index(stop_point_id)]\n",
        "                        awt = round(total_wawt / time_diff_minutes, 2) if time_diff_minutes > 0 else 0\n",
        "                        ewt = round(awt - swt, 2)\n",
        "\n",
        "                        summary_df = pd.DataFrame({\n",
        "                            'Metric': ['Number of buses scheduled per hour (nbph)', 'Number of buses observed', 'Total WAWT (minutes)',\n",
        "                                       'Time difference between 1st and last observed buses (minutes)', 'AWT (minutes)', 'SWT (minutes)', 'EWT (minutes)'],\n",
        "                            'Value': [nbph, num_buses_observed, total_wawt, time_diff_minutes, awt, swt, ewt]\n",
        "                        })\n",
        "\n",
        "                        print(f\"\\nSummary Metrics for {stop_point_id}:\")\n",
        "                        print(summary_df)\n",
        "\n",
        "                        # Append to awt_data DataFrame\n",
        "                        awt_data.loc[len(awt_data)] = [stop_point_id, num_buses_observed, awt]\n",
        "\n",
        "                    # Remove the stop ID from printed_timetable_stop_ids to avoid redundant fetches\n",
        "                    printed_timetable_stop_ids.remove(stop_point_id)\n",
        "\n",
        "        # Update printed timetable stop IDs\n",
        "        printed_timetable_stop_ids = swt_data['ID']\n",
        "\n",
        "        # Create DataFrame for SWT data\n",
        "        swt_df = pd.DataFrame(swt_data)\n",
        "        awt_df = pd.DataFrame(awt_data)\n",
        "        # Print the SWT DataFrame\n",
        "        print(f\"\\n\\nSWT DataFrame at hour {current_hour}\")\n",
        "        print(swt_df)\n",
        "\n",
        "        print(f\"\\n\\nAWT DataFrame at hour {current_hour}\")\n",
        "        print(awt_df)\n",
        "\n",
        "        # Wait for the next 30 seconds\n",
        "        #clear_output()\n",
        "        print(\"\\n\\nWaiting to fetch updated data...\\n\\n\")\n",
        "        time.sleep(30)\n",
        "\n",
        "# Function to fetch arrival predictions with error handling\n",
        "def fetch_arrival_predictions(line_id, stop_point_id, direction):\n",
        "    try:\n",
        "        base_url = f\"https://api.tfl.gov.uk/Line/{line_id}/Arrivals/{stop_point_id}\"\n",
        "        params = {'direction': direction}\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if len(data) == 0:\n",
        "            return pd.DataFrame(), None  # No data available\n",
        "        station_name = data[0]['stationName']\n",
        "        predictions = []\n",
        "        for item in data:\n",
        "            arrival_time = datetime.strptime(item['expectedArrival'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            arrival_time_bst = arrival_time + timedelta(hours=1)\n",
        "            predictions.append({\n",
        "                'Line': item['lineName'],\n",
        "                'Vehicle ID': item['vehicleId'],\n",
        "                'Stop Point': stop_point_id,\n",
        "                'Direction': direction,\n",
        "                'Expected Arrival (BST)': arrival_time_bst,\n",
        "                'Expected Arrival (HM)': arrival_time_bst.strftime('%H:%M')\n",
        "            })\n",
        "        df = pd.DataFrame(predictions)\n",
        "        df = df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "        df['Expected Arrival (BST)'] = pd.to_datetime(df['Expected Arrival (BST)'])  # Convert to datetime\n",
        "        df['Expected Arrival (HM)'] = pd.to_datetime(df['Expected Arrival (HM)'], format='%H:%M')\n",
        "        df['Headway (minutes)'] = df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "        df['AWT/bus (minutes)'] = (df['Headway (minutes)'] / 2).round(2)\n",
        "        df['WAWT'] = (df['Headway (minutes)'] * df['AWT/bus (minutes)']).round(2)\n",
        "        return df, station_name\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None, None\n",
        "        time.sleep(30)  # Wait for 30 seconds before fetching data again\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the Excel file into a DataFrame\n",
        "    file_path = '/content/QSI points.xlsx'  # Modify this path accordingly\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Ask the user to enter a lineID\n",
        "    line_id_input = input(\"Please enter the lineID: \")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Find and display the route details\n",
        "            find_route_details(line_id_input, df)\n",
        "\n",
        "            time.sleep(30)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nExecution interrupted. Exiting the loop.\\n\")\n",
        "            break"
      ],
      "metadata": {
        "id": "jDEhcXb-BVRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modification to overwrite awt"
      ],
      "metadata": {
        "id": "WasfX8mdERwL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2_ArsqzsESAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from difflib import SequenceMatcher\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import time\n",
        "\n",
        "# Initialize empty DataFrame for AWT data\n",
        "awt_data = pd.DataFrame(columns=['Stop Point ID', 'Number of Buses Observed', 'AWT (minutes)'])\n",
        "\n",
        "# Function to normalize stop names\n",
        "def normalize_stop_name(name):\n",
        "    return ' '.join(name.lower().split())\n",
        "\n",
        "# Function to fetch data from the API\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# Function to extract schedule names\n",
        "def extract_schedule_names(data, schedule_names_dict={}):\n",
        "    if isinstance(data, dict):\n",
        "        if data.get('$type') == \"Tfl.Api.Presentation.Entities.Schedule, Tfl.Api.Presentation.Entities\" and 'knownJourneys' in data:\n",
        "            if 'name' in data:\n",
        "                schedule_names_dict[data['name']] = data['knownJourneys']\n",
        "        for key, value in data.items():\n",
        "            extract_schedule_names(value, schedule_names_dict)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            extract_schedule_names(item, schedule_names_dict)\n",
        "    return schedule_names_dict\n",
        "\n",
        "# Function to categorize journeys into hourly slots\n",
        "def categorize_into_slots(timetable):\n",
        "    slots = [[] for _ in range(24)]\n",
        "    for journey in timetable:\n",
        "        hour = int(journey['hour'])  # Convert hour to integer\n",
        "        if 0 <= hour < 24:  # Ensure hour is within the valid range\n",
        "            slots[hour].append(journey)\n",
        "    return slots\n",
        "\n",
        "# Function to fetch the current day of the week\n",
        "def get_day_of_week():\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    now = datetime.now(bst)\n",
        "    return now.strftime('%A')  # %A gives full weekday name (e.g., 'Monday')\n",
        "\n",
        "# Function to retrieve stop names from TfL API and match with Route_Dir_QSI_No\n",
        "def find_route_details(lineID, df):\n",
        "    # Ensure the 'Route_Dir_QSI_No' column exists\n",
        "    if 'Route_Dir_QSI_No' not in df.columns:\n",
        "        print(\"The 'Route_Dir_QSI_No' column is not present in the provided file.\")\n",
        "        return\n",
        "\n",
        "    # Convert the lineID to uppercase to ensure case-insensitivity\n",
        "    lineID = lineID.upper()\n",
        "\n",
        "    # Convert the 'Route_Dir_QSI_No' column to uppercase for comparison\n",
        "    df['Route_Dir_QSI_No'] = df['Route_Dir_QSI_No'].str.upper()\n",
        "\n",
        "    # Normalize the stop names in the DataFrame\n",
        "    df['STOP_NAME'] = df['STOP_NAME'].apply(normalize_stop_name)\n",
        "\n",
        "    # Filter the DataFrame based on the lineID\n",
        "    pattern_A = f\"^{lineID}_A\\\\d+$\"  # Regular expression for D7_A**\n",
        "    pattern_B = f\"^{lineID}_B\\\\d+$\"  # Regular expression for D7_B**\n",
        "\n",
        "    # Filter rows where the 'Route_Dir_QSI_No' column matches the pattern\n",
        "    filtered_df_A = df[df['Route_Dir_QSI_No'].str.match(pattern_A, na=False)]\n",
        "    filtered_df_B = df[df['Route_Dir_QSI_No'].str.match(pattern_B, na=False)]\n",
        "\n",
        "    # Function to fetch and process route sequence data from TfL API\n",
        "    def fetch_and_process_route_data(route_type, pattern, filtered_df):\n",
        "        api_url = f\"https://api.tfl.gov.uk/Line/{lineID}/Route/Sequence/{route_type}\"\n",
        "        response = requests.get(api_url)\n",
        "\n",
        "        results_list = []\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            route_data = response.json()\n",
        "\n",
        "            # Iterate through each stop in the route data\n",
        "            for stop in route_data['stopPointSequences'][0]['stopPoint']:\n",
        "                stop_name_api = normalize_stop_name(stop['name'])\n",
        "                stop_id = stop['id']\n",
        "\n",
        "                # Check if the stop_name_api exists in the filtered DataFrame for the correct direction\n",
        "                matched_row = filtered_df[(filtered_df['STOP_NAME'] == stop_name_api) &\n",
        "                                          (filtered_df['Route_Dir_QSI_No'].str.match(pattern))]\n",
        "\n",
        "                if not matched_row.empty:\n",
        "                    route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                    results_list.append({\n",
        "                        'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                        'STOP_Name': stop['name'],\n",
        "                        'ID': stop_id\n",
        "                    })\n",
        "                else:\n",
        "                    # If exact match not found, try partial matching based on words before and after '/'\n",
        "                    api_stop_name_parts = stop_name_api.split('/')\n",
        "                    for index, row in filtered_df.iterrows():\n",
        "                        df_stop_name_parts = row['STOP_NAME'].split('/')\n",
        "                        for api_part in api_stop_name_parts:\n",
        "                            for df_part in df_stop_name_parts:\n",
        "                                if SequenceMatcher(None, df_part.strip(), api_part.strip()).ratio() > 0.8:\n",
        "                                    matched_row = pd.DataFrame([row])\n",
        "                                    break\n",
        "                            if not matched_row.empty:\n",
        "                                break\n",
        "                        if not matched_row.empty:\n",
        "                            break\n",
        "\n",
        "                    if not matched_row.empty:\n",
        "                        route_dir_qsi_no = matched_row.iloc[0]['Route_Dir_QSI_No']\n",
        "                        results_list.append({\n",
        "                            'Route_Dir_QSI_No': route_dir_qsi_no,\n",
        "                            'STOP_Name': stop['name'],\n",
        "                            'ID': stop_id\n",
        "                        })\n",
        "        else:\n",
        "            print(f\"Failed to fetch route sequence data from TfL API for {route_type} route. Status code: {response.status_code}\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    # Fetch and process outbound route data for _A**\n",
        "    matched_results_A = fetch_and_process_route_data('outbound', pattern_A, filtered_df_A)\n",
        "\n",
        "    # Fetch and process inbound route data for _B**\n",
        "    matched_results_B = fetch_and_process_route_data('inbound', pattern_B, filtered_df_B)\n",
        "\n",
        "    # Create DataFrames from the matched results for each direction\n",
        "    matched_results_df_A = pd.DataFrame(matched_results_A)\n",
        "    matched_results_df_B = pd.DataFrame(matched_results_B)\n",
        "\n",
        "    # Function to remove partial matches if exact matches are found\n",
        "    def remove_partial_matches(exact_df, matched_df):\n",
        "        for index, row in exact_df.iterrows():\n",
        "            exact_stop_name = row['STOP_NAME']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "            # Find exact matches in matched_df\n",
        "            exact_matches = matched_df[(matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                       (matched_df['STOP_Name'].apply(normalize_stop_name) == exact_stop_name)]\n",
        "            if not exact_matches.empty:\n",
        "                # Remove partial matches\n",
        "                matched_df = matched_df[~((matched_df['Route_Dir_QSI_No'] == route_dir_qsi_no) &\n",
        "                                          (matched_df['STOP_Name'].apply(normalize_stop_name) != exact_stop_name))]\n",
        "        return matched_df\n",
        "\n",
        "    # Remove partial matches for direction A\n",
        "    matched_results_df_A = remove_partial_matches(filtered_df_A, matched_results_df_A)\n",
        "\n",
        "    # Remove partial matches for direction B\n",
        "    matched_results_df_B = remove_partial_matches(filtered_df_B, matched_results_df_B)\n",
        "\n",
        "    # Remove duplicate stop names with the same Route_Dir_QSI_No and different IDs\n",
        "    matched_results_df_A = matched_results_df_A.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "    matched_results_df_B = matched_results_df_B.drop_duplicates(subset=['Route_Dir_QSI_No', 'STOP_Name'], keep='first')\n",
        "\n",
        "    # Print the matched results for direction A\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_A\\033[0m\\n\")\n",
        "    matched_results_df_A = matched_results_df_A[matched_results_df_A['Route_Dir_QSI_No'].str.match(pattern_A)]\n",
        "    print(matched_results_df_A[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Print the matched results for direction B\n",
        "    print(f\"\\n\\n\\033[1m\\033[4mQSI stop points for direction {lineID}_B\\033[0m\\n\")\n",
        "    matched_results_df_B = matched_results_df_B[matched_results_df_B['Route_Dir_QSI_No'].str.match(pattern_B)]\n",
        "    print(matched_results_df_B[['Route_Dir_QSI_No', 'STOP_Name', 'ID']])\n",
        "\n",
        "    # Concatenate the matched results DataFrames for directions A and B\n",
        "    combined_df = pd.concat([matched_results_df_A, matched_results_df_B], ignore_index=True)\n",
        "\n",
        "    # DataFrames to store SWT data\n",
        "    swt_data = {\n",
        "        'Route_Dir_QSI_No': [],\n",
        "        'ID': [],\n",
        "        'SWT_minutes': [],\n",
        "        'Number_of_buses': []\n",
        "    }\n",
        "\n",
        "    # Fetch timetable for each stop point ID and calculate SWT\n",
        "    bst = pytz.timezone('Europe/London')\n",
        "    current_hour = datetime.now(bst).hour\n",
        "    day_of_week = get_day_of_week()\n",
        "\n",
        "    # Store selected schedule name to ensure it's printed only once\n",
        "    selected_schedule_name = None\n",
        "    printed_schedule_name = False\n",
        "\n",
        "    # Track printed timetable stop IDs\n",
        "    printed_timetable_stop_ids = []\n",
        "\n",
        "    while True:\n",
        "        # Clear previous awt_data DataFrame\n",
        "        awt_data = pd.DataFrame(columns=['Stop Point ID', 'Number of Buses Observed', 'AWT (minutes)'])\n",
        "\n",
        "        # Update current time and hour\n",
        "        now = datetime.now(bst)\n",
        "        current_hour = now.hour\n",
        "        day_of_week = get_day_of_week()\n",
        "\n",
        "        # Clear previous SWT data\n",
        "        swt_data = {\n",
        "            'Route_Dir_QSI_No': [],\n",
        "            'ID': [],\n",
        "            'SWT_minutes': [],\n",
        "            'Number_of_buses': []\n",
        "        }\n",
        "\n",
        "        for index, row in combined_df.iterrows():\n",
        "            stop_point_id = row['ID']\n",
        "            route_dir_qsi_no = row['Route_Dir_QSI_No']\n",
        "\n",
        "            if f\"{lineID}_A\" in route_dir_qsi_no:\n",
        "                direction = 'outbound'\n",
        "            elif f\"{lineID}_B\" in route_dir_qsi_no:\n",
        "                direction = 'inbound'\n",
        "            else:\n",
        "                print(f\"Invalid route direction for Route_Dir_QSI_No: {route_dir_qsi_no}\")\n",
        "                continue\n",
        "\n",
        "            url = f'https://api.tfl.gov.uk/Line/{lineID}/Timetable/{stop_point_id}?direction={direction}'\n",
        "            data = fetch_data(url)\n",
        "\n",
        "            schedule_names_dict = extract_schedule_names(data)\n",
        "\n",
        "            if not selected_schedule_name:\n",
        "                if day_of_week.lower() in ['monday', 'tuesday', 'wednesday', 'thursday']:\n",
        "                    preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Thursday', 'Monday to Friday']\n",
        "                elif day_of_week.lower() == 'friday':\n",
        "                    preferred_schedule_names = ['Mon-Fri Schooldays', 'Monday to Friday', 'Friday']\n",
        "                elif day_of_week.lower() == 'saturday':\n",
        "                    preferred_schedule_names = ['Saturday']\n",
        "                elif day_of_week.lower() == 'sunday':\n",
        "                    preferred_schedule_names = ['Sunday']\n",
        "                else:\n",
        "                    preferred_schedule_names = [day_of_week]\n",
        "\n",
        "                for preferred_name in preferred_schedule_names:\n",
        "                    if preferred_name in schedule_names_dict:\n",
        "                        selected_schedule_name = preferred_name\n",
        "                        break\n",
        "\n",
        "            if selected_schedule_name and not printed_schedule_name:\n",
        "                print(f\"\\nToday is {day_of_week}. The selected Schedule name is {selected_schedule_name}.\")\n",
        "                printed_schedule_name = True\n",
        "\n",
        "            if selected_schedule_name:\n",
        "                timetable = schedule_names_dict[selected_schedule_name]\n",
        "                slots = categorize_into_slots(timetable)\n",
        "\n",
        "                # Calculate Scheduled Wait Time (SWT)\n",
        "                total_buses_this_hour = len(slots[current_hour])\n",
        "                if total_buses_this_hour > 0:\n",
        "                    scheduled_wait_time = 60 / (total_buses_this_hour * 2)  # SWT formula\n",
        "                else:\n",
        "                    scheduled_wait_time = float('inf')  # Handle division by zero scenario (though unlikely)\n",
        "\n",
        "                # Store SWT data\n",
        "                swt_data['Route_Dir_QSI_No'].append(route_dir_qsi_no)\n",
        "                swt_data['ID'].append(stop_point_id)\n",
        "                swt_data['SWT_minutes'].append(scheduled_wait_time)\n",
        "                swt_data['Number_of_buses'].append(total_buses_this_hour)\n",
        "\n",
        "                # Fetch arrival predictions based on SWT data for printed timetable stop IDs\n",
        "                if stop_point_id in printed_timetable_stop_ids:\n",
        "                    # Fetch arrival predictions\n",
        "                    arrival_predictions_df, station_name = fetch_arrival_predictions(lineID, stop_point_id, direction)\n",
        "\n",
        "                    if arrival_predictions_df is not None and not arrival_predictions_df.empty:\n",
        "                        #print(f\"\\nArrival Predictions for stop point {stop_point_id} ({station_name}):\")\n",
        "                        #print(arrival_predictions_df.to_string(index=False))\n",
        "                        print(f\"   \")\n",
        "                        # Calculating summary metrics\n",
        "                        total_wawt = arrival_predictions_df['WAWT'].sum()\n",
        "                        min_arrival = arrival_predictions_df['Expected Arrival (BST)'].min().replace(second=0, microsecond=0)\n",
        "                        max_arrival = arrival_predictions_df['Expected Arrival (BST)'].max().replace(second=0, microsecond=0)\n",
        "                        time_diff_minutes = (max_arrival - min_arrival).total_seconds() / 60\n",
        "                        num_buses_observed = arrival_predictions_df['Vehicle ID'].nunique()\n",
        "\n",
        "                        # Calculating AWT, SWT, and EWT\n",
        "                        nbph = swt_data['Number_of_buses'][swt_data['ID'].index(stop_point_id)]\n",
        "                        swt = swt_data['SWT_minutes'][swt_data['ID'].index(stop_point_id)]\n",
        "                        awt = round(total_wawt / time_diff_minutes, 2) if time_diff_minutes > 0 else 0\n",
        "                        ewt = round(awt - swt, 2)\n",
        "\n",
        "                        summary_df = pd.DataFrame({\n",
        "                            'Metric': ['Number of buses scheduled per hour (nbph)', 'Number of buses observed', 'Total WAWT (minutes)',\n",
        "                                       'Time difference between 1st and last observed buses (minutes)', 'AWT (minutes)', 'SWT (minutes)', 'EWT (minutes)'],\n",
        "                            'Value': [nbph, num_buses_observed, total_wawt, time_diff_minutes, awt, swt, ewt]\n",
        "                        })\n",
        "\n",
        "                        print(f\"\\nSummary Metrics for {stop_point_id}:\")\n",
        "                        print(summary_df)\n",
        "\n",
        "                        # Append to awt_data DataFrame\n",
        "                        awt_data.loc[len(awt_data)] = [stop_point_id, num_buses_observed, awt]\n",
        "\n",
        "                    # Remove the stop ID from printed_timetable_stop_ids to avoid redundant fetches\n",
        "                    printed_timetable_stop_ids.remove(stop_point_id)\n",
        "\n",
        "        # Update printed timetable stop IDs\n",
        "        printed_timetable_stop_ids = swt_data['ID']\n",
        "\n",
        "        # Create DataFrame for SWT data\n",
        "        swt_df = pd.DataFrame(swt_data)\n",
        "        awt_df = pd.DataFrame(awt_data)\n",
        "        # Print the SWT DataFrame\n",
        "        print(f\"\\n\\nSWT DataFrame at hour {current_hour}\")\n",
        "        print(swt_df)\n",
        "\n",
        "        print(f\"\\n\\nAWT DataFrame at hour {current_hour}\")\n",
        "        print(awt_df)\n",
        "\n",
        "        # Wait for the next 30 seconds\n",
        "        #clear_output()\n",
        "        print(\"\\n\\nWaiting to fetch updated data...\\n\\n\")\n",
        "        time.sleep(30)\n",
        "\n",
        "# Function to fetch arrival predictions with error handling\n",
        "def fetch_arrival_predictions(line_id, stop_point_id, direction):\n",
        "    try:\n",
        "        base_url = f\"https://api.tfl.gov.uk/Line/{line_id}/Arrivals/{stop_point_id}\"\n",
        "        params = {'direction': direction}\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if len(data) == 0:\n",
        "            return pd.DataFrame(), None  # No data available\n",
        "        station_name = data[0]['stationName']\n",
        "        predictions = []\n",
        "        for item in data:\n",
        "            arrival_time = datetime.strptime(item['expectedArrival'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            arrival_time_bst = arrival_time + timedelta(hours=1)\n",
        "            predictions.append({\n",
        "                'Line': item['lineName'],\n",
        "                'Vehicle ID': item['vehicleId'],\n",
        "                'Stop Point': stop_point_id,\n",
        "                'Direction': direction,\n",
        "                'Expected Arrival (BST)': arrival_time_bst,\n",
        "                'Expected Arrival (HM)': arrival_time_bst.strftime('%H:%M')\n",
        "            })\n",
        "        df = pd.DataFrame(predictions)\n",
        "        df = df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "        df['Expected Arrival (BST)'] = pd.to_datetime(df['Expected Arrival (BST)'])  # Convert to datetime\n",
        "        df['Expected Arrival (HM)'] = pd.to_datetime(df['Expected Arrival (HM)'], format='%H:%M')\n",
        "        df['Headway (minutes)'] = df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "        df['AWT/bus (minutes)'] = (df['Headway (minutes)'] / 2).round(2)\n",
        "        df['WAWT'] = (df['Headway (minutes)'] * df['AWT/bus (minutes)']).round(2)\n",
        "        return df, station_name\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None, None\n",
        "        time.sleep(30)  # Wait for 30 seconds before fetching data again\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the Excel file into a DataFrame\n",
        "    file_path = '/content/QSI points.xlsx'  # Modify this path accordingly\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Ask the user to enter a lineID\n",
        "    line_id_input = input(\"Please enter the lineID: \")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Find and display the route details\n",
        "            find_route_details(line_id_input, df)\n",
        "\n",
        "            time.sleep(30)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nExecution interrupted. Exiting the loop.\\n\")\n",
        "            break"
      ],
      "metadata": {
        "id": "40ipmC3PPGRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTxxfwjR6gAWZp/hapfKD4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}