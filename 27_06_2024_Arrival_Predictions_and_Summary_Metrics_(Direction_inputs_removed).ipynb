{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtKerZv6kjqLueKC/ddd3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemyaVKarthikeyan/AA-Stagecoach-Project/blob/main/27_06_2024_Arrival_Predictions_and_Summary_Metrics_(Direction_inputs_removed).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "XWQgyutcQMe-",
        "outputId": "0283c1e6-8123-4cd4-b184-4a519fdf0b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Collecting dash\n",
            "  Downloading dash-2.17.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.3)\n",
            "Collecting dash-html-components==2.0.0 (from dash)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (7.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (67.7.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.19.2)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, retrying, dash\n",
            "Successfully installed dash-2.17.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required libraries (if not already installed)\n",
        "!pip install requests pandas plotly dash\n",
        "\n",
        "# Step 2: Import required libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pytz\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Function to convert time to BST\n",
        "def convert_to_bst(dt):\n",
        "    utc_tz = pytz.timezone('UTC')\n",
        "    bst_tz = pytz.timezone('Europe/London')\n",
        "    utc_dt = utc_tz.localize(dt)\n",
        "    bst_dt = utc_dt.astimezone(bst_tz)\n",
        "    return bst_dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Function to fetch arrival predictions with error handling\n",
        "def fetch_arrival_predictions(line_id, stop_point_id, direction):\n",
        "    try:\n",
        "        base_url = f\"https://api.tfl.gov.uk/Line/{line_id}/Arrivals/{stop_point_id}\"\n",
        "        params = {'direction': direction}\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if len(data) == 0:\n",
        "            return pd.DataFrame(), None  # No data available\n",
        "        station_name = data[0]['stationName']\n",
        "        predictions = []\n",
        "        for item in data:\n",
        "            arrival_time = datetime.strptime(item['expectedArrival'], '%Y-%m-%dT%H:%M:%SZ')\n",
        "            arrival_time_bst = arrival_time + timedelta(hours=1)\n",
        "            predictions.append({\n",
        "                'Line': item['lineName'],\n",
        "                'Vehicle ID': item['vehicleId'],\n",
        "                'Stop Point': stop_point_id,\n",
        "                'Direction': direction,\n",
        "                'Expected Arrival (BST)': arrival_time_bst,\n",
        "                'Expected Arrival (HM)': arrival_time_bst.strftime('%H:%M')\n",
        "            })\n",
        "        df = pd.DataFrame(predictions)\n",
        "        df = df.sort_values(by='Expected Arrival (BST)', ascending=True)\n",
        "        df['Expected Arrival (HM)'] = pd.to_datetime(df['Expected Arrival (HM)'], format='%H:%M')\n",
        "        df['Headway (minutes)'] = df['Expected Arrival (HM)'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds() / 60\n",
        "        df['AWT/bus (minutes)'] = (df['Headway (minutes)'] / 2).round(2)\n",
        "        df['WAWT'] = (df['Headway (minutes)'] * df['AWT/bus (minutes)']).round(2)\n",
        "        df['Expected Arrival (BST)'] = df['Expected Arrival (BST)'].apply(lambda x: x.replace(second=0, microsecond=0).strftime('%H:%M:%S'))\n",
        "        return df, station_name\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Fetch route details\n",
        "def fetch_route_details(line_id, direction):\n",
        "    url = f\"https://api.tfl.gov.uk/Line/{line_id}/Route\"\n",
        "    params = {'serviceTypes': 'Regular'}\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        route_sections = data.get('routeSections', [])\n",
        "        found_direction = False\n",
        "        for section in route_sections:\n",
        "            if section.get('direction', '').lower() == direction.lower():\n",
        "                found_direction = True\n",
        "                origination_name = section.get('originationName', 'Unknown')\n",
        "                destination_name = section.get('destinationName', 'Unknown')\n",
        "                originator = section.get('originator', 'Unknown')\n",
        "                destination = section.get('destination', 'Unknown')\n",
        "                print(f\"Direction: {direction}\")\n",
        "                print(f\"Origination Name: {origination_name}\")\n",
        "                print(f\"Destination Name: {destination_name}\")\n",
        "                print(f\"Originator: {originator}\")\n",
        "                print(f\"Destination: {destination}\")\n",
        "                print(\"---\")\n",
        "                all_stop_details = fetch_and_append_stop_points(line_id, originator, destination, direction)\n",
        "                if all_stop_details:\n",
        "                    write_to_csv(all_stop_details)\n",
        "                    display_data_from_csv()\n",
        "        if not found_direction:\n",
        "            print(f\"No route found for direction '{direction}'.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "\n",
        "# Fetch and append stop points\n",
        "def fetch_and_append_stop_points(line_id, originator, destination, direction):\n",
        "    url = f\"https://api.tfl.gov.uk/Line/{line_id}/Route/Sequence/{direction}\"\n",
        "    all_stop_details = []\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        line_strings = data.get('lineStrings', [])\n",
        "        if line_strings:\n",
        "            printed_stop_ids = set()\n",
        "            for line_string in line_strings:\n",
        "                coordinates = eval(line_string)\n",
        "                for lon, lat in coordinates[0]:\n",
        "                    fetch_and_append_stop_details(lat, lon, printed_stop_ids, all_stop_details)\n",
        "        else:\n",
        "            print(\"No stop points found for this route.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching stop points: {e}\")\n",
        "    return all_stop_details\n",
        "\n",
        "# Fetch and append stop details\n",
        "def fetch_and_append_stop_details(lat, lon, printed_stop_ids, all_stop_details, retries=3):\n",
        "    url = f\"https://api.tfl.gov.uk/Stoppoint?lat={lat}&lon={lon}&stopTypes=NaptanPublicBusCoachTram&radius=200\"\n",
        "    try:\n",
        "        for attempt in range(retries):\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 429:\n",
        "                time.sleep(2**attempt)\n",
        "                continue\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            stop_points = data.get('stopPoints', [])\n",
        "            if stop_points:\n",
        "                for stop_point in stop_points:\n",
        "                    stop_id = stop_point.get('id', 'Unknown')\n",
        "                    if stop_id and stop_id not in printed_stop_ids:\n",
        "                        stop_name = stop_point.get('commonName', 'Unknown')\n",
        "                        all_stop_details.append({\n",
        "                            'Sl. No.': len(all_stop_details) + 1,\n",
        "                            'Stop ID': stop_id,\n",
        "                            'Stop Name': stop_name\n",
        "                        })\n",
        "                        printed_stop_ids.add(stop_id)\n",
        "            else:\n",
        "                continue\n",
        "            break\n",
        "        else:\n",
        "            pass\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        pass\n",
        "\n",
        "# Write to CSV\n",
        "def write_to_csv(all_stop_details):\n",
        "    headers = ['Sl. No.', 'Stop ID', 'Stop Name']\n",
        "    with open('stop_details.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
        "        writer.writeheader()\n",
        "        for stop_detail in all_stop_details:\n",
        "            writer.writerow(stop_detail)\n",
        "    print(f\"Data written to 'stop_details.csv' successfully.\")\n",
        "\n",
        "# Display data from CSV\n",
        "def display_data_from_csv():\n",
        "    print(\"Data from CSV:\")\n",
        "    with open('stop_details.csv', 'r', newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        headers_printed = False\n",
        "        for row in reader:\n",
        "            if not headers_printed:\n",
        "                print(f\"{row['Sl. No.']:<6} {row['Stop ID']:<10} {row['Stop Name']}\")\n",
        "                headers_printed = True\n",
        "            else:\n",
        "                print(f\"{row['Sl. No.']:<6} {row['Stop ID']:<10} {row['Stop Name']}\")\n",
        "\n",
        "# Get QSI stop points\n",
        "def get_qsi_stop_points():\n",
        "    count_of_qsi_stop_points = int(input(\"Enter the number of QSI stop points: \"))\n",
        "    qsi_stop_points = []\n",
        "    for i in range(count_of_qsi_stop_points):\n",
        "        row_no = int(input(f\"Enter the row number for QSI stop point {i+1}: \"))\n",
        "        qsi_stop_points.append(row_no)\n",
        "    qsi_stop_ids = []\n",
        "    print(\"QSI Stop Points:\")\n",
        "    with open('stop_details.csv', 'r', newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            if int(row['Sl. No.']) in qsi_stop_points:\n",
        "                print(f\"{row['Sl. No.']:<6} {row['Stop ID']:<10} {row['Stop Name']}\")\n",
        "                qsi_stop_ids.append(row['Stop ID'])\n",
        "    return qsi_stop_ids\n",
        "\n",
        "# Main loop to fetch and display data\n",
        "def main_loop(line_id, direction, qsi_stop_ids):\n",
        "    nbph = 6  # Fixed number of buses per hour for all QSI stop points\n",
        "    while True:\n",
        "        qsi_data = []  # List to accumulate data for all QSI stop points\n",
        "        for idx, stop_point_id in enumerate(qsi_stop_ids):\n",
        "            df, station_name = fetch_arrival_predictions(line_id, stop_point_id, direction)\n",
        "            if df is not None and station_name is not None:\n",
        "                total_wawt = df['WAWT'].sum()\n",
        "                min_arrival = pd.to_datetime(df['Expected Arrival (BST)'], format='%H:%M:%S').min().replace(second=0, microsecond=0)\n",
        "                max_arrival = pd.to_datetime(df['Expected Arrival (BST)'], format='%H:%M:%S').max().replace(second=0, microsecond=0)\n",
        "                time_diff_minutes = (max_arrival - min_arrival).total_seconds() / 60\n",
        "                awt = round(total_wawt / time_diff_minutes, 2) if time_diff_minutes > 0 else 0\n",
        "                swt = round(60 / (nbph * 2), 2)\n",
        "                ewt = round(awt - swt, 2)\n",
        "                num_buses_observed = df['Vehicle ID'].nunique()\n",
        "                summary_df = pd.DataFrame({\n",
        "                    'Metric': ['Number of buses scheduled per hour (nbph)', 'Number of buses observed', 'Total WAWT (minutes)', 'Time difference between 1st and last observed buses (minutes)', 'AWT (minutes)', 'SWT (minutes)', 'EWT (minutes)'],\n",
        "                    'Value': [nbph, num_buses_observed, total_wawt, time_diff_minutes, awt, swt, ewt]\n",
        "                })\n",
        "                qsi_data.append({\n",
        "                    'QSI Stop Point': f\"{idx + 1} - {station_name}\",\n",
        "                    'Arrival Predictions': df[['Line', 'Vehicle ID', 'Stop Point', 'Direction', 'Expected Arrival (BST)', 'Headway (minutes)', 'AWT/bus (minutes)', 'WAWT']].to_string(index=False),\n",
        "                    'Summary Metrics': summary_df.to_string(index=False)\n",
        "                })\n",
        "            else:\n",
        "                qsi_data.append({\n",
        "                    'QSI Stop Point': f\"{idx + 1} - Fetch Error\",\n",
        "                    'Arrival Predictions': \"No data available\",\n",
        "                    'Summary Metrics': \"No data available\"\n",
        "                })\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        for qsi in qsi_data:\n",
        "            print(f\"QSI Stop Point: {qsi['QSI Stop Point']}\")\n",
        "            print(\"Arrival Predictions:\")\n",
        "            print(qsi['Arrival Predictions'])\n",
        "            print(\"\\nSummary Metrics:\")\n",
        "            print(qsi['Summary Metrics'])\n",
        "            print(\"\\n--------------------------------------------\\n\")\n",
        "\n",
        "        time.sleep(15)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    line_id = input(\"Enter line ID: \")\n",
        "    directions = ['inbound', 'outbound']\n",
        "    for direction in directions:\n",
        "        fetch_route_details(line_id, direction)\n",
        "        qsi_stop_ids = get_qsi_stop_points()\n",
        "        main_loop(line_id, direction, qsi_stop_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "44eY_j6mQuaF",
        "outputId": "51f97500-de33-4f4b-9089-a8f365f414d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QSI Stop Point: 1 - Island Gardens Station\n",
            "Arrival Predictions:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST)  Headway (minutes)  AWT/bus (minutes)  WAWT\n",
            "  D7    LX61DBO 490002048X   inbound               10:35:00                0.0                0.0   0.0\n",
            "  D7    LX11BJU 490002048X   inbound               10:46:00               11.0                5.5  60.5\n",
            "  D7    LX11BHN 490002048X   inbound               10:58:00               12.0                6.0  72.0\n",
            "\n",
            "Summary Metrics:\n",
            "                                                       Metric  Value\n",
            "                    Number of buses scheduled per hour (nbph)   6.00\n",
            "                                     Number of buses observed   3.00\n",
            "                                         Total WAWT (minutes) 132.50\n",
            "Time difference between 1st and last observed buses (minutes)  23.00\n",
            "                                                AWT (minutes)   5.76\n",
            "                                                SWT (minutes)   5.00\n",
            "                                                EWT (minutes)   0.76\n",
            "\n",
            "--------------------------------------------\n",
            "\n",
            "QSI Stop Point: 2 - Stewart Street\n",
            "Arrival Predictions:\n",
            "Line Vehicle ID Stop Point Direction Expected Arrival (BST)  Headway (minutes)  AWT/bus (minutes)  WAWT\n",
            "  D7    LX61DBO 490013513N   inbound               10:40:00                0.0                0.0   0.0\n",
            "  D7    LX11BJU 490013513N   inbound               10:51:00               11.0                5.5  60.5\n",
            "  D7    LX11BHN 490013513N   inbound               11:03:00               12.0                6.0  72.0\n",
            "\n",
            "Summary Metrics:\n",
            "                                                       Metric  Value\n",
            "                    Number of buses scheduled per hour (nbph)   6.00\n",
            "                                     Number of buses observed   3.00\n",
            "                                         Total WAWT (minutes) 132.50\n",
            "Time difference between 1st and last observed buses (minutes)  23.00\n",
            "                                                AWT (minutes)   5.76\n",
            "                                                SWT (minutes)   5.00\n",
            "                                                EWT (minutes)   0.76\n",
            "\n",
            "--------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cf2231b56526>\u001b[0m in \u001b[0;36m<cell line: 218>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mfetch_route_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mqsi_stop_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_qsi_stop_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mmain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqsi_stop_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-cf2231b56526>\u001b[0m in \u001b[0;36mmain_loop\u001b[0;34m(line_id, direction, qsi_stop_ids)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--------------------------------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}